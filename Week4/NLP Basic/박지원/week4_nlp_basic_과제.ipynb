{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ê³¼ì œ 1\n",
        "\n",
        "### **Q. ê° ëª¨ë¸ì´ ì¶©ì¡±í•˜ëŠ” ì†ì„±ì— ëŒ€í•´ ì•„ë˜ í‘œë¥¼ O/Xë¡œ ì±„ì›Œì£¼ì„¸ìš”.**\n",
        "\n",
        "ğŸ“5ë²ˆì§¸ ì†ì„±ì€ **LSTM ê¸°ì¤€ìœ¼ë¡œ** O/X ì—¬ë¶€ íŒë‹¨í•´ì£¼ì„¸ìš” ! <br>\n",
        "ğŸ“ì •ë‹µì€ ê³¼ì œ ë§ˆê° ë‹¤ìŒë‚  (9ì›” 11ì¼ ìˆ˜ìš”ì¼)ì— **ë…¸ì…˜-ì •ê·œì„¸ì…˜-NLP basic**ì— ì—…ë¡œë“œ ì˜ˆì •\n",
        "\n",
        "\n",
        "> #### **ì†ì„± ì„¤ëª…**\n",
        "1. Order matters : ì…ë ¥ ì‹œí€€ìŠ¤ì˜ ìˆœì„œ ì¤‘ìš” ì—¬ë¶€\n",
        "2. Variable Length : ê³ ì •ëœ ê¸¸ì´ê°€ ì•„ë‹Œ ë‹¤ì–‘í•œ ê¸¸ì´ì˜ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ”ì§€ ì—¬ë¶€\n",
        "3. Differentiable : ë¯¸ë¶„ê°€ëŠ¥\n",
        "4. Pairwise encoding : ë‘ ë‹¨ì–´ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ í‘œí˜„\n",
        "5. Preserves long-term : ì¥ê¸°ì ì¸ ì˜ì¡´ì„±\n"
      ],
      "metadata": {
        "id": "9WW4t3iCYKuy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|               | N-gram | RNN   | LSTM  | Transformer |\n",
        "|:-------------:|:------:|:-----:|:-----:|:-----------:|\n",
        "| Order matters |      O  |  O   | O     | O           |\n",
        "| Variable length |      |  O   | O     | O           |\n",
        "| Differentiable |       |  O   | O     | O           |\n",
        "| Pairwise encoding |    |     |      | O           |\n",
        "| Preserves long-term |  |     | O     | O           |\n"
      ],
      "metadata": {
        "id": "paUeOH0OYNU0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ê³¼ì œ 2\n",
        "\n",
        "\n",
        "### ëª©í‘œ : ë…ì¼ì–´ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ëª¨ë¸ ë§Œë“¤ê¸°\n",
        "ë…ì¼ì–´ ë¬¸ì¥ì„ ì…ë ¥í•˜ë©´ ì˜ì–´ë¡œ ë²ˆì—­í•´ì£¼ëŠ” ëª¨ë¸ì„ seq2seqë¡œ êµ¬í˜„í•´ë´…ì‹œë‹¤"
      ],
      "metadata": {
        "id": "14MthA8WYQev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torchtext==0.6.0"
      ],
      "metadata": {
        "id": "7PbwGzED6TIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53e3d7af-37f6-4131-d15b-7d5fc2aa362d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.66.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.32.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.4.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.26.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (0.1.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n",
            "Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/64.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchtext\n",
            "Successfully installed torchtext-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en\n",
        "!python -m spacy download de"
      ],
      "metadata": {
        "id": "DPKSSHzQ6Uoh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94bdf121-3830-4f96-b2c6-0e88dd666bb5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3mâš  As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.8.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3mâš  Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\u001b[38;5;3mâš  As of spaCy v3.0, shortcuts like 'de' are deprecated. Please use the\n",
            "full pipeline package name 'de_core_news_sm' instead.\u001b[0m\n",
            "Collecting de-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.7.0) (3.7.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.8.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.7.0\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3mâš  Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "import spacy\n",
        "from torchtext.datasets import TranslationDataset\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "MJWiAS2yWutF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizers\n",
        "\n",
        "- ë¬¸ì¥ì˜ í† í°í™”, íƒœê¹… ë“±ì˜ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ `spaCy` ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì˜ì–´ì™€ ë…ì¼ì–´ ì „ì²˜ë¦¬ ëª¨ë“ˆì„ ì„¤ì¹˜í•´ì¤ë‹ˆë‹¤.\n",
        "- ë‘ ì–¸ì–´ì˜ ë¬¸ì¥ì´ ì£¼ì–´ì¡Œê¸° ë•Œë¬¸ì— ì˜ì–´ì™€ ë…ì¼ì–´ ê°ê°ì— ëŒ€í•´ ì „ì²˜ë¦¬í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤.\n"
      ],
      "metadata": {
        "id": "uHmIKputmJfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_de = spacy.load('de_core_news_sm')\n",
        "spacy_en = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "l7ZtI5IXm7EG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì˜ˆì‹œ\n",
        "result = spacy_en.tokenizer(\"I am a student.\")\n",
        "\n",
        "for i, token in enumerate(result):\n",
        "    print(f\"ì¸ë±ìŠ¤ {i}: {token.text}\")"
      ],
      "metadata": {
        "id": "co1TC8yv7yrX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcede0d8-65aa-443b-d16d-868e5173bf0a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì¸ë±ìŠ¤ 0: I\n",
            "ì¸ë±ìŠ¤ 1: am\n",
            "ì¸ë±ìŠ¤ 2: a\n",
            "ì¸ë±ìŠ¤ 3: student\n",
            "ì¸ë±ìŠ¤ 4: .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "í•„ë“œ(field) ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ ë°ì´í„°ì…‹ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì „ì²˜ë¦¬ ë‚´ìš©ì„ ëª…ì‹œí•´ì¤ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "lEGmP9Uk8gQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#===================================================\n",
        "# ğŸ’¡ í† í°í™” ê²°ê³¼ê°€ listë¡œ ë°˜í™˜ë  ìˆ˜ ìˆë„ë¡ return ê²°ê³¼ê°’ì„ ì±„ì›Œì£¼ì„¸ìš”\n",
        "# seq2sxeq ë…¼ë¬¸ì— ì˜í•˜ë©´, input ë‹¨ì–´ì˜ ìˆœì„œë¥¼ ë°”ê¾¸ë©´ ìµœì í™”ê°€ ë” ì‰¬ì›Œì ¸ ì„±ëŠ¥ì´ ì¢‹ì•„ì§„ë‹¤ê³  í•©ë‹ˆë‹¤.\n",
        "# ğŸ’¡ ë…ì¼ì–´ í† í°í™” ê²°ê³¼ê°€ ì—­ìˆœìœ¼ë¡œ returnë  ìˆ˜ ìˆë„ë¡ ë°˜ì˜í•´ì£¼ì„¸ìš”!\n",
        "#===================================================\n",
        "def tokenize_de(text):\n",
        "    return [token.text for token in spacy_de.tokenizer(text)][::-1]\n",
        "\n",
        "# ì˜ì–´ ë¬¸ì¥ì„ spaCyë¥¼ ì‚¬ìš©í•´ í† í°í™”í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜\n",
        "def tokenize_en(text):\n",
        "    return [token.text for token in spacy_en.tokenizer(text)]"
      ],
      "metadata": {
        "id": "uMjoI1XE7tGF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "í•„ë“œ(field) ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ ë°ì´í„°ì…‹ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì „ì²˜ë¦¬ ë‚´ìš©ì„ ëª…ì‹œí•´ì¤ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "z3wGw1nPnpMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ë…ì¼ì–´\n",
        "SRC = Field(tokenize= tokenize_de, init_token = '<sos>', eos_token = '<eos>', lower = True)\n",
        "# ì˜ì–´\n",
        "TRG = Field(tokenize= tokenize_en, init_token = '<sos>', eos_token = '<eos>', lower = True)"
      ],
      "metadata": {
        "id": "ubKI59GPpQ1f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "\n",
        "ëŒ€í‘œì ì¸ ì˜ì–´-ë…ì–´ ë²ˆì—­ ë°ì´í„°ì…‹ Multi30kì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n"
      ],
      "metadata": {
        "id": "0_ccI6_-8hR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/multi30k/dataset.git\n",
        "\n",
        "# ì••ì¶•í•´ì œ\n",
        "!gunzip /content/dataset/data/task1/raw/train.de.gz\n",
        "!gunzip /content/dataset/data/task1/raw/train.en.gz\n",
        "!gunzip /content/dataset/data/task1/raw/val.de.gz\n",
        "!gunzip /content/dataset/data/task1/raw/val.en.gz\n",
        "!gunzip /content/dataset/data/task1/raw/test_2018_flickr.de.gz\n",
        "!gunzip /content/dataset/data/task1/raw/test_2018_flickr.en.gz"
      ],
      "metadata": {
        "id": "mLA5kXAAf2uw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edbedb54-9186-4934-8462-f2f846825876"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dataset'...\n",
            "remote: Enumerating objects: 313, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 313 (delta 17), reused 21 (delta 16), pack-reused 281 (from 1)\u001b[K\n",
            "Receiving objects: 100% (313/313), 18.21 MiB | 8.49 MiB/s, done.\n",
            "Resolving deltas: 100% (69/69), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/dataset/data/task1/raw/'\n",
        "\n",
        "train_data = TranslationDataset(path=data_path, exts=('train.de', 'train.en'), fields=(SRC, TRG) )\n",
        "val_data = TranslationDataset(path=data_path, exts=('val.de', 'val.en'), fields=(SRC, TRG) )\n",
        "test_data = TranslationDataset(path=data_path, exts=('test_2018_flickr.de', 'test_2018_flickr.en'), fields=(SRC, TRG) )"
      ],
      "metadata": {
        "id": "M0JchGVU91Q5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"í•™ìŠµ ë°ì´í„°ì…‹(training dataset) í¬ê¸°: {len(train_data.examples)}ê°œ\")\n",
        "print(f\"í‰ê°€ ë°ì´í„°ì…‹(validation dataset) í¬ê¸°: {len(val_data.examples)}ê°œ\")\n",
        "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹(testing dataset) í¬ê¸°: {len(test_data.examples)}ê°œ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxLylN1y-urW",
        "outputId": "fc914f75-0b89-400d-dde1-b760875b1625"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "í•™ìŠµ ë°ì´í„°ì…‹(training dataset) í¬ê¸°: 29000ê°œ\n",
            "í‰ê°€ ë°ì´í„°ì…‹(validation dataset) í¬ê¸°: 1014ê°œ\n",
            "í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹(testing dataset) í¬ê¸°: 1071ê°œ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vars(train_data.examples[0]))\n",
        "print(vars(train_data.examples[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rpt6l_Xd_AQX",
        "outputId": "a1bf82e8-7c99-490f-b70a-afc63498f6a8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'src': ['.', 'bÃ¼sche', 'vieler', 'nÃ¤he', 'der', 'in', 'freien', 'im', 'sind', 'mÃ¤nner', 'weiÃŸe', 'junge', 'zwei'], 'trg': ['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']}\n",
            "{'src': ['.', 'antriebsradsystem', 'ein', 'bedienen', 'schutzhelmen', 'mit', 'mÃ¤nner', 'mehrere'], 'trg': ['several', 'men', 'in', 'hard', 'hats', 'are', 'operating', 'a', 'giant', 'pulley', 'system', '.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `build_vocab`í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ ì˜ì–´ì™€ ë…ì¼ì–´ì˜ ë‹¨ì–´ ì‚¬ì „ì„ ìƒì„±í•´ì¤ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê° tokenì´ indexingë©ë‹ˆë‹¤\n",
        "- ë‹¨, vocabularyëŠ” í›ˆë ¨ ë°ì´í„°ì…‹ì— ëŒ€í•´ì„œë§Œ ë§Œë“¤ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤.\n",
        "- `min_freq`ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì†Œ 2ë²ˆ ì´ìƒ ë‚˜ì˜¤ëŠ” ë‹¨ì–´ë“¤ë§Œ ì‚¬ì „ì— í¬í•¨ë˜ë„ë¡ í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "uNoigj40AD_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\n",
        "TRG.build_vocab(train_data, min_freq = 2)"
      ],
      "metadata": {
        "id": "TfK-pAr_ApLP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(TRG.vocab.stoi[\"abcabc\"]) # ì—†ëŠ” ë‹¨ì–´: 0\n",
        "print(TRG.vocab.stoi[TRG.pad_token]) # íŒ¨ë”©(padding): 1\n",
        "print(TRG.vocab.stoi[\"\"]) # : 0\n",
        "print(TRG.vocab.stoi[\"\"]) # : 0\n",
        "print(TRG.vocab.stoi[\"hello\"])\n",
        "print(TRG.vocab.stoi[\"world\"])"
      ],
      "metadata": {
        "id": "KyaA5P0Mrqaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b1521ee-ea18-4ca7-fb93-fec068155c3c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "4112\n",
            "1752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ì‹œí€€ìŠ¤ ë°ì´í„°ëŠ” ê° ë¬¸ì¥ì˜ ê¸¸ì´ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "- `BucketIteratorëŠ”` ìœ ì‚¬í•œ ê¸¸ì´ë¥¼ ê°€ì§„ ìƒ˜í”Œë“¤ì„ ê°™ì€ ë°°ì¹˜ì— ë¬¶ì–´ì£¼ëŠ” ì—­í• ì„ í•˜ê¸° ë•Œë¬¸ì—, ê³ ì •ëœ ê¸¸ì´ë¡œ ë§ì¶”ê¸° ìœ„í•œ íŒ¨ë”©ì˜ ì–‘ì„ ìµœì†Œí™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "GmHXb1phBXJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, val_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device\n",
        ")"
      ],
      "metadata": {
        "id": "uazI6xuv8rDH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ì²« ë²ˆì§¸ ë°°ì¹˜ë¥¼ ì¶œë ¥í•œ ê²°ê³¼, [sequence length, batch size]ë¼ëŠ” tensorê°€ ìƒì„±ë©ë‹ˆë‹¤\n",
        "- `sequence length`ëŠ” í•´ë‹¹ ë°°ì¹˜ ë‚´ì—ì„œ ê°€ì¥ ê¸´ ë¬¸ì¥ì˜ ê¸¸ì´ë¥¼ ì˜ë¯¸í•˜ë©°, ì´ë³´ë‹¤ ì§§ì€ ë¬¸ì¥ì€ <pad> tokenìœ¼ë¡œ ì±„ì›Œì§‘ë‹ˆë‹¤.\n",
        "- í¸ì˜ìƒ transposeí•œ ë’¤, ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ ë¬¸ì¥ì˜ í…ì„œë¥¼ ì¶œë ¥í•˜ë©´, íŠ¹ì • ë‹¨ì–´ì— ëŒ€ì‘í•˜ëŠ” ì¸ë±ìŠ¤ê°€ ì¶œë ¥ë˜ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
      ],
      "metadata": {
        "id": "Z154iai8Czsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, batch in enumerate(train_iterator):\n",
        "    src = batch.src\n",
        "    trg = batch.trg\n",
        "\n",
        "    print(f\"ì²« ë²ˆì§¸ ë°°ì¹˜ì˜ text í¬ê¸°: {src.shape}\")\n",
        "    src = src.transpose(1,0)\n",
        "    print(src[0])\n",
        "    print(src[1])\n",
        "\n",
        "    break"
      ],
      "metadata": {
        "id": "3r-eReL8rwm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60942270-1408-40fe-d9b5-86feef5c6529"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì²« ë²ˆì§¸ ë°°ì¹˜ì˜ text í¬ê¸°: torch.Size([27, 128])\n",
            "tensor([   2,    4,    0,    8,  147,   37,   14,   10, 1477,   54,   76,    3,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1], device='cuda:0')\n",
            "tensor([   2,    4,   28, 1931,   59,    0,   44, 5136,  109,  182,  113,    8,\n",
            "           3,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the Seq2Seq with LSTM Model\n",
        "\n",
        "- seq2seq ì´í•´ë¥¼ ìœ„í•œ ê³¼ì œì´ë‹ˆ, ì•„ë˜ë¥¼ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•´ë„ ë¬´ë°©í•©ë‹ˆë‹¤ :)\n",
        "\n",
        "\n",
        "https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice/blob/master/code_practices/Sequence_to_Sequence_with_LSTM_Tutorial.ipynb"
      ],
      "metadata": {
        "id": "51xSGy35XLvG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder"
      ],
      "metadata": {
        "id": "i9WWS97vYnSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, p):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = nn.Dropout(p)\n",
        "\n",
        "        #=========================================#\n",
        "        # ğŸ’¡ì•„ë˜ì¤„ì— embeddingê³¼ multi-layer LSTM ë¶€ë¶„ì„ ì±„ì›Œì£¼ì„¸ìš” (dropout í¬í•¨)\n",
        "        #=========================================#\n",
        "        self.embedding =  nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=p)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = [x length, batch size]\n",
        "        embedding = self.dropout(self.embedding(x))  # embedding = [x length, batch size, emb size]\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(embedding)\n",
        "\n",
        "        # hidden = [n layers, batch size, hid dim]\n",
        "        # cell = [n layer, batch size, hid dim]\n",
        "        # outputs = [src len, batch size, hid dim]\n",
        "\n",
        "        return hidden, cell"
      ],
      "metadata": {
        "id": "GtpU_ZjeYNEZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder"
      ],
      "metadata": {
        "id": "ZrQoLPg-Ype1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, p):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = nn.Dropout(p)\n",
        "\n",
        "        #=========================================#\n",
        "        # ğŸ’¡ì•„ë˜ ì½”ë“œë¥¼ ì±„ì›Œì£¼ê³ , ê°ê° ì–´ë–¤ ì—­í• ì„ í•˜ëŠ”ì§€ ì£¼ì„ìœ¼ë¡œ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”\n",
        "        #\n",
        "        #=========================================#\n",
        "        # Embedding: ì›-í•« ì¸ì½”ë”©ë§ê³  íŠ¹ì • ì°¨ì›ì˜ ì„ë² ë”©, ì¦‰ dense vectorë¡œ ë³€í™˜\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        # LSTM: ì„ë² ë”©ëœ ë²¡í„°ë¥¼ ì…ë ¥ë°›ì•„ hidden stateì™€ cell stateë¥¼ ì²˜ë¦¬\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=p)\n",
        "        # Fully connected layer: LSTMì˜ ì¶œë ¥ì„ vocabulary í¬ê¸°ì— ë§ì¶° ì˜ˆì¸¡ê°’ìœ¼ë¡œ ë³€í™˜\n",
        "        self.fc = nn.Linear(hid_dim, output_dim)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "\n",
        "        # í˜„ì¬ input í˜•íƒœ = [batch size]\n",
        "        # DecoderëŠ” í•œë²ˆì— í•˜ë‚˜ì˜ í† í°ë§Œ ì²˜ë¦¬í•˜ë„ë¡ sequence length = 1ì´ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤\n",
        "        input = input.unsqueeze(0)\n",
        "\n",
        "        embedding = self.dropout(self.embedding(input))\n",
        "\n",
        "        #=========================================#\n",
        "        # ğŸ’¡self.rnn() ê´„í˜¸ ì•ˆ ë¶€ë¶„ì„ ì±„ì›Œì£¼ì„¸ìš”\n",
        "        #=========================================#\n",
        "        output, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
        "\n",
        "        prediction = self.fc(output.squeeze(0))  #prediction = [batch size, output dim]\n",
        "\n",
        "        return prediction, hidden, cell"
      ],
      "metadata": {
        "id": "NOVQfminYknh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seq2Seq"
      ],
      "metadata": {
        "id": "NNsTqRamcfPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "\n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "\n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        hidden, cell = self.encoder(src)\n",
        "\n",
        "        #=========================================#\n",
        "        # ğŸ’¡trgë¥¼ ì‚¬ìš©í•˜ì—¬ decoderì— ì…ë ¥í•  ì²«ë²ˆì§¸ inputì„ ì„¤ì •í•´ì£¼ì„¸ìš”\n",
        "        #=========================================#\n",
        "        input = trg[0, :]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "\n",
        "            outputs[t] = output\n",
        "\n",
        "            # predictionsë“¤ ì¤‘ì— ê°€ì¥ ì˜ ì˜ˆì¸¡ëœ token ì¶”ì¶œ\n",
        "            best_guess = output.argmax(1) # [batch size]\n",
        "\n",
        "            input = trg[t] if random.random() < teacher_forcing_ratio else best_guess\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "Ik28Umx6gAPW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Q. ìœ„ ì½”ë“œì—ì„œëŠ” ë§¤ ì‹œì ë§ˆë‹¤ í™•ë¥ ì´ ê°€ì¥ ë†’ì€ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì„ íƒí•˜ëŠ” Greedy decodingÂ  ë°©ì‹ì´ ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ëŸ° ë°©ë²•ì„ ì±„íƒí•  ê²½ìš° ë°œìƒí•  ìˆ˜ ìˆëŠ” ë¬¸ì œì ì€ ë¬´ì—‡ì¼ì§€ ì‘ì„±í•´ì£¼ì„¸ìš”.**\n",
        "\n",
        "\n",
        "```python\n",
        "\n",
        "# predictionsë“¤ ì¤‘ì— ê°€ì¥ ì˜ ì˜ˆì¸¡ëœ token ì¶”ì¶œ\n",
        "best_guess = output.argmax(1) # [batch size]\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "â¡ï¸ Greedy decodingì€ ë§¤ ì‹œì ë§ˆë‹¤ ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ë‹¨ì–´ë¥¼ ì„ íƒí•˜ëŠ” ë°©ì‹ì´ë‹¤. ì´ ë°©ì‹ì€ ê° ì‹œì ì—ì„œ ìµœì ì˜ ì„ íƒì„ í•˜ì§€ë§Œ, ì „ì²´ ë¬¸ë§¥ì—ì„œëŠ” ê·¸ ì„ íƒì´ ì í•©í•˜ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ì¥ê¸°ì ì¸ ìµœì ì˜ ê²°ê³¼ë¥¼ ë†“ì¹  ìˆ˜ ìˆë‹¤. ì´ë¡œ ì¸í•´ ë¬¸ë²•ì ìœ¼ë¡œ ë¶€ì ì ˆí•˜ê±°ë‚˜ ìì—°ìŠ¤ëŸ½ì§€ ì•Šì€ ë¬¸ì¥ì´ ìƒì„±ë  ê°€ëŠ¥ì„±ì´ ìˆë‹¤.\n"
      ],
      "metadata": {
        "id": "bfKrIZ63jkVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "EHk36-bkh055"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "metadata": {
        "id": "Xj33q4Izh3aB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ëª¨ë¸ ì´ˆê¸° ê°€ì¤‘ì¹˜ ê°’ì€ ë…¼ë¬¸ì˜ ë‚´ìš©ëŒ€ë¡œ U(âˆ’0.08,0.08)ì˜ ì—°ì†ê· ë“±ë¶„í¬ë¡œë¶€í„° ì–»ìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "uoFprkiyh5vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "metadata": {
        "id": "-oLZ0jXyh4zG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b843da7f-8a3c-47d4-e3e6-25aa7be20c44"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "    (embedding): Embedding(7853, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "    (embedding): Embedding(5893, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (fc): Linear(in_features=512, out_features=5893, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# ë’· ë¶€ë¶„ì˜ íŒ¨ë”©(padding)ì— ëŒ€í•´ì„œëŠ” ê°’ ë¬´ì‹œ\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
      ],
      "metadata": {
        "id": "TpKWiiBIF5NA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate"
      ],
      "metadata": {
        "id": "veJrgUHBjRVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(iterator):\n",
        "\n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src, trg)\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "LDfEPQUwFvVG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output = model(src, trg, 0)\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "O0fOgC3jc8K4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "5OCHWUhmGORD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 3\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "metadata": {
        "id": "n0VHYyZLjFO2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b391c811-baad-446a-ac17-2725c5e3a363"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 0m 45s\n",
            "\tTrain Loss: 5.049 | Train PPL: 155.842\n",
            "\t Val. Loss: 5.115 |  Val. PPL: 166.478\n",
            "Epoch: 02 | Time: 0m 44s\n",
            "\tTrain Loss: 4.465 | Train PPL:  86.952\n",
            "\t Val. Loss: 4.706 |  Val. PPL: 110.556\n",
            "Epoch: 03 | Time: 0m 42s\n",
            "\tTrain Loss: 4.143 | Train PPL:  62.999\n",
            "\t Val. Loss: 4.539 |  Val. PPL:  93.557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/tut1-model.pt'))\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "metadata": {
        "id": "QCou2VSKVz64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99bab1d4-08a4-4772-9ef5-c56c82347010"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-806c4c390395>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('/content/tut1-model.pt'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Test Loss: 5.133 | Test PPL: 169.522 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JsiX9L55ddft"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}