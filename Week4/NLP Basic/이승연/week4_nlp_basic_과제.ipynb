{"cells":[{"cell_type":"markdown","metadata":{"id":"9WW4t3iCYKuy"},"source":["## ê³¼ì œ 1\n","\n","### **Q. ê° ëª¨ë¸ì´ ì¶©ì¡±í•˜ëŠ” ì†ì„±ì— ëŒ€í•´ ì•„ë˜ í‘œë¥¼ O/Xë¡œ ì±„ì›Œì£¼ì„¸ìš”.**\n","\n","ğŸ“5ë²ˆì§¸ ì†ì„±ì€ **LSTM ê¸°ì¤€ìœ¼ë¡œ** O/X ì—¬ë¶€ íŒë‹¨í•´ì£¼ì„¸ìš” ! <br>\n","ğŸ“ì •ë‹µì€ ê³¼ì œ ë§ˆê° ë‹¤ìŒë‚  (9ì›” 11ì¼ ìˆ˜ìš”ì¼)ì— **ë…¸ì…˜-ì •ê·œì„¸ì…˜-NLP basic**ì— ì—…ë¡œë“œ ì˜ˆì •\n","\n","\n","> #### **ì†ì„± ì„¤ëª…**\n","1. Order matters : ì…ë ¥ ì‹œí€€ìŠ¤ì˜ ìˆœì„œ ì¤‘ìš” ì—¬ë¶€\n","2. Variable Length : ê³ ì •ëœ ê¸¸ì´ê°€ ì•„ë‹Œ ë‹¤ì–‘í•œ ê¸¸ì´ì˜ ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ”ì§€ ì—¬ë¶€\n","3. Differentiable : ë¯¸ë¶„ê°€ëŠ¥\n","4. Pairwise encoding : ë‘ ë‹¨ì–´ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ í‘œí˜„\n","5. Preserves long-term : ì¥ê¸°ì ì¸ ì˜ì¡´ì„±\n"]},{"cell_type":"markdown","metadata":{"id":"paUeOH0OYNU0"},"source":["|               | N-gram | RNN   | LSTM  | Transformer |\n","|:-------------:|:------:|:-----:|:-----:|:-----------:|\n","| Order matters |   O    |  O  |  O   | O           |\n","| Variable length |   X  |  O  |  O   | O           |\n","| Differentiable |   X   |  O  |  O   | O           |\n","| Pairwise encoding |  X |  X  |  X   | O           |\n","| Preserves long-term | X|  X  |  O   | O           |\n"]},{"cell_type":"markdown","metadata":{"id":"14MthA8WYQev"},"source":["## ê³¼ì œ 2\n","\n","\n","### ëª©í‘œ : ë…ì¼ì–´ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ëª¨ë¸ ë§Œë“¤ê¸°\n","ë…ì¼ì–´ ë¬¸ì¥ì„ ì…ë ¥í•˜ë©´ ì˜ì–´ë¡œ ë²ˆì—­í•´ì£¼ëŠ” ëª¨ë¸ì„ seq2seqë¡œ êµ¬í˜„í•´ë´…ì‹œë‹¤"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"7PbwGzED6TIV"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torchtext==0.6.0\n","  Using cached torchtext-0.6.0-py3-none-any.whl.metadata (6.3 kB)\n","Collecting tqdm (from torchtext==0.6.0)\n","  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n","Collecting requests (from torchtext==0.6.0)\n","  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n","Collecting torch (from torchtext==0.6.0)\n","  Downloading torch-2.4.1-cp38-cp38-win_amd64.whl.metadata (27 kB)\n","Requirement already satisfied: numpy in c:\\users\\win2d\\anaconda3\\envs\\myenv38\\lib\\site-packages (from torchtext==0.6.0) (1.24.4)\n","Requirement already satisfied: six in c:\\users\\win2d\\anaconda3\\envs\\myenv38\\lib\\site-packages (from torchtext==0.6.0) (1.16.0)\n","Collecting sentencepiece (from torchtext==0.6.0)\n","  Downloading sentencepiece-0.2.0-cp38-cp38-win_amd64.whl.metadata (8.3 kB)\n","Collecting charset-normalizer<4,>=2 (from requests->torchtext==0.6.0)\n","  Downloading charset_normalizer-3.3.2-cp38-cp38-win_amd64.whl.metadata (34 kB)\n","Collecting idna<4,>=2.5 (from requests->torchtext==0.6.0)\n","  Using cached idna-3.8-py3-none-any.whl.metadata (9.9 kB)\n","Collecting urllib3<3,>=1.21.1 (from requests->torchtext==0.6.0)\n","  Using cached urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n","Collecting certifi>=2017.4.17 (from requests->torchtext==0.6.0)\n","  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n","Collecting filelock (from torch->torchtext==0.6.0)\n","  Using cached filelock-3.16.0-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\win2d\\anaconda3\\envs\\myenv38\\lib\\site-packages (from torch->torchtext==0.6.0) (4.12.2)\n","Collecting sympy (from torch->torchtext==0.6.0)\n","  Using cached sympy-1.13.2-py3-none-any.whl.metadata (12 kB)\n","Collecting networkx (from torch->torchtext==0.6.0)\n","  Downloading networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\n","Requirement already satisfied: jinja2 in c:\\users\\win2d\\anaconda3\\envs\\myenv38\\lib\\site-packages (from torch->torchtext==0.6.0) (3.1.4)\n","Collecting fsspec (from torch->torchtext==0.6.0)\n","  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: colorama in c:\\users\\win2d\\anaconda3\\envs\\myenv38\\lib\\site-packages (from tqdm->torchtext==0.6.0) (0.4.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\win2d\\anaconda3\\envs\\myenv38\\lib\\site-packages (from jinja2->torch->torchtext==0.6.0) (2.1.5)\n","Collecting mpmath<1.4,>=1.1.0 (from sympy->torch->torchtext==0.6.0)\n","  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n","Using cached torchtext-0.6.0-py3-none-any.whl (64 kB)\n","Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n","Downloading sentencepiece-0.2.0-cp38-cp38-win_amd64.whl (991 kB)\n","   ---------------------------------------- 0.0/991.7 kB ? eta -:--:--\n","   ------------------------------- -------- 786.4/991.7 kB 4.8 MB/s eta 0:00:01\n","   ---------------------------------------- 991.7/991.7 kB 5.2 MB/s eta 0:00:00\n","Downloading torch-2.4.1-cp38-cp38-win_amd64.whl (199.4 MB)\n","   ---------------------------------------- 0.0/199.4 MB ? eta -:--:--\n","   ---------------------------------------- 0.8/199.4 MB 4.8 MB/s eta 0:00:42\n","   ---------------------------------------- 1.6/199.4 MB 4.2 MB/s eta 0:00:48\n","    --------------------------------------- 2.6/199.4 MB 4.4 MB/s eta 0:00:45\n","    --------------------------------------- 3.7/199.4 MB 4.4 MB/s eta 0:00:45\n","    --------------------------------------- 4.5/199.4 MB 4.4 MB/s eta 0:00:45\n","   - -------------------------------------- 5.2/199.4 MB 4.3 MB/s eta 0:00:46\n","   - -------------------------------------- 6.3/199.4 MB 4.3 MB/s eta 0:00:46\n","   - -------------------------------------- 7.3/199.4 MB 4.3 MB/s eta 0:00:45\n","   - -------------------------------------- 8.1/199.4 MB 4.3 MB/s eta 0:00:45\n","   - -------------------------------------- 8.9/199.4 MB 4.3 MB/s eta 0:00:45\n","   -- ------------------------------------- 10.2/199.4 MB 4.4 MB/s eta 0:00:44\n","   -- ------------------------------------- 11.3/199.4 MB 4.5 MB/s eta 0:00:42\n","   -- ------------------------------------- 12.6/199.4 MB 4.6 MB/s eta 0:00:41\n","   -- ------------------------------------- 13.6/199.4 MB 4.6 MB/s eta 0:00:41\n","   -- ------------------------------------- 14.9/199.4 MB 4.7 MB/s eta 0:00:40\n","   --- ------------------------------------ 16.0/199.4 MB 4.8 MB/s eta 0:00:39\n","   --- ------------------------------------ 16.8/199.4 MB 4.7 MB/s eta 0:00:39\n","   --- ------------------------------------ 17.6/199.4 MB 4.6 MB/s eta 0:00:40\n","   --- ------------------------------------ 18.6/199.4 MB 4.6 MB/s eta 0:00:40\n","   --- ------------------------------------ 19.4/199.4 MB 4.6 MB/s eta 0:00:39\n","   ---- ----------------------------------- 20.7/199.4 MB 4.7 MB/s eta 0:00:39\n","   ---- ----------------------------------- 22.0/199.4 MB 4.7 MB/s eta 0:00:38\n","   ---- ----------------------------------- 22.8/199.4 MB 4.7 MB/s eta 0:00:38\n","   ---- ----------------------------------- 23.9/199.4 MB 4.8 MB/s eta 0:00:37\n","   ----- ---------------------------------- 25.2/199.4 MB 4.8 MB/s eta 0:00:37\n","   ----- ---------------------------------- 26.2/199.4 MB 4.8 MB/s eta 0:00:36\n","   ----- ---------------------------------- 27.8/199.4 MB 4.9 MB/s eta 0:00:36\n","   ----- ---------------------------------- 29.1/199.4 MB 4.9 MB/s eta 0:00:35\n","   ------ --------------------------------- 30.1/199.4 MB 5.0 MB/s eta 0:00:35\n","   ------ --------------------------------- 31.5/199.4 MB 5.0 MB/s eta 0:00:34\n","   ------ --------------------------------- 32.8/199.4 MB 5.0 MB/s eta 0:00:34\n","   ------ --------------------------------- 34.1/199.4 MB 5.1 MB/s eta 0:00:33\n","   ------- -------------------------------- 35.1/199.4 MB 5.1 MB/s eta 0:00:33\n","   ------- -------------------------------- 37.0/199.4 MB 5.2 MB/s eta 0:00:32\n","   ------- -------------------------------- 38.3/199.4 MB 5.2 MB/s eta 0:00:32\n","   ------- -------------------------------- 39.3/199.4 MB 5.2 MB/s eta 0:00:31\n","   -------- ------------------------------- 40.1/199.4 MB 5.2 MB/s eta 0:00:31\n","   -------- ------------------------------- 40.9/199.4 MB 5.1 MB/s eta 0:00:31\n","   -------- ------------------------------- 41.9/199.4 MB 5.1 MB/s eta 0:00:31\n","   -------- ------------------------------- 43.0/199.4 MB 5.1 MB/s eta 0:00:31\n","   -------- ------------------------------- 44.3/199.4 MB 5.1 MB/s eta 0:00:31\n","   --------- ------------------------------ 45.4/199.4 MB 5.1 MB/s eta 0:00:30\n","   --------- ------------------------------ 45.9/199.4 MB 5.1 MB/s eta 0:00:31\n","   --------- ------------------------------ 46.7/199.4 MB 5.0 MB/s eta 0:00:31\n","   --------- ------------------------------ 47.2/199.4 MB 5.0 MB/s eta 0:00:31\n","   --------- ------------------------------ 48.0/199.4 MB 5.0 MB/s eta 0:00:31\n","   --------- ------------------------------ 49.0/199.4 MB 5.0 MB/s eta 0:00:31\n","   ---------- ----------------------------- 50.1/199.4 MB 5.0 MB/s eta 0:00:31\n","   ---------- ----------------------------- 50.9/199.4 MB 5.0 MB/s eta 0:00:30\n","   ---------- ----------------------------- 51.9/199.4 MB 5.0 MB/s eta 0:00:30\n","   ---------- ----------------------------- 53.0/199.4 MB 5.0 MB/s eta 0:00:30\n","   ---------- ----------------------------- 53.7/199.4 MB 4.9 MB/s eta 0:00:30\n","   ---------- ----------------------------- 54.8/199.4 MB 4.9 MB/s eta 0:00:30\n","   ----------- ---------------------------- 55.6/199.4 MB 4.9 MB/s eta 0:00:30\n","   ----------- ---------------------------- 56.6/199.4 MB 4.9 MB/s eta 0:00:29\n","   ----------- ---------------------------- 57.1/199.4 MB 4.9 MB/s eta 0:00:30\n","   ----------- ---------------------------- 58.2/199.4 MB 4.9 MB/s eta 0:00:29\n","   ----------- ---------------------------- 59.2/199.4 MB 4.9 MB/s eta 0:00:29\n","   ------------ --------------------------- 60.3/199.4 MB 4.9 MB/s eta 0:00:29\n","   ------------ --------------------------- 61.3/199.4 MB 4.9 MB/s eta 0:00:29\n","   ------------ --------------------------- 62.4/199.4 MB 4.9 MB/s eta 0:00:28\n","   ------------ --------------------------- 63.2/199.4 MB 4.9 MB/s eta 0:00:28\n","   ------------ --------------------------- 64.0/199.4 MB 4.9 MB/s eta 0:00:28\n","   ------------- -------------------------- 65.0/199.4 MB 4.9 MB/s eta 0:00:28\n","   ------------- -------------------------- 65.8/199.4 MB 4.8 MB/s eta 0:00:28\n","   ------------- -------------------------- 67.1/199.4 MB 4.9 MB/s eta 0:00:28\n","   ------------- -------------------------- 67.9/199.4 MB 4.9 MB/s eta 0:00:28\n","   ------------- -------------------------- 68.7/199.4 MB 4.8 MB/s eta 0:00:28\n","   ------------- -------------------------- 69.5/199.4 MB 4.8 MB/s eta 0:00:27\n","   -------------- ------------------------- 70.8/199.4 MB 4.8 MB/s eta 0:00:27\n","   -------------- ------------------------- 71.8/199.4 MB 4.8 MB/s eta 0:00:27\n","   -------------- ------------------------- 72.9/199.4 MB 4.8 MB/s eta 0:00:27\n","   -------------- ------------------------- 73.9/199.4 MB 4.8 MB/s eta 0:00:26\n","   --------------- ------------------------ 75.0/199.4 MB 4.8 MB/s eta 0:00:26\n","   --------------- ------------------------ 75.8/199.4 MB 4.8 MB/s eta 0:00:26\n","   --------------- ------------------------ 76.8/199.4 MB 4.8 MB/s eta 0:00:26\n","   --------------- ------------------------ 78.1/199.4 MB 4.9 MB/s eta 0:00:26\n","   --------------- ------------------------ 79.4/199.4 MB 4.9 MB/s eta 0:00:25\n","   ---------------- ----------------------- 80.7/199.4 MB 4.9 MB/s eta 0:00:25\n","   ---------------- ----------------------- 82.1/199.4 MB 4.9 MB/s eta 0:00:24\n","   ---------------- ----------------------- 83.4/199.4 MB 4.9 MB/s eta 0:00:24\n","   ---------------- ----------------------- 84.4/199.4 MB 4.9 MB/s eta 0:00:24\n","   ----------------- ---------------------- 85.7/199.4 MB 4.9 MB/s eta 0:00:24\n","   ----------------- ---------------------- 87.0/199.4 MB 4.9 MB/s eta 0:00:23\n","   ----------------- ---------------------- 88.1/199.4 MB 4.9 MB/s eta 0:00:23\n","   ----------------- ---------------------- 88.9/199.4 MB 4.9 MB/s eta 0:00:23\n","   ------------------ --------------------- 90.4/199.4 MB 5.0 MB/s eta 0:00:22\n","   ------------------ --------------------- 91.2/199.4 MB 5.0 MB/s eta 0:00:22\n","   ------------------ --------------------- 92.5/199.4 MB 5.0 MB/s eta 0:00:22\n","   ------------------ --------------------- 93.8/199.4 MB 5.0 MB/s eta 0:00:22\n","   ------------------- -------------------- 95.2/199.4 MB 5.0 MB/s eta 0:00:21\n","   ------------------- -------------------- 96.2/199.4 MB 5.0 MB/s eta 0:00:21\n","   ------------------- -------------------- 97.8/199.4 MB 5.0 MB/s eta 0:00:21\n","   ------------------- -------------------- 98.8/199.4 MB 5.0 MB/s eta 0:00:21\n","   -------------------- ------------------- 99.9/199.4 MB 5.0 MB/s eta 0:00:20\n","   -------------------- ------------------- 100.7/199.4 MB 5.0 MB/s eta 0:00:20\n","   -------------------- ------------------- 102.0/199.4 MB 5.0 MB/s eta 0:00:20\n","   -------------------- ------------------- 103.3/199.4 MB 5.0 MB/s eta 0:00:20\n","   -------------------- ------------------- 104.6/199.4 MB 5.0 MB/s eta 0:00:19\n","   --------------------- ------------------ 105.9/199.4 MB 5.1 MB/s eta 0:00:19\n","   --------------------- ------------------ 107.0/199.4 MB 5.0 MB/s eta 0:00:19\n","   --------------------- ------------------ 108.0/199.4 MB 5.0 MB/s eta 0:00:19\n","   --------------------- ------------------ 109.1/199.4 MB 5.0 MB/s eta 0:00:18\n","   ---------------------- ----------------- 110.1/199.4 MB 5.0 MB/s eta 0:00:18\n","   ---------------------- ----------------- 111.4/199.4 MB 5.1 MB/s eta 0:00:18\n","   ---------------------- ----------------- 112.7/199.4 MB 5.1 MB/s eta 0:00:18\n","   ---------------------- ----------------- 114.0/199.4 MB 5.1 MB/s eta 0:00:17\n","   ----------------------- ---------------- 115.1/199.4 MB 5.1 MB/s eta 0:00:17\n","   ----------------------- ---------------- 116.4/199.4 MB 5.1 MB/s eta 0:00:17\n","   ----------------------- ---------------- 117.2/199.4 MB 5.1 MB/s eta 0:00:17\n","   ----------------------- ---------------- 118.2/199.4 MB 5.1 MB/s eta 0:00:17\n","   ----------------------- ---------------- 119.3/199.4 MB 5.1 MB/s eta 0:00:16\n","   ------------------------ --------------- 120.1/199.4 MB 5.1 MB/s eta 0:00:16\n","   ------------------------ --------------- 120.8/199.4 MB 5.1 MB/s eta 0:00:16\n","   ------------------------ --------------- 121.9/199.4 MB 5.0 MB/s eta 0:00:16\n","   ------------------------ --------------- 122.9/199.4 MB 5.0 MB/s eta 0:00:16\n","   ------------------------ --------------- 124.3/199.4 MB 5.1 MB/s eta 0:00:15\n","   ------------------------- -------------- 125.6/199.4 MB 5.1 MB/s eta 0:00:15\n","   ------------------------- -------------- 126.9/199.4 MB 5.1 MB/s eta 0:00:15\n","   ------------------------- -------------- 127.9/199.4 MB 5.1 MB/s eta 0:00:15\n","   ------------------------- -------------- 129.0/199.4 MB 5.1 MB/s eta 0:00:14\n","   -------------------------- ------------- 130.3/199.4 MB 5.1 MB/s eta 0:00:14\n","   -------------------------- ------------- 131.6/199.4 MB 5.1 MB/s eta 0:00:14\n","   -------------------------- ------------- 132.9/199.4 MB 5.1 MB/s eta 0:00:14\n","   -------------------------- ------------- 134.2/199.4 MB 5.1 MB/s eta 0:00:13\n","   --------------------------- ------------ 135.5/199.4 MB 5.1 MB/s eta 0:00:13\n","   --------------------------- ------------ 136.3/199.4 MB 5.1 MB/s eta 0:00:13\n","   --------------------------- ------------ 137.4/199.4 MB 5.1 MB/s eta 0:00:13\n","   --------------------------- ------------ 138.4/199.4 MB 5.1 MB/s eta 0:00:12\n","   --------------------------- ------------ 139.5/199.4 MB 5.1 MB/s eta 0:00:12\n","   ---------------------------- ----------- 140.8/199.4 MB 5.1 MB/s eta 0:00:12\n","   ---------------------------- ----------- 141.6/199.4 MB 5.1 MB/s eta 0:00:12\n","   ---------------------------- ----------- 142.6/199.4 MB 5.1 MB/s eta 0:00:12\n","   ---------------------------- ----------- 143.9/199.4 MB 5.1 MB/s eta 0:00:11\n","   ----------------------------- ---------- 145.0/199.4 MB 5.1 MB/s eta 0:00:11\n","   ----------------------------- ---------- 146.0/199.4 MB 5.1 MB/s eta 0:00:11\n","   ----------------------------- ---------- 147.1/199.4 MB 5.1 MB/s eta 0:00:11\n","   ----------------------------- ---------- 148.1/199.4 MB 5.1 MB/s eta 0:00:11\n","   ----------------------------- ---------- 148.9/199.4 MB 5.1 MB/s eta 0:00:10\n","   ------------------------------ --------- 149.9/199.4 MB 5.1 MB/s eta 0:00:10\n","   ------------------------------ --------- 150.7/199.4 MB 5.1 MB/s eta 0:00:10\n","   ------------------------------ --------- 151.5/199.4 MB 5.1 MB/s eta 0:00:10\n","   ------------------------------ --------- 152.6/199.4 MB 5.1 MB/s eta 0:00:10\n","   ------------------------------ --------- 153.4/199.4 MB 5.1 MB/s eta 0:00:10\n","   ------------------------------ --------- 154.1/199.4 MB 5.1 MB/s eta 0:00:09\n","   ------------------------------- -------- 154.7/199.4 MB 5.1 MB/s eta 0:00:09\n","   ------------------------------- -------- 155.7/199.4 MB 5.1 MB/s eta 0:00:09\n","   ------------------------------- -------- 156.2/199.4 MB 5.1 MB/s eta 0:00:09\n","   ------------------------------- -------- 157.0/199.4 MB 5.0 MB/s eta 0:00:09\n","   ------------------------------- -------- 157.3/199.4 MB 5.0 MB/s eta 0:00:09\n","   ------------------------------- -------- 158.1/199.4 MB 5.0 MB/s eta 0:00:09\n","   ------------------------------- -------- 159.1/199.4 MB 5.0 MB/s eta 0:00:09\n","   -------------------------------- ------- 159.9/199.4 MB 5.0 MB/s eta 0:00:08\n","   -------------------------------- ------- 160.7/199.4 MB 5.0 MB/s eta 0:00:08\n","   -------------------------------- ------- 161.7/199.4 MB 5.0 MB/s eta 0:00:08\n","   -------------------------------- ------- 163.1/199.4 MB 5.0 MB/s eta 0:00:08\n","   -------------------------------- ------- 164.4/199.4 MB 5.0 MB/s eta 0:00:08\n","   --------------------------------- ------ 165.4/199.4 MB 5.0 MB/s eta 0:00:07\n","   --------------------------------- ------ 165.7/199.4 MB 5.0 MB/s eta 0:00:07\n","   --------------------------------- ------ 166.7/199.4 MB 5.0 MB/s eta 0:00:07\n","   --------------------------------- ------ 167.5/199.4 MB 5.0 MB/s eta 0:00:07\n","   --------------------------------- ------ 168.0/199.4 MB 5.0 MB/s eta 0:00:07\n","   --------------------------------- ------ 168.6/199.4 MB 5.0 MB/s eta 0:00:07\n","   ---------------------------------- ----- 169.6/199.4 MB 4.9 MB/s eta 0:00:07\n","   ---------------------------------- ----- 170.7/199.4 MB 4.9 MB/s eta 0:00:06\n","   ---------------------------------- ----- 171.4/199.4 MB 4.9 MB/s eta 0:00:06\n","   ---------------------------------- ----- 172.2/199.4 MB 4.9 MB/s eta 0:00:06\n","   ---------------------------------- ----- 173.0/199.4 MB 4.9 MB/s eta 0:00:06\n","   ---------------------------------- ----- 173.5/199.4 MB 4.9 MB/s eta 0:00:06\n","   ---------------------------------- ----- 174.3/199.4 MB 4.9 MB/s eta 0:00:06\n","   ----------------------------------- ---- 175.4/199.4 MB 4.8 MB/s eta 0:00:05\n","   ----------------------------------- ---- 175.9/199.4 MB 4.8 MB/s eta 0:00:05\n","   ----------------------------------- ---- 176.9/199.4 MB 4.8 MB/s eta 0:00:05\n","   ----------------------------------- ---- 177.5/199.4 MB 4.8 MB/s eta 0:00:05\n","   ----------------------------------- ---- 178.0/199.4 MB 4.8 MB/s eta 0:00:05\n","   ----------------------------------- ---- 179.0/199.4 MB 4.8 MB/s eta 0:00:05\n","   ------------------------------------ --- 179.8/199.4 MB 4.7 MB/s eta 0:00:05\n","   ------------------------------------ --- 180.6/199.4 MB 4.7 MB/s eta 0:00:04\n","   ------------------------------------ --- 181.4/199.4 MB 4.7 MB/s eta 0:00:04\n","   ------------------------------------ --- 182.5/199.4 MB 4.7 MB/s eta 0:00:04\n","   ------------------------------------ --- 183.5/199.4 MB 4.7 MB/s eta 0:00:04\n","   ------------------------------------- -- 184.5/199.4 MB 4.7 MB/s eta 0:00:04\n","   ------------------------------------- -- 185.3/199.4 MB 4.7 MB/s eta 0:00:03\n","   ------------------------------------- -- 186.1/199.4 MB 4.7 MB/s eta 0:00:03\n","   ------------------------------------- -- 186.6/199.4 MB 4.7 MB/s eta 0:00:03\n","   ------------------------------------- -- 187.7/199.4 MB 4.7 MB/s eta 0:00:03\n","   ------------------------------------- -- 188.2/199.4 MB 4.7 MB/s eta 0:00:03\n","   ------------------------------------- -- 189.0/199.4 MB 4.7 MB/s eta 0:00:03\n","   -------------------------------------- - 189.5/199.4 MB 4.7 MB/s eta 0:00:03\n","   -------------------------------------- - 190.3/199.4 MB 4.7 MB/s eta 0:00:02\n","   -------------------------------------- - 190.8/199.4 MB 4.7 MB/s eta 0:00:02\n","   -------------------------------------- - 191.6/199.4 MB 4.7 MB/s eta 0:00:02\n","   -------------------------------------- - 192.4/199.4 MB 4.6 MB/s eta 0:00:02\n","   -------------------------------------- - 193.2/199.4 MB 4.7 MB/s eta 0:00:02\n","   -------------------------------------- - 193.7/199.4 MB 4.6 MB/s eta 0:00:02\n","   ---------------------------------------  194.5/199.4 MB 4.6 MB/s eta 0:00:02\n","   ---------------------------------------  195.3/199.4 MB 4.6 MB/s eta 0:00:01\n","   ---------------------------------------  196.3/199.4 MB 4.6 MB/s eta 0:00:01\n","   ---------------------------------------  197.1/199.4 MB 4.6 MB/s eta 0:00:01\n","   ---------------------------------------  197.9/199.4 MB 4.6 MB/s eta 0:00:01\n","   ---------------------------------------  198.4/199.4 MB 4.6 MB/s eta 0:00:01\n","   ---------------------------------------  199.2/199.4 MB 4.6 MB/s eta 0:00:01\n","   ---------------------------------------  199.2/199.4 MB 4.6 MB/s eta 0:00:01\n","   ---------------------------------------- 199.4/199.4 MB 4.5 MB/s eta 0:00:00\n","Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n","Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n","Downloading charset_normalizer-3.3.2-cp38-cp38-win_amd64.whl (99 kB)\n","Using cached idna-3.8-py3-none-any.whl (66 kB)\n","Using cached urllib3-2.2.2-py3-none-any.whl (121 kB)\n","Using cached filelock-3.16.0-py3-none-any.whl (16 kB)\n","Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n","   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n","   ---------- ----------------------------- 0.5/2.1 MB 2.8 MB/s eta 0:00:01\n","   ------------------------- -------------- 1.3/2.1 MB 3.2 MB/s eta 0:00:01\n","   ------------------------------ --------- 1.6/2.1 MB 3.2 MB/s eta 0:00:01\n","   ---------------------------------------- 2.1/2.1 MB 2.8 MB/s eta 0:00:00\n","Using cached sympy-1.13.2-py3-none-any.whl (6.2 MB)\n","Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n","Installing collected packages: sentencepiece, mpmath, urllib3, tqdm, sympy, networkx, idna, fsspec, filelock, charset-normalizer, certifi, torch, requests, torchtext\n","Successfully installed certifi-2024.8.30 charset-normalizer-3.3.2 filelock-3.16.0 fsspec-2024.9.0 idna-3.8 mpmath-1.3.0 networkx-3.1 requests-2.32.3 sentencepiece-0.2.0 sympy-1.13.2 torch-2.4.1 torchtext-0.6.0 tqdm-4.66.5 urllib3-2.2.2\n"]}],"source":["!pip install -U torchtext==0.6.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DPKSSHzQ6Uoh"},"outputs":[],"source":["!python -m spacy download en\n","!python -m spacy download de"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MJWiAS2yWutF"},"outputs":[],"source":["import numpy as np\n","import random\n","import time\n","import math\n","import spacy\n","from torchtext.datasets import TranslationDataset\n","from torchtext.data import Field, BucketIterator\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim"]},{"cell_type":"markdown","metadata":{"id":"uHmIKputmJfU"},"source":["### Tokenizers\n","\n","- ë¬¸ì¥ì˜ í† í°í™”, íƒœê¹… ë“±ì˜ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ `spaCy` ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì˜ì–´ì™€ ë…ì¼ì–´ ì „ì²˜ë¦¬ ëª¨ë“ˆì„ ì„¤ì¹˜í•´ì¤ë‹ˆë‹¤.\n","- ë‘ ì–¸ì–´ì˜ ë¬¸ì¥ì´ ì£¼ì–´ì¡Œê¸° ë•Œë¬¸ì— ì˜ì–´ì™€ ë…ì¼ì–´ ê°ê°ì— ëŒ€í•´ ì „ì²˜ë¦¬í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l7ZtI5IXm7EG"},"outputs":[],"source":["spacy_de = spacy.load('de_core_news_sm')\n","spacy_en = spacy.load('en_core_web_sm')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"co1TC8yv7yrX"},"outputs":[],"source":["# ì˜ˆì‹œ\n","result = spacy_en.tokenizer(\"I am a student.\")\n","\n","for i, token in enumerate(result):\n","    print(f\"ì¸ë±ìŠ¤ {i}: {token.text}\")"]},{"cell_type":"markdown","metadata":{"id":"lEGmP9Uk8gQG"},"source":["í•„ë“œ(field) ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ ë°ì´í„°ì…‹ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì „ì²˜ë¦¬ ë‚´ìš©ì„ ëª…ì‹œí•´ì¤ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uMjoI1XE7tGF"},"outputs":[],"source":["#===================================================\n","# ğŸ’¡ í† í°í™” ê²°ê³¼ê°€ listë¡œ ë°˜í™˜ë  ìˆ˜ ìˆë„ë¡ return ê²°ê³¼ê°’ì„ ì±„ì›Œì£¼ì„¸ìš”\n","# seq2sxeq ë…¼ë¬¸ì— ì˜í•˜ë©´, input ë‹¨ì–´ì˜ ìˆœì„œë¥¼ ë°”ê¾¸ë©´ ìµœì í™”ê°€ ë” ì‰¬ì›Œì ¸ ì„±ëŠ¥ì´ ì¢‹ì•„ì§„ë‹¤ê³  í•©ë‹ˆë‹¤.\n","# ğŸ’¡ ë…ì¼ì–´ í† í°í™” ê²°ê³¼ê°€ ì—­ìˆœìœ¼ë¡œ returnë  ìˆ˜ ìˆë„ë¡ ë°˜ì˜í•´ì£¼ì„¸ìš”!\n","#===================================================\n","def tokenize_de(text):\n","    tokenizer = get_tokenizer(\"spacy\", language=\"de_core_news_sm\")  \n","    return tokenizer(text)[::-1] \n","\n","def tokenize_en(text):\n","    tokenizer = get_tokenizer(\"spacy\", language=\"en_core_web_sm\")  \n","    return tokenizer(text) "]},{"cell_type":"markdown","metadata":{"id":"z3wGw1nPnpMd"},"source":["í•„ë“œ(field) ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ ë°ì´í„°ì…‹ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì „ì²˜ë¦¬ ë‚´ìš©ì„ ëª…ì‹œí•´ì¤ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ubKI59GPpQ1f"},"outputs":[],"source":["# ë…ì¼ì–´\n","SRC = Field(tokenize= tokenize_de, init_token = '<sos>', eos_token = '<eos>', lower = True)\n","# ì˜ì–´\n","TRG = Field(tokenize= tokenize_en, init_token = '<sos>', eos_token = '<eos>', lower = True)"]},{"cell_type":"markdown","metadata":{"id":"0_ccI6_-8hR3"},"source":["### ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n","\n","ëŒ€í‘œì ì¸ ì˜ì–´-ë…ì–´ ë²ˆì—­ ë°ì´í„°ì…‹ Multi30kì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mLA5kXAAf2uw"},"outputs":[],"source":["!git clone https://github.com/multi30k/dataset.git\n","\n","# ì••ì¶•í•´ì œ\n","!gunzip /content/dataset/data/task1/raw/train.de.gz\n","!gunzip /content/dataset/data/task1/raw/train.en.gz\n","!gunzip /content/dataset/data/task1/raw/val.de.gz\n","!gunzip /content/dataset/data/task1/raw/val.en.gz\n","!gunzip /content/dataset/data/task1/raw/test_2018_flickr.de.gz\n","!gunzip /content/dataset/data/task1/raw/test_2018_flickr.en.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M0JchGVU91Q5"},"outputs":[],"source":["data_path = '/content/dataset/data/task1/raw/'\n","\n","train_data = TranslationDataset(path=data_path, exts=('train.de', 'train.en'), fields=(SRC, TRG) )\n","val_data = TranslationDataset(path=data_path, exts=('val.de', 'val.en'), fields=(SRC, TRG) )\n","test_data = TranslationDataset(path=data_path, exts=('test_2018_flickr.de', 'test_2018_flickr.en'), fields=(SRC, TRG) )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1724602161494,"user":{"displayName":"ì°¨ë¯¼ì¬","userId":"05174396098945723154"},"user_tz":-540},"id":"qxLylN1y-urW","outputId":"62447416-c1f5-48c5-dec7-4c438c67a7f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["í•™ìŠµ ë°ì´í„°ì…‹(training dataset) í¬ê¸°: 29000ê°œ\n","í‰ê°€ ë°ì´í„°ì…‹(validation dataset) í¬ê¸°: 1014ê°œ\n","í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹(testing dataset) í¬ê¸°: 1071ê°œ\n"]}],"source":["print(f\"í•™ìŠµ ë°ì´í„°ì…‹(training dataset) í¬ê¸°: {len(train_data.examples)}ê°œ\")\n","print(f\"í‰ê°€ ë°ì´í„°ì…‹(validation dataset) í¬ê¸°: {len(val_data.examples)}ê°œ\")\n","print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹(testing dataset) í¬ê¸°: {len(test_data.examples)}ê°œ\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":377,"status":"ok","timestamp":1724602163967,"user":{"displayName":"ì°¨ë¯¼ì¬","userId":"05174396098945723154"},"user_tz":-540},"id":"Rpt6l_Xd_AQX","outputId":"f8d29c4a-bef3-4d61-8175-fc08ca298369"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'src': ['.', 'bÃ¼sche', 'vieler', 'nÃ¤he', 'der', 'in', 'freien', 'im', 'sind', 'mÃ¤nner', 'weiÃŸe', 'junge', 'zwei'], 'trg': ['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']}\n","{'src': ['.', 'antriebsradsystem', 'ein', 'bedienen', 'schutzhelmen', 'mit', 'mÃ¤nner', 'mehrere'], 'trg': ['several', 'men', 'in', 'hard', 'hats', 'are', 'operating', 'a', 'giant', 'pulley', 'system', '.']}\n"]}],"source":["print(vars(train_data.examples[0]))\n","print(vars(train_data.examples[1]))"]},{"cell_type":"markdown","metadata":{"id":"uNoigj40AD_0"},"source":["- `build_vocab`í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ ì˜ì–´ì™€ ë…ì¼ì–´ì˜ ë‹¨ì–´ ì‚¬ì „ì„ ìƒì„±í•´ì¤ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê° tokenì´ indexingë©ë‹ˆë‹¤\n","- ë‹¨, vocabularyëŠ” í›ˆë ¨ ë°ì´í„°ì…‹ì— ëŒ€í•´ì„œë§Œ ë§Œë“¤ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤.\n","- `min_freq`ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì†Œ 2ë²ˆ ì´ìƒ ë‚˜ì˜¤ëŠ” ë‹¨ì–´ë“¤ë§Œ ì‚¬ì „ì— í¬í•¨ë˜ë„ë¡ í•©ë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TfK-pAr_ApLP"},"outputs":[],"source":["SRC.build_vocab(train_data, min_freq = 2)\n","TRG.build_vocab(train_data, min_freq = 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KyaA5P0Mrqaa"},"outputs":[],"source":["print(TRG.vocab.stoi[\"abcabc\"]) # ì—†ëŠ” ë‹¨ì–´: 0\n","print(TRG.vocab.stoi[TRG.pad_token]) # íŒ¨ë”©(padding): 1\n","print(TRG.vocab.stoi[\"\"]) # : 0\n","print(TRG.vocab.stoi[\"\"]) # : 0\n","print(TRG.vocab.stoi[\"hello\"])\n","print(TRG.vocab.stoi[\"world\"])"]},{"cell_type":"markdown","metadata":{"id":"GmHXb1phBXJN"},"source":["- ì‹œí€€ìŠ¤ ë°ì´í„°ëŠ” ê° ë¬¸ì¥ì˜ ê¸¸ì´ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","- `BucketIteratorëŠ”` ìœ ì‚¬í•œ ê¸¸ì´ë¥¼ ê°€ì§„ ìƒ˜í”Œë“¤ì„ ê°™ì€ ë°°ì¹˜ì— ë¬¶ì–´ì£¼ëŠ” ì—­í• ì„ í•˜ê¸° ë•Œë¬¸ì—, ê³ ì •ëœ ê¸¸ì´ë¡œ ë§ì¶”ê¸° ìœ„í•œ íŒ¨ë”©ì˜ ì–‘ì„ ìµœì†Œí™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uazI6xuv8rDH"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","BATCH_SIZE = 128\n","\n","train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n","    (train_data, val_data, test_data),\n","    batch_size = BATCH_SIZE,\n","    device = device\n",")"]},{"cell_type":"markdown","metadata":{"id":"Z154iai8Czsr"},"source":["- ì²« ë²ˆì§¸ ë°°ì¹˜ë¥¼ ì¶œë ¥í•œ ê²°ê³¼, [sequence length, batch size]ë¼ëŠ” tensorê°€ ìƒì„±ë©ë‹ˆë‹¤\n","- `sequence length`ëŠ” í•´ë‹¹ ë°°ì¹˜ ë‚´ì—ì„œ ê°€ì¥ ê¸´ ë¬¸ì¥ì˜ ê¸¸ì´ë¥¼ ì˜ë¯¸í•˜ë©°, ì´ë³´ë‹¤ ì§§ì€ ë¬¸ì¥ì€ <pad> tokenìœ¼ë¡œ ì±„ì›Œì§‘ë‹ˆë‹¤.\n","- í¸ì˜ìƒ transposeí•œ ë’¤, ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ ë¬¸ì¥ì˜ í…ì„œë¥¼ ì¶œë ¥í•˜ë©´, íŠ¹ì • ë‹¨ì–´ì— ëŒ€ì‘í•˜ëŠ” ì¸ë±ìŠ¤ê°€ ì¶œë ¥ë˜ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3r-eReL8rwm_"},"outputs":[],"source":["for i, batch in enumerate(train_iterator):\n","    src = batch.src\n","    trg = batch.trg\n","\n","    print(f\"ì²« ë²ˆì§¸ ë°°ì¹˜ì˜ text í¬ê¸°: {src.shape}\")\n","    src = src.transpose(1,0)\n","    print(src[0])\n","    print(src[1])\n","\n","    break"]},{"cell_type":"markdown","metadata":{"id":"51xSGy35XLvG"},"source":["### Building the Seq2Seq with LSTM Model\n","\n","- seq2seq ì´í•´ë¥¼ ìœ„í•œ ê³¼ì œì´ë‹ˆ, ì•„ë˜ë¥¼ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•´ë„ ë¬´ë°©í•©ë‹ˆë‹¤ :)\n","\n","\n","https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice/blob/master/code_practices/Sequence_to_Sequence_with_LSTM_Tutorial.ipynb"]},{"cell_type":"markdown","metadata":{"id":"i9WWS97vYnSb"},"source":["### Encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GtpU_ZjeYNEZ"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, p):\n","        super().__init__()\n","\n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        self.dropout = nn.Dropout(p)\n","\n","        #=========================================#\n","        # ğŸ’¡ì•„ë˜ì¤„ì— embeddingê³¼ multi-layer LSTM ë¶€ë¶„ì„ ì±„ì›Œì£¼ì„¸ìš” (dropout í¬í•¨)\n","        #=========================================#\n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=p)\n","\n","    def forward(self, x):\n","        # x = [x length, batch size]\n","        embedding = self.dropout(self.embedding(x))  # embedding = [x length, batch size, emb size]\n","\n","        outputs, (hidden, cell) = self.rnn(embedding)\n","\n","        # hidden = [n layers, batch size, hid dim]\n","        # cell = [n layer, batch size, hid dim]\n","        # outputs = [src len, batch size, hid dim]\n","\n","        return hidden, cell"]},{"cell_type":"markdown","metadata":{"id":"ZrQoLPg-Ype1"},"source":["### Decoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NOVQfminYknh"},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, p):\n","        super().__init__()\n","\n","        self.output_dim = output_dim\n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        self.dropout = nn.Dropout(p)\n","\n","        #=========================================#\n","        # ğŸ’¡ì•„ë˜ ì½”ë“œë¥¼ ì±„ì›Œì£¼ê³ , ê°ê° ì–´ë–¤ ì—­í• ì„ í•˜ëŠ”ì§€ ì£¼ì„ìœ¼ë¡œ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”\n","        #\n","        #=========================================#\n","        self.embedding = nn.Embedding(output_dim, emb_dim) # embedding: ë‹¨ì–´ë¥¼ vectorë¡œ ë³€í™˜\n","        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=p)  # RNN(LSTM): hidden state, cell state -> ë‹¤ìŒ state ì˜ˆì¸¡\n","        self.fc = nn.Linear(hid_dim, output_dim) # RC: ë‹¤ìŒ ë‹¨ì–´ ì˜ˆì¸¡\n","\n","    def forward(self, input, hidden, cell):\n","\n","        # í˜„ì¬ input í˜•íƒœ = [batch size]\n","        # DecoderëŠ” í•œë²ˆì— í•˜ë‚˜ì˜ í† í°ë§Œ ì²˜ë¦¬í•˜ë„ë¡ sequence length = 1ì´ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤\n","        input = input.unsqueeze(0)\n","\n","        embedding = self.dropout(self.embedding(input))\n","\n","        #=========================================#\n","        # ğŸ’¡self.rnn() ê´„í˜¸ ì•ˆ ë¶€ë¶„ì„ ì±„ì›Œì£¼ì„¸ìš”\n","        #=========================================#\n","        output, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n","\n","        prediction = self.fc(output.squeeze(0))  #prediction = [batch size, output dim]\n","\n","        return prediction, hidden, cell"]},{"cell_type":"markdown","metadata":{"id":"NNsTqRamcfPg"},"source":["### Seq2Seq"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ik28Umx6gAPW"},"outputs":[],"source":["class Seq2Seq(nn.Module):\n","\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","\n","        assert encoder.hid_dim == decoder.hid_dim, \\\n","            \"Hidden dimensions of encoder and decoder must be equal!\"\n","        assert encoder.n_layers == decoder.n_layers, \\\n","            \"Encoder and decoder must have equal number of layers!\"\n","\n","    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n","\n","        #src = [src len, batch size]\n","        #trg = [trg len, batch size]\n","        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n","\n","        batch_size = trg.shape[1]\n","        trg_len = trg.shape[0]\n","        trg_vocab_size = self.decoder.output_dim\n","\n","        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n","\n","        hidden, cell = self.encoder(src)\n","\n","        #=========================================#\n","        # ğŸ’¡trgë¥¼ ì‚¬ìš©í•˜ì—¬ decoderì— ì…ë ¥í•  ì²«ë²ˆì§¸ inputì„ ì„¤ì •í•´ì£¼ì„¸ìš”\n","        #=========================================#\n","        input = trg[0, :]\n","\n","        for t in range(1, trg_len):\n","\n","            output, hidden, cell = self.decoder(input, hidden, cell)\n","\n","            outputs[t] = output\n","\n","            # predictionsë“¤ ì¤‘ì— ê°€ì¥ ì˜ ì˜ˆì¸¡ëœ token ì¶”ì¶œ\n","            best_guess = output.argmax(1) # [batch size]\n","\n","            input = trg[t] if random.random() < teacher_forcing_ratio else best_guess\n","\n","        return outputs"]},{"cell_type":"markdown","metadata":{"id":"bfKrIZ63jkVF"},"source":["### **Q. ìœ„ ì½”ë“œì—ì„œëŠ” ë§¤ ì‹œì ë§ˆë‹¤ í™•ë¥ ì´ ê°€ì¥ ë†’ì€ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì„ íƒí•˜ëŠ” Greedy decodingÂ  ë°©ì‹ì´ ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ëŸ° ë°©ë²•ì„ ì±„íƒí•  ê²½ìš° ë°œìƒí•  ìˆ˜ ìˆëŠ” ë¬¸ì œì ì€ ë¬´ì—‡ì¼ì§€ ì‘ì„±í•´ì£¼ì„¸ìš”.**\n","\n","\n","```python\n","\n","# predictionsë“¤ ì¤‘ì— ê°€ì¥ ì˜ ì˜ˆì¸¡ëœ token ì¶”ì¶œ\n","best_guess = output.argmax(1) # [batch size]\n","\n","```\n","\n","\n","â¡ï¸"]},{"cell_type":"markdown","metadata":{"id":"EHk36-bkh055"},"source":["### Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xj33q4Izh3aB"},"outputs":[],"source":["INPUT_DIM = len(SRC.vocab)\n","OUTPUT_DIM = len(TRG.vocab)\n","ENC_EMB_DIM = 256\n","DEC_EMB_DIM = 256\n","HID_DIM = 512\n","N_LAYERS = 2\n","ENC_DROPOUT = 0.5\n","DEC_DROPOUT = 0.5\n","\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n","\n","model = Seq2Seq(enc, dec, device).to(device)"]},{"cell_type":"markdown","metadata":{"id":"uoFprkiyh5vm"},"source":["ëª¨ë¸ ì´ˆê¸° ê°€ì¤‘ì¹˜ ê°’ì€ ë…¼ë¬¸ì˜ ë‚´ìš©ëŒ€ë¡œ U(âˆ’0.08,0.08)ì˜ ì—°ì†ê· ë“±ë¶„í¬ë¡œë¶€í„° ì–»ìŠµë‹ˆë‹¤."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-oLZ0jXyh4zG"},"outputs":[],"source":["def init_weights(m):\n","    for name, param in m.named_parameters():\n","        nn.init.uniform_(param.data, -0.08, 0.08)\n","\n","model.apply(init_weights)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TpKWiiBIF5NA"},"outputs":[],"source":["optimizer = optim.Adam(model.parameters())\n","\n","# ë’· ë¶€ë¶„ì˜ íŒ¨ë”©(padding)ì— ëŒ€í•´ì„œëŠ” ê°’ ë¬´ì‹œ\n","TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n","criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"]},{"cell_type":"markdown","metadata":{"id":"veJrgUHBjRVa"},"source":["### Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LDfEPQUwFvVG"},"outputs":[],"source":["def train(model, iterator, optimizer, criterion, clip):\n","\n","    model.train()\n","    epoch_loss = 0\n","\n","    for i, batch in enumerate(iterator):\n","\n","        src = batch.src\n","        trg = batch.trg\n","\n","        optimizer.zero_grad()\n","\n","        output = model(src, trg)\n","\n","        output_dim = output.shape[-1]\n","\n","        output = output[1:].view(-1, output_dim)\n","        trg = trg[1:].view(-1)\n","\n","        loss = criterion(output, trg)\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","    return epoch_loss / len(iterator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O0fOgC3jc8K4"},"outputs":[],"source":["def evaluate(model, iterator, criterion):\n","\n","    model.eval()\n","\n","    epoch_loss = 0\n","\n","    with torch.no_grad():\n","\n","        for i, batch in enumerate(iterator):\n","\n","            src = batch.src\n","            trg = batch.trg\n","\n","            output = model(src, trg, 0)\n","\n","            output_dim = output.shape[-1]\n","\n","            output = output[1:].view(-1, output_dim)\n","            trg = trg[1:].view(-1)\n","\n","            loss = criterion(output, trg)\n","\n","            epoch_loss += loss.item()\n","\n","    return epoch_loss / len(iterator)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5OCHWUhmGORD"},"outputs":[],"source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n0VHYyZLjFO2"},"outputs":[],"source":["N_EPOCHS = 3\n","CLIP = 1\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","\n","    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n","    valid_loss = evaluate(model, valid_iterator, criterion)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'tut1-model.pt')\n","\n","    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QCou2VSKVz64"},"outputs":[],"source":["model.load_state_dict(torch.load('/content/seq2seq-lstm-model.pt'))\n","test_loss = evaluate(model, test_iterator, criterion)\n","print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPO048WnZCYZh+CX7AzYDsd","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":0}
