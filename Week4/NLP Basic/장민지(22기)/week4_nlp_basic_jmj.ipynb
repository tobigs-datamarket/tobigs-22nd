{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 과제 1\n",
        "\n",
        "### **Q. 각 모델이 충족하는 속성에 대해 아래 표를 O/X로 채워주세요.**\n",
        "\n",
        "📍5번째 속성은 **LSTM 기준으로** O/X 여부 판단해주세요 ! <br>\n",
        "📍정답은 과제 마감 다음날 (9월 11일 수요일)에 **노션-정규세션-NLP basic**에 업로드 예정\n",
        "\n",
        "\n",
        "> #### **속성 설명**\n",
        "1. Order matters : 입력 시퀀스의 순서 중요 여부\n",
        "2. Variable Length : 고정된 길이가 아닌 다양한 길이의 시퀀스를 처리할 수 있는지 여부\n",
        "3. Differentiable : 미분가능\n",
        "4. Pairwise encoding : 두 단어 사이의 관계를 표현\n",
        "5. Preserves long-term : 장기적인 의존성\n"
      ],
      "metadata": {
        "id": "9WW4t3iCYKuy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|               | N-gram | RNN   | LSTM  | Transformer |\n",
        "|:-------------:|:------:|:-----:|:-----:|:-----------:|\n",
        "| Order matters |    0    |  0   |  0    | O           |\n",
        "| Variable length |   x   |   0  |   0   | O           |\n",
        "| Differentiable |     x  |    0 |    0  | O           |\n",
        "| Pairwise encoding |   x |     x|     x | O           |\n",
        "| Preserves long-term |  x|    x |      0| O           |\n"
      ],
      "metadata": {
        "id": "paUeOH0OYNU0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 과제 2\n",
        "\n",
        "\n",
        "### 목표 : 독일어를 영어로 번역하는 모델 만들기\n",
        "독일어 문장을 입력하면 영어로 번역해주는 모델을 seq2seq로 구현해봅시다"
      ],
      "metadata": {
        "id": "14MthA8WYQev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torchtext==0.6.0"
      ],
      "metadata": {
        "id": "7PbwGzED6TIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en\n",
        "!python -m spacy download de"
      ],
      "metadata": {
        "id": "DPKSSHzQ6Uoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "import spacy\n",
        "from torchtext.datasets import TranslationDataset\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "MJWiAS2yWutF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizers\n",
        "\n",
        "- 문장의 토큰화, 태깅 등의 전처리를 수행하기 위해 `spaCy` 라이브러리에서 영어와 독일어 전처리 모듈을 설치해줍니다.\n",
        "- 두 언어의 문장이 주어졌기 때문에 영어와 독일어 각각에 대해 전처리해주어야 합니다.\n"
      ],
      "metadata": {
        "id": "uHmIKputmJfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_de = spacy.load('de_core_news_sm')\n",
        "spacy_en = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "l7ZtI5IXm7EG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예시\n",
        "result = spacy_en.tokenizer(\"I am a student.\")\n",
        "\n",
        "for i, token in enumerate(result):\n",
        "    print(f\"인덱스 {i}: {token.text}\")"
      ],
      "metadata": {
        "id": "co1TC8yv7yrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "필드(field) 라이브러리를 이용해 데이터셋에 대한 구체적인 전처리 내용을 명시해줍니다."
      ],
      "metadata": {
        "id": "lEGmP9Uk8gQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#===================================================\n",
        "# 💡 토큰화 결과가 list로 반환될 수 있도록 return 결과값을 채워주세요\n",
        "# seq2sxeq 논문에 의하면, input 단어의 순서를 바꾸면 최적화가 더 쉬워져 성능이 좋아진다고 합니다.\n",
        "# 💡 독일어 토큰화 결과가 역순으로 return될 수 있도록 반영해주세요!\n",
        "#===================================================\n",
        "def tokenize_de(text):\n",
        "    return\n",
        "\n",
        "def tokenize_en(text):\n",
        "    return"
      ],
      "metadata": {
        "id": "uMjoI1XE7tGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "필드(field) 라이브러리를 이용해 데이터셋에 대한 구체적인 전처리 내용을 명시해줍니다."
      ],
      "metadata": {
        "id": "z3wGw1nPnpMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 독일어\n",
        "SRC = Field(tokenize= tokenize_de, init_token = '<sos>', eos_token = '<eos>', lower = True)\n",
        "# 영어\n",
        "TRG = Field(tokenize= tokenize_en, init_token = '<sos>', eos_token = '<eos>', lower = True)"
      ],
      "metadata": {
        "id": "ubKI59GPpQ1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 불러오기\n",
        "\n",
        "대표적인 영어-독어 번역 데이터셋 Multi30k을 불러옵니다.\n"
      ],
      "metadata": {
        "id": "0_ccI6_-8hR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/multi30k/dataset.git\n",
        "\n",
        "# 압축해제\n",
        "!gunzip /content/dataset/data/task1/raw/train.de.gz\n",
        "!gunzip /content/dataset/data/task1/raw/train.en.gz\n",
        "!gunzip /content/dataset/data/task1/raw/val.de.gz\n",
        "!gunzip /content/dataset/data/task1/raw/val.en.gz\n",
        "!gunzip /content/dataset/data/task1/raw/test_2018_flickr.de.gz\n",
        "!gunzip /content/dataset/data/task1/raw/test_2018_flickr.en.gz"
      ],
      "metadata": {
        "id": "mLA5kXAAf2uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/dataset/data/task1/raw/'\n",
        "\n",
        "train_data = TranslationDataset(path=data_path, exts=('train.de', 'train.en'), fields=(SRC, TRG) )\n",
        "val_data = TranslationDataset(path=data_path, exts=('val.de', 'val.en'), fields=(SRC, TRG) )\n",
        "test_data = TranslationDataset(path=data_path, exts=('test_2018_flickr.de', 'test_2018_flickr.en'), fields=(SRC, TRG) )"
      ],
      "metadata": {
        "id": "M0JchGVU91Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"학습 데이터셋(training dataset) 크기: {len(train_data.examples)}개\")\n",
        "print(f\"평가 데이터셋(validation dataset) 크기: {len(val_data.examples)}개\")\n",
        "print(f\"테스트 데이터셋(testing dataset) 크기: {len(test_data.examples)}개\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxLylN1y-urW",
        "outputId": "62447416-c1f5-48c5-dec7-4c438c67a7f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터셋(training dataset) 크기: 29000개\n",
            "평가 데이터셋(validation dataset) 크기: 1014개\n",
            "테스트 데이터셋(testing dataset) 크기: 1071개\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vars(train_data.examples[0]))\n",
        "print(vars(train_data.examples[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rpt6l_Xd_AQX",
        "outputId": "f8d29c4a-bef3-4d61-8175-fc08ca298369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'src': ['.', 'büsche', 'vieler', 'nähe', 'der', 'in', 'freien', 'im', 'sind', 'männer', 'weiße', 'junge', 'zwei'], 'trg': ['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']}\n",
            "{'src': ['.', 'antriebsradsystem', 'ein', 'bedienen', 'schutzhelmen', 'mit', 'männer', 'mehrere'], 'trg': ['several', 'men', 'in', 'hard', 'hats', 'are', 'operating', 'a', 'giant', 'pulley', 'system', '.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `build_vocab`함수를 이용하여 영어와 독일어의 단어 사전을 생성해줍니다. 이를 통해 각 token이 indexing됩니다\n",
        "- 단, vocabulary는 훈련 데이터셋에 대해서만 만들어져야 합니다.\n",
        "- `min_freq`를 사용하여 최소 2번 이상 나오는 단어들만 사전에 포함되도록 합니다."
      ],
      "metadata": {
        "id": "uNoigj40AD_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\n",
        "TRG.build_vocab(train_data, min_freq = 2)"
      ],
      "metadata": {
        "id": "TfK-pAr_ApLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(TRG.vocab.stoi[\"abcabc\"]) # 없는 단어: 0\n",
        "print(TRG.vocab.stoi[TRG.pad_token]) # 패딩(padding): 1\n",
        "print(TRG.vocab.stoi[\"\"]) # : 0\n",
        "print(TRG.vocab.stoi[\"\"]) # : 0\n",
        "print(TRG.vocab.stoi[\"hello\"])\n",
        "print(TRG.vocab.stoi[\"world\"])"
      ],
      "metadata": {
        "id": "KyaA5P0Mrqaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 시퀀스 데이터는 각 문장의 길이가 다를 수 있습니다.\n",
        "- `BucketIterator는` 유사한 길이를 가진 샘플들을 같은 배치에 묶어주는 역할을 하기 때문에, 고정된 길이로 맞추기 위한 패딩의 양을 최소화할 수 있습니다."
      ],
      "metadata": {
        "id": "GmHXb1phBXJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, val_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device\n",
        ")"
      ],
      "metadata": {
        "id": "uazI6xuv8rDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 첫 번째 배치를 출력한 결과, [sequence length, batch size]라는 tensor가 생성됩니다\n",
        "- `sequence length`는 해당 배치 내에서 가장 긴 문장의 길이를 의미하며, 이보다 짧은 문장은 <pad> token으로 채워집니다.\n",
        "- 편의상 transpose한 뒤, 첫 번째와 두 번째 문장의 텐서를 출력하면, 특정 단어에 대응하는 인덱스가 출력되는 것을 알 수 있습니다.\n"
      ],
      "metadata": {
        "id": "Z154iai8Czsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, batch in enumerate(train_iterator):\n",
        "    src = batch.src\n",
        "    trg = batch.trg\n",
        "\n",
        "    print(f\"첫 번째 배치의 text 크기: {src.shape}\")\n",
        "    src = src.transpose(1,0)\n",
        "    print(src[0])\n",
        "    print(src[1])\n",
        "\n",
        "    break"
      ],
      "metadata": {
        "id": "3r-eReL8rwm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the Seq2Seq with LSTM Model\n",
        "\n",
        "- seq2seq 이해를 위한 과제이니, 아래를 참고하여 작성해도 무방합니다 :)\n",
        "\n",
        "\n",
        "https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice/blob/master/code_practices/Sequence_to_Sequence_with_LSTM_Tutorial.ipynb"
      ],
      "metadata": {
        "id": "51xSGy35XLvG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder"
      ],
      "metadata": {
        "id": "i9WWS97vYnSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, p):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = nn.Dropout(p)\n",
        "\n",
        "        # Embedding and multi-layer LSTM with dropout\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)  # Embedding layer\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=p)  # LSTM with multiple layers and dropout\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = [x length, batch size]\n",
        "        embedding = self.dropout(self.embedding(x))  # embedding = [x length, batch size, emb size]\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(embedding)\n",
        "\n",
        "        # hidden = [n layers, batch size, hid dim]\n",
        "        # cell = [n layers, batch size, hid dim]\n",
        "        # outputs = [src len, batch size, hid dim]\n",
        "\n",
        "        return hidden, cell\n"
      ],
      "metadata": {
        "id": "GtpU_ZjeYNEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder"
      ],
      "metadata": {
        "id": "ZrQoLPg-Ype1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, p):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = nn.Dropout(p)\n",
        "\n",
        "        # Embedding layer: 입력을 임베딩 벡터로 변환\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "\n",
        "        # RNN (LSTM) layer: 임베딩 벡터와 hidden/cell 상태를 입력으로 받아 다음 hidden, cell 상태를 반환\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=p)\n",
        "\n",
        "        # Fully connected layer: RNN의 출력을 사용해 최종 예측값을 계산\n",
        "        self.fc = nn.Linear(hid_dim, output_dim)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "\n",
        "        # input = [batch size], 1차원 텐서를 2차원으로 확장해 sequence length가 1이 되도록 함\n",
        "        input = input.unsqueeze(0)  # input = [1, batch size]\n",
        "\n",
        "        # Embedding: 입력 토큰을 임베딩 벡터로 변환\n",
        "        embedding = self.dropout(self.embedding(input))  # embedding = [1, batch size, emb dim]\n",
        "\n",
        "        # RNN: 임베딩과 hidden, cell 상태를 사용해 RNN 실행\n",
        "        output, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
        "        # output = [seq len, batch size, hid dim] -> seq len = 1이므로 [1, batch size, hid dim]\n",
        "        # hidden = [n layers, batch size, hid dim]\n",
        "        # cell = [n layers, batch size, hid dim]\n",
        "\n",
        "        # Fully connected layer: RNN의 출력을 사용해 예측값 계산\n",
        "        prediction = self.fc(output.squeeze(0))  # output의 첫 번째 차원 제거 (seq len 제거) -> [batch size, hid dim]\n",
        "        # prediction = [batch size, output dim]\n",
        "\n",
        "        return prediction, hidden, cell\n"
      ],
      "metadata": {
        "id": "NOVQfminYknh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seq2Seq"
      ],
      "metadata": {
        "id": "NNsTqRamcfPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "\n",
        "        # src = [src len, batch size]\n",
        "        # trg = [trg len, batch size]\n",
        "        # e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "\n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        hidden, cell = self.encoder(src)\n",
        "\n",
        "        # trg를 사용하여 decoder에 입력할 첫 번째 input 설정 (trg의 첫 번째 토큰을 사용)\n",
        "        input = trg[0]  # trg의 첫 번째 토큰 [batch size]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "\n",
        "            outputs[t] = output\n",
        "\n",
        "            # predictions들 중에 가장 잘 예측된 token 추출\n",
        "            best_guess = output.argmax(1)  # [batch size]\n",
        "\n",
        "            # Teacher forcing: 일정 확률로 ground-truth(정답) 또는 모델의 예측 사용\n",
        "            input = trg[t] if random.random() < teacher_forcing_ratio else best_guess\n",
        "\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "Ik28Umx6gAPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Q. 위 코드에서는 매 시점마다 확률이 가장 높은 다음 단어를 선택하는 Greedy decoding  방식이 사용됩니다. 이런 방법을 채택할 경우 발생할 수 있는 문제점은 무엇일지 작성해주세요.**\n",
        "\n",
        "➡️ 전역 최적화 실패: Greedy decoding은 각 시점에서 가장 높은 확률의 단어를 선택하지만, 이는 전체 시퀀스에서 최적의 해를 보장하지 못할 수 있습니다. 일시적으로 덜 확률이 높은 단어를 선택해야 더 나은 전체 문장을 생성할 수 있는 경우도 있는데, Greedy 방식은 이를 고려하지 않습니다.\n",
        "\n",
        "다양성 부족: Greedy decoding은 항상 가장 확률이 높은 단어만 선택하므로, 생성된 문장이 매우 반복적이고 다양성이 부족할 수 있습니다. 같은 입력에 대해 항상 동일한 출력을 생성하게 되어 창의적이거나 다양한 결과를 얻기 어렵습니다.\n",
        "\n",
        "문맥 무시: Greedy decoding은 이전에 선택한 단어들의 맥락을 충분히 고려하지 못할 수 있습니다. 이후 문장에서 더 적합한 단어를 선택하기 위해서는 문맥을 고려해야 하지만, Greedy 방식은 각 단계를 독립적으로 처리하기 때문에 문맥을 제대로 반영하지 못할 수 있습니다.\n",
        "\n",
        "비문법적 또는 부자연스러운 문장: Greedy 방식은 각 단어를 최적화하려 하기 때문에, 전체 문장이 비문법적이거나 부자연스러운 결과로 이어질 수 있습니다. 전체 문장의 흐름이나 일관성을 유지하기 어렵습니다."
      ],
      "metadata": {
        "id": "bfKrIZ63jkVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "EHk36-bkh055"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "metadata": {
        "id": "Xj33q4Izh3aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 초기 가중치 값은 논문의 내용대로 U(−0.08,0.08)의 연속균등분포로부터 얻습니다."
      ],
      "metadata": {
        "id": "uoFprkiyh5vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "metadata": {
        "id": "-oLZ0jXyh4zG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# 뒷 부분의 패딩(padding)에 대해서는 값 무시\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
      ],
      "metadata": {
        "id": "TpKWiiBIF5NA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate"
      ],
      "metadata": {
        "id": "veJrgUHBjRVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(iterator):\n",
        "\n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src, trg)\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "LDfEPQUwFvVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output = model(src, trg, 0)\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "O0fOgC3jc8K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "5OCHWUhmGORD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 3\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "metadata": {
        "id": "n0VHYyZLjFO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/seq2seq-lstm-model.pt'))\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "metadata": {
        "id": "QCou2VSKVz64"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}