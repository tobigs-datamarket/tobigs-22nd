{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzG0kX5K68kw"
      },
      "source": [
        "#1-1\n",
        "\n",
        "MNIST 데이터셋을 사용하여 간단한 VAE을 구현한 코드입니다.\n",
        "\n",
        "코드를 실행시키고, 주석을 달아주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KVnT38i07pPK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AbhamSuI7Eaa"
      },
      "outputs": [],
      "source": [
        "num_epochs = 50\n",
        "batch_size = 100\n",
        "learning_rate = 0.0002\n",
        "img_size = 28 * 28\n",
        "latent_dim = 20\n",
        "hidden_size1 = 256\n",
        "hidden_size2 = 512\n",
        "hidden_size3 = 1024\n",
        "dir_name = \"VAE_results\"\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "if not os.path.exists(dir_name):\n",
        "    os.makedirs(dir_name)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WIhwaLXY7PA6"
      },
      "outputs": [],
      "source": [
        "MNIST_dataset = datasets.MNIST(root='../../data/',\n",
        "                               train=True,\n",
        "                               transform=transform,\n",
        "                               download=True)\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(dataset=MNIST_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-8ANJtF77Sv6"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(img_size, hidden_size3)\n",
        "        self.fc2 = nn.Linear(hidden_size3, hidden_size2)\n",
        "        self.fc3 = nn.Linear(hidden_size2, hidden_size1)\n",
        "        self.fc_mean = nn.Linear(hidden_size1, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(hidden_size1, latent_dim)\n",
        "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky_relu(self.fc1(x))\n",
        "        x = self.leaky_relu(self.fc2(x))\n",
        "        x = self.leaky_relu(self.fc3(x))\n",
        "        mean = self.fc_mean(x)\n",
        "        logvar = self.fc_logvar(x)\n",
        "        return mean, logvar\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(latent_dim, hidden_size1)\n",
        "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
        "        self.fc4 = nn.Linear(hidden_size3, img_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.sigmoid(self.fc4(x))\n",
        "        return x\n",
        "\n",
        "encoder = Encoder().to(device)\n",
        "decoder = Decoder().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbFB4rGL7j6R"
      },
      "outputs": [],
      "source": [
        "def reparameterize(mean, logvar):\n",
        "    std = torch.exp(0.5 * logvar)\n",
        "    eps = torch.randn_like(std)\n",
        "    return mean + eps * std\n",
        "\n",
        "def loss_function(recon_x, x, mean, logvar):\n",
        "    BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
        "    return BCE + KLD\n",
        "\n",
        "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJt3Iaj67nAd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Loss: 200.2667\n",
            "Epoch [2/50], Loss: 149.3244\n",
            "Epoch [3/50], Loss: 129.9481\n",
            "Epoch [4/50], Loss: 123.4804\n",
            "Epoch [5/50], Loss: 119.4928\n",
            "Epoch [6/50], Loss: 116.2104\n",
            "Epoch [7/50], Loss: 113.6074\n",
            "Epoch [8/50], Loss: 111.4449\n",
            "Epoch [9/50], Loss: 109.5634\n",
            "Epoch [10/50], Loss: 108.1194\n",
            "Epoch [11/50], Loss: 107.0075\n",
            "Epoch [12/50], Loss: 106.0942\n",
            "Epoch [13/50], Loss: 105.3176\n",
            "Epoch [14/50], Loss: 104.5061\n",
            "Epoch [15/50], Loss: 103.8561\n",
            "Epoch [16/50], Loss: 103.2435\n",
            "Epoch [17/50], Loss: 102.6651\n",
            "Epoch [18/50], Loss: 102.1500\n",
            "Epoch [19/50], Loss: 101.6444\n",
            "Epoch [20/50], Loss: 101.1977\n",
            "Epoch [21/50], Loss: 100.8032\n",
            "Epoch [22/50], Loss: 100.4451\n",
            "Epoch [23/50], Loss: 100.1153\n",
            "Epoch [24/50], Loss: 99.7972\n",
            "Epoch [25/50], Loss: 99.5091\n",
            "Epoch [26/50], Loss: 99.2362\n",
            "Epoch [27/50], Loss: 98.9801\n",
            "Epoch [28/50], Loss: 98.6895\n",
            "Epoch [29/50], Loss: 98.4870\n",
            "Epoch [30/50], Loss: 98.2747\n",
            "Epoch [31/50], Loss: 98.0452\n",
            "Epoch [32/50], Loss: 97.8738\n",
            "Epoch [33/50], Loss: 97.6999\n",
            "Epoch [34/50], Loss: 97.4862\n",
            "Epoch [35/50], Loss: 97.3263\n",
            "Epoch [36/50], Loss: 97.1545\n",
            "Epoch [37/50], Loss: 97.0198\n",
            "Epoch [38/50], Loss: 96.8601\n",
            "Epoch [39/50], Loss: 96.7243\n",
            "Epoch [40/50], Loss: 96.6086\n",
            "Epoch [41/50], Loss: 96.3925\n",
            "Epoch [42/50], Loss: 96.2612\n",
            "Epoch [43/50], Loss: 96.1653\n",
            "Epoch [44/50], Loss: 96.0529\n",
            "Epoch [45/50], Loss: 95.9314\n",
            "Epoch [46/50], Loss: 95.8190\n",
            "Epoch [47/50], Loss: 95.7213\n",
            "Epoch [48/50], Loss: 95.5598\n",
            "Epoch [49/50], Loss: 95.4857\n",
            "Epoch [50/50], Loss: 95.3914\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for images, _ in data_loader:\n",
        "        images = images.view(-1, img_size).to(device)\n",
        "\n",
        "        images = (images + 1) / 2\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        mean, logvar = encoder(images)\n",
        "        z = reparameterize(mean, logvar)\n",
        "        recon_images = decoder(z)\n",
        "\n",
        "        loss = loss_function(recon_images, images, mean, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = train_loss / len(data_loader.dataset)\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(batch_size, latent_dim).to(device)\n",
        "        sample = decoder(z).view(-1, 1, 28, 28)\n",
        "        save_image(sample, os.path.join(dir_name, f'VAE_fake_image_{epoch + 1}.png'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXpTKQSp8CBY"
      },
      "source": [
        "#1-2\n",
        "\n",
        "아래 마크다운으로 VAE_fake_image_1.png와 VAE_fake_image_50.png를 함께 첨부해주세요.\n",
        "\n",
        "\n",
        "\n",
        "![](VAE_fake_image_1.png)\n",
        "![](VAE_fake_image_50.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
