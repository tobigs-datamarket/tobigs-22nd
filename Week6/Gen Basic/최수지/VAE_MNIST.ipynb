{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzG0kX5K68kw"
      },
      "source": [
        "#1-1\n",
        "\n",
        "MNIST 데이터셋을 사용하여 간단한 VAE을 구현한 코드입니다.\n",
        "\n",
        "코드를 실행시키고, 주석을 달아주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KVnT38i07pPK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AbhamSuI7Eaa"
      },
      "outputs": [],
      "source": [
        "# 하이퍼파라미터 설정\n",
        "num_epochs = 50\n",
        "batch_size = 100\n",
        "learning_rate = 0.0002\n",
        "img_size = 28 * 28\n",
        "latent_dim = 20\n",
        "hidden_size1 = 256\n",
        "hidden_size2 = 512\n",
        "hidden_size3 = 1024\n",
        "dir_name = \"VAE_results\"\n",
        "\n",
        "# GPU 사용 여부 확인\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 결과 이미지를 저장할 디렉토리 생성\n",
        "if not os.path.exists(dir_name):\n",
        "    os.makedirs(dir_name)\n",
        "\n",
        "# 전처리\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WIhwaLXY7PA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7334f828-0003-434d-8c67-17e828949926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 18050818.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/MNIST/raw/train-images-idx3-ubyte.gz to ../../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 508349.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 4469674.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 9948056.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# MNIST 데이터셋 로드\n",
        "MNIST_dataset = datasets.MNIST(root='../../data/',\n",
        "                               train=True,\n",
        "                               transform=transform,\n",
        "                               download=True)\n",
        "\n",
        "# DataLoader 설정\n",
        "data_loader = torch.utils.data.DataLoader(dataset=MNIST_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-8ANJtF77Sv6"
      },
      "outputs": [],
      "source": [
        "# VAE의 인코더 클래스 정의\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        # 인코더의 Fully Connected 레이어 정의\n",
        "        self.fc1 = nn.Linear(img_size, hidden_size3)\n",
        "        self.fc2 = nn.Linear(hidden_size3, hidden_size2)\n",
        "        self.fc3 = nn.Linear(hidden_size2, hidden_size1)\n",
        "        self.fc_mean = nn.Linear(hidden_size1, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(hidden_size1, latent_dim)\n",
        "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 인코더의 forward 계산\n",
        "        x = self.leaky_relu(self.fc1(x))\n",
        "        x = self.leaky_relu(self.fc2(x))\n",
        "        x = self.leaky_relu(self.fc3(x))\n",
        "        mean = self.fc_mean(x)\n",
        "        logvar = self.fc_logvar(x)\n",
        "        return mean, logvar\n",
        "\n",
        "# VAE의 디코더 클래스 정의\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        # 디코더의 Fully Connected 레이어 정의\n",
        "        self.fc1 = nn.Linear(latent_dim, hidden_size1)\n",
        "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
        "        self.fc4 = nn.Linear(hidden_size3, img_size)\n",
        "        self.relu = nn.ReLU() # ReLU 활성화 함수\n",
        "        self.sigmoid = nn.Sigmoid() # Sigmoid 활성화 함수\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 디코더의 forward 계산\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.sigmoid(self.fc4(x))\n",
        "        return x\n",
        "\n",
        "# 인코더와 디코더 모델 초기화 및 GPU로 전송\n",
        "encoder = Encoder().to(device)\n",
        "decoder = Decoder().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TbFB4rGL7j6R"
      },
      "outputs": [],
      "source": [
        "# 잠재 공간에서 샘플링을 위한 함수 정의\n",
        "def reparameterize(mean, logvar):\n",
        "    std = torch.exp(0.5 * logvar)\n",
        "    eps = torch.randn_like(std)\n",
        "    return mean + eps * std\n",
        "\n",
        "# VAE 손실 함수 정의\n",
        "def loss_function(recon_x, x, mean, logvar):\n",
        "    BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum') # 재구성 손실\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp()) # Kullback-Leibler Divergence (KLD) 손실\n",
        "    return BCE + KLD\n",
        "\n",
        "# Adam Optimizer 설정\n",
        "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wJt3Iaj67nAd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "092a943e-6ef0-48d6-fc1a-d916e0f61f0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Loss: 200.7084\n",
            "Epoch [2/50], Loss: 151.4977\n",
            "Epoch [3/50], Loss: 132.5315\n",
            "Epoch [4/50], Loss: 125.6801\n",
            "Epoch [5/50], Loss: 121.0569\n",
            "Epoch [6/50], Loss: 117.1720\n",
            "Epoch [7/50], Loss: 114.2857\n",
            "Epoch [8/50], Loss: 111.9960\n",
            "Epoch [9/50], Loss: 110.1114\n",
            "Epoch [10/50], Loss: 108.6766\n",
            "Epoch [11/50], Loss: 107.4454\n",
            "Epoch [12/50], Loss: 106.3984\n",
            "Epoch [13/50], Loss: 105.5095\n",
            "Epoch [14/50], Loss: 104.7539\n",
            "Epoch [15/50], Loss: 104.0979\n",
            "Epoch [16/50], Loss: 103.4729\n",
            "Epoch [17/50], Loss: 102.9730\n",
            "Epoch [18/50], Loss: 102.4631\n",
            "Epoch [19/50], Loss: 102.0132\n",
            "Epoch [20/50], Loss: 101.6319\n",
            "Epoch [21/50], Loss: 101.2538\n",
            "Epoch [22/50], Loss: 100.9097\n",
            "Epoch [23/50], Loss: 100.5563\n",
            "Epoch [24/50], Loss: 100.2359\n",
            "Epoch [25/50], Loss: 99.9689\n",
            "Epoch [26/50], Loss: 99.6937\n",
            "Epoch [27/50], Loss: 99.4005\n",
            "Epoch [28/50], Loss: 99.2049\n",
            "Epoch [29/50], Loss: 98.9711\n",
            "Epoch [30/50], Loss: 98.7372\n",
            "Epoch [31/50], Loss: 98.4926\n",
            "Epoch [32/50], Loss: 98.3228\n",
            "Epoch [33/50], Loss: 98.1624\n",
            "Epoch [34/50], Loss: 97.9230\n",
            "Epoch [35/50], Loss: 97.7659\n",
            "Epoch [36/50], Loss: 97.5825\n",
            "Epoch [37/50], Loss: 97.4263\n",
            "Epoch [38/50], Loss: 97.2540\n",
            "Epoch [39/50], Loss: 97.1048\n",
            "Epoch [40/50], Loss: 96.9838\n",
            "Epoch [41/50], Loss: 96.8225\n",
            "Epoch [42/50], Loss: 96.7198\n",
            "Epoch [43/50], Loss: 96.5599\n",
            "Epoch [44/50], Loss: 96.4326\n",
            "Epoch [45/50], Loss: 96.2622\n",
            "Epoch [46/50], Loss: 96.1607\n",
            "Epoch [47/50], Loss: 96.0481\n",
            "Epoch [48/50], Loss: 95.9178\n",
            "Epoch [49/50], Loss: 95.7919\n",
            "Epoch [50/50], Loss: 95.6797\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    # 배치별 학습\n",
        "    for images, _ in data_loader:\n",
        "        images = images.view(-1, img_size).to(device) # 이미지 데이터를 Flatten\n",
        "\n",
        "        images = (images + 1) / 2 # 이미지 값을 0~1로 변환\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        mean, logvar = encoder(images) # 인코더를 통해 mean, logvar 추출\n",
        "        z = reparameterize(mean, logvar) # 잠재 변수 z 샘플링\n",
        "        recon_images = decoder(z) # 디코더를 통해 재구성된 이미지 생성\n",
        "\n",
        "        loss = loss_function(recon_images, images, mean, logvar) # 손실 함수 계산\n",
        "        loss.backward() # 역전파로 손실을 통한 기울기 계산\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step() # optimizer로 파라미터 업데이트\n",
        "\n",
        "    # epoch별 평균 손실 출력\n",
        "    avg_loss = train_loss / len(data_loader.dataset)\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "\n",
        "    # 샘플 이미지 생성 및 저장\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(batch_size, latent_dim).to(device)\n",
        "        sample = decoder(z).view(-1, 1, 28, 28)\n",
        "        save_image(sample, os.path.join(dir_name, f'VAE_fake_image_{epoch + 1}.png'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXpTKQSp8CBY"
      },
      "source": [
        "#1-2\n",
        "\n",
        "아래 마크다운으로 VAE_fake_image_1.png와 VAE_fake_image_50.png를 함께 첨부해주세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsKNpBqWgR0F"
      },
      "source": [
        "![VAE_fake_image_1.png](VAE_fake_image_1.png)\n",
        "![VAE_fake_image_50.png](VAE_fake_image_50.png)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}