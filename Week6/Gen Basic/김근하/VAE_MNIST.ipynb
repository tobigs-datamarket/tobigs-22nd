{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1-1\n",
        "\n",
        "MNIST 데이터셋을 사용하여 간단한 VAE을 구현한 코드입니다.\n",
        "\n",
        "코드를 실행시키고, 주석을 달아주세요."
      ],
      "metadata": {
        "id": "MzG0kX5K68kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image"
      ],
      "metadata": {
        "id": "KVnT38i07pPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50\n",
        "batch_size = 100\n",
        "learning_rate = 0.0002\n",
        "img_size = 28 * 28\n",
        "latent_dim = 20\n",
        "hidden_size1 = 256\n",
        "hidden_size2 = 512\n",
        "hidden_size3 = 1024\n",
        "dir_name = \"VAE_results\"\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "if not os.path.exists(dir_name):\n",
        "    os.makedirs(dir_name)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "metadata": {
        "id": "AbhamSuI7Eaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MNIST_dataset = datasets.MNIST(root='../../data/',\n",
        "                               train=True,\n",
        "                               transform=transform,\n",
        "                               download=True)\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(dataset=MNIST_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)"
      ],
      "metadata": {
        "id": "WIhwaLXY7PA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(img_size, hidden_size3)\n",
        "        self.fc2 = nn.Linear(hidden_size3, hidden_size2)\n",
        "        self.fc3 = nn.Linear(hidden_size2, hidden_size1)\n",
        "        self.fc_mean = nn.Linear(hidden_size1, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(hidden_size1, latent_dim)\n",
        "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky_relu(self.fc1(x))\n",
        "        x = self.leaky_relu(self.fc2(x))\n",
        "        x = self.leaky_relu(self.fc3(x))\n",
        "        mean = self.fc_mean(x)\n",
        "        logvar = self.fc_logvar(x)\n",
        "        return mean, logvar\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc1 = nn.Linear(latent_dim, hidden_size1)\n",
        "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
        "        self.fc4 = nn.Linear(hidden_size3, img_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.sigmoid(self.fc4(x))\n",
        "        return x\n",
        "\n",
        "encoder = Encoder().to(device)\n",
        "decoder = Decoder().to(device)"
      ],
      "metadata": {
        "id": "-8ANJtF77Sv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reparameterize(mean, logvar):\n",
        "    std = torch.exp(0.5 * logvar)\n",
        "    eps = torch.randn_like(std)\n",
        "    return mean + eps * std\n",
        "\n",
        "def loss_function(recon_x, x, mean, logvar):\n",
        "    BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
        "    return BCE + KLD\n",
        "\n",
        "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=learning_rate)"
      ],
      "metadata": {
        "id": "TbFB4rGL7j6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for images, _ in data_loader:\n",
        "        images = images.view(-1, img_size).to(device)\n",
        "\n",
        "        images = (images + 1) / 2\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        mean, logvar = encoder(images)\n",
        "        z = reparameterize(mean, logvar)\n",
        "        recon_images = decoder(z)\n",
        "\n",
        "        loss = loss_function(recon_images, images, mean, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = train_loss / len(data_loader.dataset)\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(batch_size, latent_dim).to(device)\n",
        "        sample = decoder(z).view(-1, 1, 28, 28)\n",
        "        save_image(sample, os.path.join(dir_name, f'VAE_fake_image_{epoch + 1}.png'))"
      ],
      "metadata": {
        "id": "wJt3Iaj67nAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1-2\n",
        "\n",
        "아래 마크다운으로 VAE_fake_image_1.png와 VAE_fake_image_50.png를 함께 첨부해주세요."
      ],
      "metadata": {
        "id": "GXpTKQSp8CBY"
      }
    }
  ]
}