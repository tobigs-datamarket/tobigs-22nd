{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**1. Self AttentionğŸ“Œ**\n","\n","ì•„ë˜ ì½”ë“œë¥¼ ìˆ˜í–‰í•´ë³´ê³ , Self Attentionì€ ì–´ë–¤ ë©”ì»¤ë‹ˆì¦˜ì¸ì§€ ì„¤ëª…í•˜ê³ ,\n","\n"," ê·¸ ì„¤ëª…ì— ë§ê²Œ ê° ì½”ë“œì— ì§ì ‘ ì£¼ì„ì„ ë‹¬ì•„ë´…ì‹œë‹¤.\n","\n"," âœ…ì„¤ëª…: ë‹¨ì–´ í•˜ë‚˜ê°€ queryê°€ ë˜ê³  ë‚˜ë¨¸ì§€ê°€ keyê°€ ë˜ì–´, queryì™€ ê° key ì‚¬ì´ì˜ ì—°ê´€ì„±ì„ ë‚´ì ì„ í†µí•´ ê³„ì‚°í•œë‹¤."],"metadata":{"id":"ojf8hcSd9hLC"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m2KyObPG9Z7v","outputId":"2e119665-512c-417b-b4ad-92efafe14ebb","executionInfo":{"status":"ok","timestamp":1727003204680,"user_tz":-540,"elapsed":318,"user":{"displayName":"ìµœí•´ì›","userId":"14793508175590533527"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Self-Attention Matrix:\n","[[1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]]\n"]}],"source":["import numpy as np\n","\n","# ê°„ë‹¨í•œ ë¬¸ì¥: ['ë‚˜ëŠ”', 'ì‚¬ê³¼ë¥¼', 'ë¨¹ì—ˆë‹¤']\n","words = ['ë‚˜ëŠ”', 'ì‚¬ê³¼ë¥¼', 'ë¨¹ì—ˆë‹¤']\n","word_vectors = {\n","    'ë‚˜ëŠ”': np.array([1, 0, 0]),\n","    'ì‚¬ê³¼ë¥¼': np.array([0, 1, 0]),\n","    'ë¨¹ì—ˆë‹¤': np.array([0, 0, 1])\n","}\n","\n","# ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜ (self-attention)\n","def self_attention(query, key):\n","    return np.dot(query, key) # ë²¡í„° ë‚´ì ìœ¼ë¡œ ì—°ê´€ì„± ê³„ì‚°\n","\n","attention_matrix = np.zeros((len(words), len(words)))\n","for i in range(len(words)):      # ëª¨ë“  ë‹¨ì–´ê°€ í•œë²ˆì”© queryê°€ ë¨\n","    for j in range(len(words)):  # ê° ë‹¨ì–´ë“¤ì´ keyê°€ ë˜ì–´\n","        attention_matrix[i][j] = self_attention(word_vectors[words[i]], word_vectors[words[j]]) # ì—°ê´€ì„± ê³„ì‚° í›„ í•´ë‹¹í•˜ëŠ” í–‰ë ¬ ìœ„ì¹˜ì— ì¶”ê°€\n","\n","print(\"Self-Attention Matrix:\")\n","print(attention_matrix)\n"]},{"cell_type":"markdown","source":["**2. Multi-Head Self AttentionğŸ“Œ**\n","\n","ì•„ë˜ ì½”ë“œë¥¼ ìˆ˜í–‰í•´ë³´ê³ , Multi-Head Self Attentionì€ ì–´ë–¤ ë©”ì»¤ë‹ˆì¦˜ì¸ì§€ ì„¤ëª…í•˜ê³ ,\n","\n"," ê·¸ ì„¤ëª…ì— ë§ê²Œ ê° ì½”ë“œì— ì§ì ‘ ì£¼ì„ì„ ë‹¬ì•„ë´…ì‹œë‹¤.\n","\n"," âœ…ì„¤ëª…: attentionì„ headì˜ ê°œìˆ˜ ë§Œí¼ ë‚˜ëˆ„ì–´ ë³‘ë ¬ì ìœ¼ë¡œ ìˆ˜í–‰"],"metadata":{"id":"WA3NEBQC-Dpg"}},{"cell_type":"code","source":["# ì—¬ëŸ¬ ê°œì˜ attention heads\n","def multi_head_self_attention(query, key, heads=3):\n","    return [np.dot(query, key) for _ in range(heads)]  # ì—°ê´€ì„± ê³„ì‚° ì‹œ head ìˆ˜ ë§Œí¼ ê³„ì‚°\n","\n","multi_head_attention_matrix = np.zeros((len(words), len(words), 3)) # head ìˆ˜ ë§Œí¼\n","for i in range(len(words)):      # ëª¨ë“  ë‹¨ì–´ê°€ í•œë²ˆì”© queryê°€ ë¨\n","    for j in range(len(words)):  # ê° ë‹¨ì–´ë“¤ì´ keyê°€ ë˜ì–´\n","        multi_head_attention_matrix[i][j] = multi_head_self_attention(word_vectors[words[i]], word_vectors[words[j]])\n","        # self attention ì ìš©. head ìˆ˜ ë§Œí¼ ë‹¨ì–´ì˜ ê´€ê³„ë¥¼ ë‹¤ê°ì ìœ¼ë¡œ ë¶„ì„\n","\n","print(\"\\nMulti-Head Self-Attention Matrix:\")\n","print(multi_head_attention_matrix)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O1bvP6lC-efR","outputId":"d45f8293-b044-4420-e695-63a026a271f2","executionInfo":{"status":"ok","timestamp":1727003879830,"user_tz":-540,"elapsed":369,"user":{"displayName":"ìµœí•´ì›","userId":"14793508175590533527"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Multi-Head Self-Attention Matrix:\n","[[[1. 1. 1.]\n","  [0. 0. 0.]\n","  [0. 0. 0.]]\n","\n"," [[0. 0. 0.]\n","  [1. 1. 1.]\n","  [0. 0. 0.]]\n","\n"," [[0. 0. 0.]\n","  [0. 0. 0.]\n","  [1. 1. 1.]]]\n"]}]},{"cell_type":"markdown","source":["**3. Masked Multi-Head Self AttentionğŸ“Œ**\n","\n","ì•„ë˜ ì½”ë“œë¥¼ ìˆ˜í–‰í•´ë³´ê³ , Masked Multi-Head Self Attentionì€ ì–´ë–¤ ë©”ì»¤ë‹ˆì¦˜ì¸ì§€ ì„¤ëª…í•˜ê³ ,\n","\n"," ê·¸ ì„¤ëª…ì— ë§ê²Œ ê° ì½”ë“œì— ì§ì ‘ ì£¼ì„ì„ ë‹¬ì•„ë´…ì‹œë‹¤.\n","\n"," âœ…ì„¤ëª…:ë§ˆìŠ¤í¬ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ë‹¨ì–´ë“¤ì˜ ì—°ê´€ì„± ë¶„ì„ ì œí•œ. ì£¼ë¡œ ë¯¸ë˜ ë‹¨ì–´ë“¤ì„ ì°¸ì¡°í•˜ì§€ ëª»í•˜ê²Œ ì°¨ë‹¨í•˜ëŠ”ë° ì‚¬ìš©"],"metadata":{"id":"lHm1Y03S-hz9"}},{"cell_type":"code","source":["# ë§ˆìŠ¤í¬ ì¶”ê°€: í˜„ì¬ ë‹¨ì–´ ì´í›„ì˜ ë‹¨ì–´ëŠ” ê³„ì‚°í•˜ì§€ ì•ŠìŒ\n","def masked_attention(query, key, mask):\n","    return np.dot(query, key) * mask   # mask ê°’ì´ 0ì´ë©´ í•´ë‹¹ attetion ê°’ì€ ê³„ì‚°í•˜ì§€ ì•ŠìŒ\n","\n","mask = np.array([1, 1, 0])  # ì²« ë²ˆì§¸, ë‘ ë²ˆì§¸ëŠ” ë³´ì§€ë§Œ, ì„¸ ë²ˆì§¸ëŠ” masking (ì´ ë¹ˆì¹¸ ê¼­ ì±„ì›Œì£¼ì„¸ìš” :) )\n","masked_attention_matrix = np.zeros((len(words), len(words)))\n","for i in range(len(words)):\n","    for j in range(len(words)):\n","        masked_attention_matrix[i][j] = masked_attention(word_vectors[words[i]], word_vectors[words[j]], mask[j])\n","\n","print(\"\\nMasked Self-Attention Matrix:\")\n","print(masked_attention_matrix)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hELE_Nyf-pOP","outputId":"1de4c944-b241-4ccf-fd6c-20be0bc15e08","executionInfo":{"status":"ok","timestamp":1727003883144,"user_tz":-540,"elapsed":339,"user":{"displayName":"ìµœí•´ì›","userId":"14793508175590533527"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Masked Self-Attention Matrix:\n","[[1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 0.]]\n"]}]},{"cell_type":"markdown","source":["**4. Cross AttentionğŸ“Œ**\n","\n","ì•„ë˜ ì½”ë“œë¥¼ ìˆ˜í–‰í•´ë³´ê³ , Cross Attentionì€ ì–´ë–¤ ë©”ì»¤ë‹ˆì¦˜ì¸ì§€ ì„¤ëª…í•˜ê³ ,\n","\n"," ê·¸ ì„¤ëª…ì— ë§ê²Œ ê° ì½”ë“œì— ì§ì ‘ ì£¼ì„ì„ ë‹¬ì•„ë´…ì‹œë‹¤.\n","\n"," âœ…ì„¤ëª…:ì§ˆë¬¸ê³¼ ì‘ë‹µ ë¬¸ì¥ ê°„ì˜ attention ê³„ì‚°"],"metadata":{"id":"wEiAlmYi-xg9"}},{"cell_type":"code","source":["# ì…ë ¥ ë¬¸ì¥ê³¼ ì‘ë‹µ ë¬¸ì¥\n","question_words = ['ë„ˆëŠ”', 'ì‚¬ê³¼ë¥¼']\n","answer_words = ['ë‚˜ëŠ”', 'ë¨¹ì—ˆë‹¤']\n","question_vectors = {\n","    'ë„ˆëŠ”': np.array([1, 0]),\n","    'ì‚¬ê³¼ë¥¼': np.array([0, 1])\n","}\n","answer_vectors = {\n","    'ë‚˜ëŠ”': np.array([1, 0]),\n","    'ë¨¹ì—ˆë‹¤': np.array([0, 1])\n","}\n","\n","# Cross-Attention\n","cross_attention_matrix = np.zeros((len(question_words), len(answer_words)))\n","for i in range(len(question_words)):    # ì§ˆë¬¸ ë¬¸ì¥ì˜ ë‹¨ì–´ê°€ queryê°€ ë˜ê³ \n","    for j in range(len(answer_words)):  # ì‘ë‹µ ë¬¸ì¥ì˜ ë‹¨ì–´ê°€ keyê°€ ë˜ì–´\n","        cross_attention_matrix[i][j] = np.dot(question_vectors[question_words[i]], answer_vectors[answer_words[j]])\n","        # queryì™€ keyì˜ attention ê³„ì‚°\n","print(\"\\nCross-Attention Matrix:\")\n","print(cross_attention_matrix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F2871Q9r-5ZP","outputId":"1ebb45de-c576-4ac5-d3fc-e34b20f47c76","executionInfo":{"status":"ok","timestamp":1727003885702,"user_tz":-540,"elapsed":488,"user":{"displayName":"ìµœí•´ì›","userId":"14793508175590533527"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Cross-Attention Matrix:\n","[[1. 0.]\n"," [0. 1.]]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"OmWRXHXqc_zo"},"execution_count":null,"outputs":[]}]}