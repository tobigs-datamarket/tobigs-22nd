{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. Self AttentionğŸ“Œ**\n",
        "\n",
        "ì•„ë˜ ì½”ë“œë¥¼ ìˆ˜í–‰í•´ë³´ê³ , Self Attentionì€ ì–´ë–¤ ë©”ì»¤ë‹ˆì¦˜ì¸ì§€ ì„¤ëª…í•˜ê³ ,\n",
        "\n",
        " ê·¸ ì„¤ëª…ì— ë§ê²Œ ê° ì½”ë“œì— ì§ì ‘ ì£¼ì„ì„ ë‹¬ì•„ë´…ì‹œë‹¤.\n",
        "\n",
        " âœ…ì„¤ëª…: self attentionì€ ì…ë ¥ ì‹œí€€ìŠ¤ì˜ ê° ìš”ì†Œê°€ ë‹¤ë¥¸ ëª¨ë“  ìš”ì†Œì™€ ìƒí˜¸ì‘ìš©í•˜ì—¬ ì¤‘ìš”í•œ ì •ë³´ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜ì´ë‹¤. ì´ëŠ” ê° ë‹¨ì–´ê°€ ë¬¸ë§¥ì„ ì´í•´í•˜ê³ , í•´ë‹¹ ë¬¸ë§¥ ë‚´ì—ì„œ ìì‹ ì´ ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€ë¥¼ ê²°ì •í•  ìˆ˜ ìˆê²Œ í•œë‹¤. ë¨¼ì €, ì…ë ¥ ë²¡í„°ì—ì„œ Query, Key, Valueë¥¼ ìƒì„±í•œë‹¤. ì´í›„ Queryì™€ Key ì‚¬ì´ì˜ ì—°ê´€ì„±ì„ ê³„ì‚°í•˜ê¸° ìœ„í•´ ë‘ ê°’ì„ ë‚´ì í•˜ì—¬ Attention scoreì„ ê³„ì‚°í•œë‹¤. ê·¸ë¦¬ê³  ê°’ë“¤ì„ ì •ê·œí™”ì‹œí‚¤ê¸° ìœ„í•´ softmax í•¨ìˆ˜ë¥¼ ê±°ì³ Attention Weightë¥¼ ê³„ì‚°í•œ í›„, Attention Weightì™€ Valueì˜ ê°€ì¤‘í•©ì„ í†µí•´ ìµœì¢… ì¶œë ¥ì„ ìƒì„±í•œë‹¤."
      ],
      "metadata": {
        "id": "ojf8hcSd9hLC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2KyObPG9Z7v",
        "outputId": "b699e7b9-6da5-4db7-93d4-8575993623e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Self-Attention Matrix:\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# ê°„ë‹¨í•œ ë¬¸ì¥: ['ë‚˜ëŠ”', 'ì‚¬ê³¼ë¥¼', 'ë¨¹ì—ˆë‹¤']\n",
        "words = ['ë‚˜ëŠ”', 'ì‚¬ê³¼ë¥¼', 'ë¨¹ì—ˆë‹¤']\n",
        "word_vectors = {\n",
        "    'ë‚˜ëŠ”': np.array([1, 0, 0]),\n",
        "    'ì‚¬ê³¼ë¥¼': np.array([0, 1, 0]),\n",
        "    'ë¨¹ì—ˆë‹¤': np.array([0, 0, 1])\n",
        "}\n",
        "\n",
        "# ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜ (self-attention)\n",
        "def self_attention(query, key): # Queryì™€ Keyë¥¼ ë‚´ì í•˜ì—¬ Attention score ê³„ì‚°\n",
        "    return np.dot(query, key)\n",
        "\n",
        "attention_matrix = np.zeros((len(words), len(words)))\n",
        "for i in range(len(words)):\n",
        "    for j in range(len(words)):\n",
        "        attention_matrix[i][j] = self_attention(word_vectors[words[i]], word_vectors[words[j]]) # ë‹¨ì–´ iì™€ ë‹¨ì–´ jì˜ ë²¡í„° ì‚¬ì´ì˜ self-attention ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ í–‰ë ¬ì— ì €ì¥\n",
        "\n",
        "print(\"Self-Attention Matrix:\") # ê²°ê³¼ ì¶œë ¥\n",
        "print(attention_matrix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Multi-Head Self AttentionğŸ“Œ**\n",
        "\n",
        "ì•„ë˜ ì½”ë“œë¥¼ ìˆ˜í–‰í•´ë³´ê³ , Multi-Head Self Attentionì€ ì–´ë–¤ ë©”ì»¤ë‹ˆì¦˜ì¸ì§€ ì„¤ëª…í•˜ê³ ,\n",
        "\n",
        " ê·¸ ì„¤ëª…ì— ë§ê²Œ ê° ì½”ë“œì— ì§ì ‘ ì£¼ì„ì„ ë‹¬ì•„ë´…ì‹œë‹¤.\n",
        "\n",
        " âœ…ì„¤ëª…: Multi-Head Self Attentionì€ ì…ë ¥ ì‹œí€€ìŠ¤ì˜ ê° ìš”ì†Œê°€ ì—¬ëŸ¬ ê°€ì§€ ì‹œê°ì—ì„œ ìƒí˜¸ì‘ìš©í•˜ì—¬ ë” ë‹¤ì–‘í•œ ì •ë³´ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜ì´ë‹¤. ê¸°ë³¸ì ì¸ self-attentionê³¼ ë™ì¼í•˜ê²Œ Query, Key, Valueë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ, ì´ë¥¼ ì—¬ëŸ¬ ê°œì˜ headë¡œ ë‚˜ëˆ„ì–´ ë…ë¦½ì ìœ¼ë¡œ attentionì„ ìˆ˜í–‰í•œë‹¤. ê° headëŠ” ì„œë¡œ ë‹¤ë¥¸ ì •ë³´ì— ì§‘ì¤‘í•˜ë©°, ê°ê¸° ë‹¤ë¥¸ Query, Key, Value ë²¡í„°ë¥¼ ìƒì„±í•´ ê°ê°ì˜ Attention Scoreë¥¼ ê³„ì‚°í•œë‹¤. ì´ë ‡ê²Œ ì—¬ëŸ¬ headì—ì„œ ë‚˜ì˜¨ Attention Scoreë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ë‹¤ì–‘í•œ Attention Weightê°€ ìƒì„±ë˜ë©°, ì´ Weightì™€ Valueë¥¼ ì‚¬ìš©í•´ ê°ê°ì˜ ì¶œë ¥ì„ ìƒì„±í•œ í›„, ì´ ì¶œë ¥ë“¤ì„ ê²°í•©í•˜ì—¬ ìµœì¢… ê²°ê³¼ë¥¼ ë§Œë“ ë‹¤. ì´ëŠ” ëª¨ë¸ì´ ë‹¤ì–‘í•œ ë¬¸ë§¥ ì •ë³´ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆê²Œ í•˜ê³ , ë” í’ë¶€í•œ í‘œí˜„ì„ ë§Œë“¤ ìˆ˜ ìˆê²Œ í•´ì¤€ë‹¤."
      ],
      "metadata": {
        "id": "WA3NEBQC-Dpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì—¬ëŸ¬ ê°œì˜ attention heads\n",
        "def multi_head_self_attention(query, key, heads=3): # ì—¬ëŸ¬ ê°œì˜ headsì— ëŒ€í•´ Queryì™€ Keyë¥¼ ë‚´ì í•˜ì—¬ Attention Score ê³„ì‚°\n",
        "    return [np.dot(query, key) for _ in range(heads)]\n",
        "\n",
        "multi_head_attention_matrix = np.zeros((len(words), len(words), 3))\n",
        "for i in range(len(words)):\n",
        "    for j in range(len(words)):\n",
        "        multi_head_attention_matrix[i][j] = multi_head_self_attention(word_vectors[words[i]], word_vectors[words[j]])  # ê° ë‹¨ì–´ ìŒì— ëŒ€í•´ ë‹¤ìˆ˜ì˜ attention head ê²°ê³¼ ê³„ì‚°\n",
        "\n",
        "print(\"\\nMulti-Head Self-Attention Matrix:\") # ê²°ê³¼ ì¶œë ¥\n",
        "print(multi_head_attention_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1bvP6lC-efR",
        "outputId": "c761b53f-4397-4367-efe5-04f80e155d21"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Multi-Head Self-Attention Matrix:\n",
            "[[[1. 1. 1.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [1. 1. 1.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [1. 1. 1.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Masked Multi-Head Self AttentionğŸ“Œ**\n",
        "\n",
        "ì•„ë˜ ì½”ë“œë¥¼ ìˆ˜í–‰í•´ë³´ê³ , Masked Multi-Head Self Attentionì€ ì–´ë–¤ ë©”ì»¤ë‹ˆì¦˜ì¸ì§€ ì„¤ëª…í•˜ê³ ,\n",
        "\n",
        " ê·¸ ì„¤ëª…ì— ë§ê²Œ ê° ì½”ë“œì— ì§ì ‘ ì£¼ì„ì„ ë‹¬ì•„ë´…ì‹œë‹¤.\n",
        "\n",
        " âœ…ì„¤ëª…: Masked Multi-Head Self Attentionì€ ë¯¸ë˜ì˜ ì •ë³´ê°€ í˜„ì¬ì˜ ê³„ì‚°ì— ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•Šë„ë¡ ì…ë ¥ ì‹œí€€ìŠ¤ì—ì„œ íŠ¹ì • ìœ„ì¹˜ì˜ ì •ë³´ë¥¼ ê°€ë¦¬ëŠ” ë©”ì»¤ë‹ˆì¦˜ì´ë‹¤. ì£¼ë¡œ ì‹œí€€ìŠ¤ ìƒì„± ëª¨ë¸ì—ì„œ ì‚¬ìš©ë˜ë©°, ëª¨ë¸ì´ ìˆœì°¨ì ìœ¼ë¡œ ë‹¤ìŒ í† í°ì„ ì˜ˆì¸¡í•  ë•Œ ë¯¸ë˜ì˜ ë‹¨ì–´ë¥¼ ë¯¸ë¦¬ ì•Œ ìˆ˜ ì—†ë„ë¡ í•˜ê¸° ìœ„í•´ ì‚¬ìš©ëœë‹¤. ê¸°ë³¸ì ì¸ Multi-Head Self Attentionì²˜ëŸ¼ ì—¬ëŸ¬ ê°œì˜ Query, Key, Value ë²¡í„°ë¥¼ ìƒì„±í•˜ê³  ì—¬ëŸ¬ headì—ì„œ ë…ë¦½ì ì¸ attentionì„ ìˆ˜í–‰í•˜ì§€ë§Œ, maskë¥¼ ì ìš©í•˜ì—¬ ë¯¸ë˜ì˜ ë‹¨ì–´ì— ëŒ€í•œ ì—°ì‚°ì„ ë¬´íš¨í™”í•œë‹¤. ì´ë¥¼ ìœ„í•´ Queryì™€ Key ê°„ì˜ Attention Score ê³„ì‚° ì‹œ, ë¯¸ë˜ í† í°ì— í•´ë‹¹í•˜ëŠ” ìœ„ì¹˜ì— í° ìŒìˆ˜ë¥¼ ë”í•´ softmaxë¥¼ ì ìš©í•œ í›„, ê·¸ ê°’ì´ 0ì— ê°€ê¹ê²Œ ë§Œë“¤ì–´ í•´ë‹¹ ìœ„ì¹˜ì˜ ì˜í–¥ì„ ì°¨ë‹¨í•œë‹¤. ì´í›„ ê° headì—ì„œ ê³„ì‚°ëœ Attention Weightì™€ Valueì˜ ê°€ì¤‘í•©ì„ í†µí•´ ì¶œë ¥ì„ ìƒì„±í•˜ê³ , ì—¬ëŸ¬ headì˜ ì¶œë ¥ì„ ê²°í•©í•˜ì—¬ ìµœì¢… ê²°ê³¼ë¥¼ ë§Œë“ ë‹¤. ì´ ë°©ì‹ì€ ëª¨ë¸ì´ ì‹œí€€ìŠ¤ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ìƒì„±í•  ë•Œ ë¯¸ë˜ ì •ë³´ ì—†ì´ ì´ì „ ë‹¨ì–´ë“¤ë§Œì„ ê³ ë ¤í•˜ë„ë¡ ë³´ì¥í•œë‹¤."
      ],
      "metadata": {
        "id": "lHm1Y03S-hz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ë§ˆìŠ¤í¬ ì¶”ê°€: í˜„ì¬ ë‹¨ì–´ ì´í›„ì˜ ë‹¨ì–´ëŠ” ê³„ì‚°í•˜ì§€ ì•ŠìŒ\n",
        "def masked_attention(query, key, mask): # Queryì™€ Keyì˜ ë‚´ì ì„ ê³„ì‚°, ë§ˆìŠ¤í¬ ê°’ì— ë”°ë¼ ê²°ê³¼ë¥¼ ì œí•œ\n",
        "    return np.dot(query, key) * mask\n",
        "\n",
        "mask = np.array([1, 1, 0])  # ì²« ë²ˆì§¸, ë‘ ë²ˆì§¸ëŠ” ë³´ì§€ë§Œ, ì„¸ ë²ˆì§¸ëŠ” ë³´ì§€ ì•ŠìŒ\n",
        "masked_attention_matrix = np.zeros((len(words), len(words)))\n",
        "for i in range(len(words)):\n",
        "    for j in range(len(words)):\n",
        "        masked_attention_matrix[i][j] = masked_attention(word_vectors[words[i]], word_vectors[words[j]], mask[j]) # ië²ˆì§¸ ë‹¨ì–´ë¥¼ queryë¡œ, jë²ˆì§¸ ë‹¨ì–´ë¥¼ keyë¡œ ì‚¬ìš©í•˜ë©°, ë§ˆìŠ¤í¬ë¥¼ ì ìš©í•´ attention score ê³„ì‚°\n",
        "\n",
        "print(\"\\nMasked Self-Attention Matrix:\") # ê²°ê³¼ ì¶œë ¥\n",
        "print(masked_attention_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hELE_Nyf-pOP",
        "outputId": "54d21afa-0265-44a1-a0f9-3efd97852bec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Masked Self-Attention Matrix:\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Cross AttentionğŸ“Œ**\n",
        "\n",
        "ì•„ë˜ ì½”ë“œë¥¼ ìˆ˜í–‰í•´ë³´ê³ , Cross Attentionì€ ì–´ë–¤ ë©”ì»¤ë‹ˆì¦˜ì¸ì§€ ì„¤ëª…í•˜ê³ ,\n",
        "\n",
        " ê·¸ ì„¤ëª…ì— ë§ê²Œ ê° ì½”ë“œì— ì§ì ‘ ì£¼ì„ì„ ë‹¬ì•„ë´…ì‹œë‹¤.\n",
        "\n",
        " âœ…ì„¤ëª…: Cross Attentionì€ ë‘ ê°€ì§€ ì„œë¡œ ë‹¤ë¥¸ ì…ë ¥ ì‹œí€€ìŠ¤ ê°„ì˜ ìƒí˜¸ì‘ìš©ì„ í•™ìŠµí•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜ì´ë‹¤. ì´ ë©”ì»¤ë‹ˆì¦˜ì€ í•œ ì‹œí€€ìŠ¤ì—ì„œ Queryë¥¼ ìƒì„±í•˜ê³ , ë‹¤ë¥¸ ì‹œí€€ìŠ¤ì—ì„œ Keyì™€ Valueë¥¼ ìƒì„±í•˜ì—¬ ë‘ ì‹œí€€ìŠ¤ ê°„ì˜ ì—°ê´€ì„±ì„ íŒŒì•…í•œë‹¤. ì¦‰, ìê¸° ìì‹ ì´ ì•„ë‹Œ ë‹¤ë¥¸ ì‹œí€€ìŠ¤ì˜ ì •ë³´ì— ì§‘ì¤‘í•˜ê²Œ ëœë‹¤. Queryì™€ Key ê°„ì˜ Attention Scoreë¥¼ ê³„ì‚°í•˜ì—¬ ë‘ ì‹œí€€ìŠ¤ ì‚¬ì´ì˜ ìƒí˜¸ì‘ìš©ì„ ì¸¡ì •í•˜ê³ , ì´ Scoreë¥¼ softmaxë¡œ ì •ê·œí™”í•´ Attention Weightë¥¼ ë§Œë“ ë‹¤. ì´ WeightëŠ” Key ì‹œí€€ìŠ¤ì™€ ì—°ê´€ëœ ì •ë³´ì˜ ì¤‘ìš”ë„ë¥¼ ë‚˜íƒ€ë‚´ë©°, ì´ë¥¼ ì‚¬ìš©í•´ Value ì‹œí€€ìŠ¤ì˜ ì •ë³´ë¥¼ ê°€ì¤‘í•©í•´ ìµœì¢… ì¶œë ¥ì„ ìƒì„±í•œë‹¤. Cross Attentionì€ ë‹¤ì–‘í•œ ì‹œí€€ìŠ¤ ê°„ì˜ ìƒí˜¸ ê´€ê³„ë¥¼ í•™ìŠµí•˜ëŠ” ë° ìœ ìš©í•˜ë©°, ëŒ€í‘œì ìœ¼ë¡œ Transformer ê¸°ë°˜ ëª¨ë¸ì—ì„œ ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°ì—ì„œ ì‚¬ìš©ëœë‹¤. ì¸ì½”ë”ì˜ ì¶œë ¥ì´ ë””ì½”ë”ì˜ Queryì™€ ìƒí˜¸ì‘ìš©í•˜ë©°, ë””ì½”ë”ëŠ” ì£¼ì–´ì§„ ì‹œí€€ìŠ¤ì™€ ê´€ë ¨ëœ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì¸ì½”ë”ì˜ ì¶œë ¥ì—ì„œ ì¶”ì¶œí•˜ê²Œ ëœë‹¤.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wEiAlmYi-xg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì…ë ¥ ë¬¸ì¥ê³¼ ì‘ë‹µ ë¬¸ì¥\n",
        "question_words = ['ë„ˆëŠ”', 'ì‚¬ê³¼ë¥¼']\n",
        "answer_words = ['ë‚˜ëŠ”', 'ë¨¹ì—ˆë‹¤']\n",
        "question_vectors = {\n",
        "    'ë„ˆëŠ”': np.array([1, 0]),\n",
        "    'ì‚¬ê³¼ë¥¼': np.array([0, 1])\n",
        "}\n",
        "answer_vectors = {\n",
        "    'ë‚˜ëŠ”': np.array([1, 0]),\n",
        "    'ë¨¹ì—ˆë‹¤': np.array([0, 1])\n",
        "}\n",
        "\n",
        "# Cross-Attention\n",
        "cross_attention_matrix = np.zeros((len(question_words), len(answer_words)))\n",
        "for i in range(len(question_words)):\n",
        "    for j in range(len(answer_words)):\n",
        "        cross_attention_matrix[i][j] = np.dot(question_vectors[question_words[i]], answer_vectors[answer_words[j]])  # ië²ˆì§¸ ì§ˆë¬¸ ë‹¨ì–´ì™€ jë²ˆì§¸ ì‘ë‹µ ë‹¨ì–´ì˜ ë²¡í„° ê°„ì˜ ë‚´ì ì„ ê³„ì‚°í•˜ì—¬ attention score êµ¬í•¨\n",
        "\n",
        "print(\"\\nCross-Attention Matrix:\") # ê²°ê³¼ ì¶œë ¥\n",
        "print(cross_attention_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2871Q9r-5ZP",
        "outputId": "89425e17-ffa6-4251-f476-627a3ecff021"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cross-Attention Matrix:\n",
            "[[1. 0.]\n",
            " [0. 1.]]\n"
          ]
        }
      ]
    }
  ]
}