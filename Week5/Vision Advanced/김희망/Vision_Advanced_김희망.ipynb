{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ARB6yuk9zpD"
      },
      "source": [
        "## ToBigs 5ì£¼ì°¨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7NzhIu69zpG"
      },
      "source": [
        "### Vision Advanced ê³¼ì œ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKlzYdE49zpG"
      },
      "source": [
        "#### ë¬¸ì œ 1.\n",
        "\n",
        "Object Detection ì—ëŠ” 2-stage model ê³¼ 1-stage modelì´ ì¡´ì¬í•©ë‹ˆë‹¤.  \n",
        "ê° ìœ í˜•ì— í•´ë‹¹í•˜ëŠ” modelì„ í•˜ë‚˜ì”© ì„ ì •í•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”. (ë‹¨, ì„¸ì…˜ ì‹œê°„ì— ì„¤ëª…í•œ ëª¨ë¸ê³¼ ì•„ë˜ ì œì‹œëœ ëª¨ë¸ì€ ì œì™¸í•  ê²ƒ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZ3sbOc19zpG"
      },
      "outputs": [],
      "source": [
        "#### ë‹µì•ˆ ì‘ì„±\n",
        "\n",
        "# 1-stage model: RetinaNet\n",
        "\n",
        "## í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Focal Lossë¥¼ ë„ì…í•œ ê²ƒì„ íŠ¹ì§•ìœ¼ë¡œ í•œë‹¤. ë‹¤ë¥¸ ëª¨ë¸ê³¼ ê¸°ë³¸ì ì¸ ê³¨ìëŠ” ë˜‘ê°™ì§€ë§Œ ë¶„ë¥˜ ë¬¸ì œë¥¼ ë”ìš± ì˜ í•´ê²°í•˜ê¸° ìœ„í•´ ë‹¤ë¥¸ ëª¨ë¸ê³¼ ë‹¤ë¥¸ loss functionì„ í™œìš©í•˜ëŠ”ê²Œ íŠ¹ì§•ì´ë‹¤.\n",
        "## í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œëŠ” ì‚¬ì§„ì—ëŠ” ê°ì²´ë³´ë‹¤ ë°°ê²½ì´ ë” ë§ê¸° ë•Œë¬¸ì— ë°°ê²½ì˜ classë¥¼ ì˜ˆì¸¡í•˜ê¸°ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ì‰½ì§€ë§Œ ê°ì²´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì€ ì–´ë µê¸°ì— í•™ìŠµì´ ë°°ê²½ì— ì§‘ì¤‘ë˜ëŠ” ë¬¸ì œì´ë‹¤.\n",
        "## Focal lossëŠ” ë°°ê²½ê³¼ ê°™ì€ ì‰¬ìš´ ì˜ˆì¸¡ì€ ê°€ì¤‘ì¹˜ë¥¼ ë‚®ì¶”ê³  ê°ì²´ì™€ ê°™ì´ ì–´ë ¤ìš´ ì˜ˆì¸¡ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë†’ì„ìœ¼ë¡œì¨ ê°ì²´ íƒì§€ì— ëŒ€í•œ ì„±ëŠ¥ì„ í–¥ìƒí•  ìˆ˜ ìˆë‹¤.\n",
        "\n",
        "# 2-stage model: Mask R-CNN\n",
        "\n",
        "## Mask R-CNNëŠ” ê°ì²´ì˜ ê²½ê³„ë¥¼ í”½ì…€ ë‹¨ìœ„ê¹Œì§€ êµ¬ë¶„(Instance Segmentation)í•˜ê¸° ìœ„í•´ Mask Branchë¼ëŠ” ê³¼ì •ì„ ê±°ì¹œë‹¤.\n",
        "## ê¸°ì¡´ ë°©ì‹ëŒ€ë¡œ ê°ì²´ê°€ ìˆì„ ê²ƒì´ë¼ ì¶”ì •ë˜ëŠ” Region Proposalì„ íŠ¹ì • í¬ê¸°ì˜ feature mapìœ¼ë¡œ ë³€í™˜ í›„ í•´ë‹¹ ì§€ì—­ì˜ ê°ì²´ê°€ ë¬´ì—‡ì¼ì§€ ë¶„ë¥˜í•œë‹¤.\n",
        "## ì´í›„ í•´ë‹¹ ì˜ì—­ì—ì„œ í”½ì…€ ë‹¨ìœ„ ì˜ì—­ë§ˆë‹¤ ë¶„ë¥˜ëœ ê°ì²´ê°€ ì†í•˜ëŠ”ì§€ íƒì§€í•˜ì—¬ ê²°ê³¼ì ìœ¼ë¡œ ê°ì²´ì˜ ê²½ê³„ë¥¼ ì„¸ë°€í•˜ê²Œ íƒì§€í•œë‹¤.\n",
        "## ì´ë•Œ í”½ì…€ë§ˆë‹¤ Binary Mask(ê°ì²´ê°€ ì†í•˜ë©´ 1, ì•„ë‹ˆë©´ 0) í˜•ì‹ìœ¼ë¡œ ê°’ì„ ë°˜í™˜í•˜ë©° 1ì´ë©´ í•´ë‹¹ í”½ì…€ì´ ì˜ˆì¸¡í•œ ê°ì²´ê°€ ì†í•  ê²ƒìœ¼ë¡œ íŒë‹¨í•˜ê³  0ì´ë©´ ë°°ê²½ìœ¼ë¡œ íŒë‹¨í•œë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvw64DOH9zpH"
      },
      "source": [
        "#### ë¬¸ì œ 2.\n",
        "\n",
        "ì•„ë˜ ì œì‹œëœ FasterRCNN ê³¼ YOLOv5 ë¥¼ ê°ê° ì‹¤í–‰í•©ë‹ˆë‹¤.  \n",
        "ì‹¤í–‰ ê²°ê³¼ë¥¼ ì œì‹œí•˜ê³  ë‘ ëª¨ë¸ ì‚¬ì´ì˜ ì°¨ì´ì ì„ ì‹¤í–‰ ê²°ê³¼ì— ê·¼ê±°í•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k_uN8DZs9zpH"
      },
      "outputs": [],
      "source": [
        "## Package Import\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models, transforms\n",
        "from torchvision.datasets import CocoDetection\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "import numpy as np\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iK4_kHM1ALw0"
      },
      "outputs": [],
      "source": [
        "## Data Download\n",
        "\n",
        "import os\n",
        "os.makedirs('./data/', exist_ok=True)\n",
        "os.makedirs('./data/images/', exist_ok=True)\n",
        "\n",
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "!unzip annotations_trainval2017.zip -d ./data/\n",
        "!wget http://images.cocodataset.org/zips/val2017.zip\n",
        "!unzip val2017.zip -d ./data/images/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kQzE9KrL9zpI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67ebb851-85d1-422f-f262-ea4986d085cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=1.14s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160M/160M [00:01<00:00, 86.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì†Œìš” ì‹œê°„: 58.27ì´ˆ\n",
            "ì •í™•ë„: 20.46%\n"
          ]
        }
      ],
      "source": [
        "## FasterRCNN\n",
        "\n",
        "# ê²½ë¡œ ì„¤ì •\n",
        "image_dir = \"./data/images/val2017/\"\n",
        "json_path = \"./data/annotations/instances_val2017.json\"\n",
        "\n",
        "# Transform ì„¤ì •\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Datasetê³¼ DataLoader ì„¤ì •\n",
        "dataset = CocoDetection(root=image_dir, annFile=json_path, transform=transform)\n",
        "data_loader = DataLoader(dataset, batch_size=4, shuffle=False, num_workers=2, collate_fn=lambda x: tuple(zip(*x)))\n",
        "\n",
        "# ëª¨ë¸ ë¡œë“œ ë° ì„¤ì •\n",
        "model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "# ëª¨ë¸ì˜ í´ë˜ìŠ¤ ìˆ˜ë¥¼ 3ê°œë¡œ ì„¤ì • (ë°°ê²½ í¬í•¨í•´ì„œ 0, 2, background)\n",
        "num_classes = 3  # COCOì˜ ê²½ìš° background í¬í•¨ (0, 2 ë‘ ê°œì˜ í´ë˜ìŠ¤ + ë°°ê²½)\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "# GPU ì‚¬ìš© ê°€ëŠ¥ ì‹œ GPUë¡œ ì„¤ì •\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
        "model.eval()\n",
        "\n",
        "# ì •í™•ë„ ê³„ì‚°ì„ ìœ„í•œ ë³€ìˆ˜\n",
        "total_correct = 0\n",
        "total_predictions = 0\n",
        "\n",
        "# ì†Œìš” ì‹œê°„ ì¸¡ì • ì‹œì‘\n",
        "start_time = time.time()\n",
        "\n",
        "# 100ì¥ ì˜ˆì¸¡ ì†ë„ë¥¼ ë¹„êµ\n",
        "cnt = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, targets in data_loader:\n",
        "        cnt += 1\n",
        "        images = list(image.to(device) for image in images)\n",
        "\n",
        "        # ê° ì´ë¯¸ì§€ì˜ íƒ€ê¹ƒì„ ì ì ˆíˆ ë³€í™˜í•˜ì—¬ GPUë¡œ ì „ì†¡\n",
        "        processed_targets = []\n",
        "        for target in targets:\n",
        "            processed_target = {}\n",
        "            processed_target['boxes'] = torch.tensor([ann['bbox'] for ann in target]).to(device)\n",
        "            processed_target['labels'] = torch.tensor([ann['category_id'] for ann in target]).to(device)\n",
        "            processed_targets.append(processed_target)\n",
        "\n",
        "        # ëª¨ë¸ ì˜ˆì¸¡\n",
        "        outputs = model(images)\n",
        "\n",
        "        for i, output in enumerate(outputs):\n",
        "            pred_labels = output['labels'].cpu().numpy()\n",
        "            true_labels = processed_targets[i]['labels'].cpu().numpy()\n",
        "\n",
        "            # ì˜ˆì¸¡ ìˆ˜ê°€ ì‹¤ì œ ë¼ë²¨ ìˆ˜ë³´ë‹¤ ë§ì€ ê²½ìš° ì˜ˆì¸¡ ìˆ˜ë¥¼ ì˜ë¼ëƒ„\n",
        "            if len(pred_labels) > len(true_labels):\n",
        "                pred_labels = pred_labels[:len(true_labels)]\n",
        "\n",
        "            # ì˜ˆì¸¡ ë ˆì´ë¸”ê³¼ ì‹¤ì œ ë ˆì´ë¸”ì´ ì–¼ë§ˆë‚˜ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸\n",
        "            correct = np.sum(pred_labels == true_labels[:len(pred_labels)])\n",
        "            total_correct += correct\n",
        "            total_predictions += len(true_labels)\n",
        "\n",
        "        if cnt == 100:\n",
        "            break\n",
        "\n",
        "# ì†Œìš” ì‹œê°„ ì¸¡ì • ì¢…ë£Œ\n",
        "end_time = time.time()\n",
        "\n",
        "# ì†Œìš” ì‹œê°„ ë° ì •í™•ë„ ì¶œë ¥\n",
        "time_taken = end_time - start_time\n",
        "accuracy = total_correct / total_predictions if total_predictions > 0 else 0\n",
        "\n",
        "print(f\"ì†Œìš” ì‹œê°„: {time_taken:.2f}ì´ˆ\")\n",
        "print(f\"ì •í™•ë„: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "stB0A3MN9zpI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f511d2e-3e7f-4786-af13-b618be465fb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.80s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['gitpython>=3.1.30'] not found, attempting AutoUpdate...\n",
            "Collecting gitpython>=3.1.30\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 207.3/207.3 kB 12.8 MB/s eta 0:00:00\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 62.7/62.7 kB 299.2 MB/s eta 0:00:00\n",
            "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, gitdb, gitpython\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 smmap-5.0.1\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 2.7s, installed 1 package: ['gitpython>=3.1.30']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ğŸš€ 2024-9-24 Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.1M/14.1M [00:00<00:00, 118MB/s] \n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì†Œìš” ì‹œê°„: 28.63ì´ˆ\n",
            "ì •í™•ë„: 0.28%\n"
          ]
        }
      ],
      "source": [
        "## YOLOv5\n",
        "\n",
        "# ê²½ë¡œ ì„¤ì •\n",
        "image_dir = \"./data/images/val2017/\"\n",
        "json_path = \"./data/annotations/instances_val2017.json\"\n",
        "\n",
        "# Transform ì„¤ì •\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((640, 640)),  # YOLOv5ì˜ ê¸°ë³¸ ì…ë ¥ í¬ê¸°\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Datasetê³¼ DataLoader ì„¤ì •\n",
        "dataset = CocoDetection(root=image_dir, annFile=json_path, transform=transform)\n",
        "data_loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=2)\n",
        "\n",
        "# ëª¨ë¸ ë¡œë“œ (PyTorch Hubì—ì„œ COCOë¡œ ì‚¬ì „ í•™ìŠµëœ YOLOv5 ëª¨ë¸ ë¡œë“œ)\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "\n",
        "# GPU ì‚¬ìš© ê°€ëŠ¥ ì‹œ GPUë¡œ ì„¤ì •\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# ì •í™•ë„ ê³„ì‚°ì„ ìœ„í•œ ë³€ìˆ˜\n",
        "total_correct = 0\n",
        "total_predictions = 0\n",
        "\n",
        "# ì†Œìš” ì‹œê°„ ì¸¡ì • ì‹œì‘\n",
        "start_time = time.time()\n",
        "\n",
        "# 100ì¥ ì˜ˆì¸¡ ì†ë„ë¥¼ ë¹„êµ\n",
        "cnt = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, targets in data_loader:\n",
        "        cnt += 1\n",
        "        images = images.to(device)\n",
        "\n",
        "        # ëª¨ë¸ ì˜ˆì¸¡\n",
        "        outputs = model(images)\n",
        "\n",
        "        # ì˜ˆì¸¡ëœ ë°”ìš´ë”© ë°•ìŠ¤ì™€ í´ë˜ìŠ¤ ì •ë³´ ì¶”ì¶œ\n",
        "        for output in outputs:\n",
        "            pred_labels = output[:, 5:].argmax(1).cpu().numpy()  # ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ ë ˆì´ë¸”\n",
        "\n",
        "            # ì‹¤ì œ ë¼ë²¨ì„ ì¶”ì¶œí•˜ê³ , ì˜ˆì¸¡ëœ ë¼ë²¨ê³¼ ë¹„êµ\n",
        "            true_labels = [t['category_id'].item() for t in targets]\n",
        "\n",
        "            # ì˜ˆì¸¡ëœ ë¼ë²¨ê³¼ ì‹¤ì œ ë¼ë²¨ì´ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸\n",
        "            correct = np.sum(pred_labels[:len(true_labels)] == true_labels)\n",
        "            total_correct += correct\n",
        "            total_predictions += len(true_labels)\n",
        "\n",
        "        if cnt == 100:\n",
        "            break\n",
        "\n",
        "# ì†Œìš” ì‹œê°„ ì¸¡ì • ì¢…ë£Œ\n",
        "end_time = time.time()\n",
        "\n",
        "# ì†Œìš” ì‹œê°„ ë° ì •í™•ë„ ì¶œë ¥\n",
        "time_taken = end_time - start_time\n",
        "\n",
        "# ì •í™•ë„ ê³„ì‚°\n",
        "if total_predictions > 0:\n",
        "    accuracy = (total_correct / total_predictions) * 100\n",
        "else:\n",
        "    accuracy = 0\n",
        "\n",
        "# ì†Œìš” ì‹œê°„ ë° ì •í™•ë„ ì¶œë ¥\n",
        "print(f\"ì†Œìš” ì‹œê°„: {time_taken:.2f}ì´ˆ\")\n",
        "print(f\"ì •í™•ë„: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FasterRCNN: ì†Œìš” ì‹œê°„: 58.27ì´ˆ, ì •í™•ë„: 20.46%\n",
        "\n",
        "### YOLOv5: ì†Œìš” ì‹œê°„: 28.63ì´ˆ, ì •í™•ë„: 0.28%\n",
        "\n",
        "#### FasterRCNNì˜ ê²½ìš° Two-stage ëª¨ë¸ì´ê¸° ë•Œë¬¸ì— í›„ë³´ ì˜ì—­ì„ ë¨¼ì € ì„ ë°œí•œ ë’¤ì— ì´ ì˜ì—­ì„ ì„¸ë°€í•˜ê²Œ ë¶„ì„í•˜ë¯€ë¡œ ì •í™•ë„ê°€ ë†’ì§€ë§Œ ì†Œìš” ì‹œê°„ ì—­ì‹œ ë§ì´ ê±¸ë¦¬ê²Œ ëœë‹¤. ê·¸ëŸ¬ë‚˜ YOLOv5ì˜ ê²½ìš° One-stage ëª¨ë¸ì´ë¯€ë¡œ í•œ ë²ˆì— ëª¨ë“  ì²˜ë¦¬ë¥¼ ì™„ë£Œí•˜ì—¬ ì‹œê°„ì´ ìƒëŒ€ì ìœ¼ë¡œ ì ê²Œ ê±¸ë¦¬ì§€ë§Œ ì •í™•ë„ ì—­ì‹œ ë‚®ì•„ì§€ëŠ” ëª¨ìŠµì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤."
      ],
      "metadata": {
        "id": "caa4KO2if8LY"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}