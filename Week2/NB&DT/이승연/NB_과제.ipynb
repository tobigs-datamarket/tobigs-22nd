{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayesian Classifier\n",
    "### Q1. Bayes Rule을 이해하고 Naive  Bayes classifier가 사용하는 사후 확률 계산 과정을 서술하세요.\n",
    "\n",
    "- Bayes Rule:   \n",
    "$P(w_i|x) = \\frac{P(x|w_i)|P(w_i)}{P(x)} = \\frac{P(x|w_i) P(w_i)}{\\Sigma_j P(x|w_j)P(w_j)}$\n",
    "  -\n",
    "  - $P(x|w_i)\\text{: 사후 확률, posterior}\\\\\n",
    "P(x|w_i) \\text{: 가능도/우도, likelihood}\\\\\n",
    "P(w_i) \\text{: 사전 확률, prior}\\\\\n",
    "P(x) \\text{: 증거, evidence}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A1. \n",
    "\n",
    "According to the Naive Bayes assumption, the features are considered independent of each other, so the likelihood $P(\\mathbf{x} \\mid C)$ can be expressed as the product of the individual likelihoods:\n",
    "\n",
    "$$\n",
    "P(\\mathbf{x} \\mid C) = P(x_1 \\mid C) \\cdot P(x_2 \\mid C) \\cdot \\ldots \\cdot P(x_d \\mid C) = \\prod_{i=1}^{d} P(x_i \\mid C)\n",
    "$$\n",
    "\n",
    "Therefore, the posterior probability can be calculated as follows:\n",
    "\n",
    "$$\n",
    "P(C \\mid \\mathbf{x}) = \\frac{P(C) \\cdot \\prod_{i=1}^{d} P(x_i \\mid C)}{P(\\mathbf{x})}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Naive Bayes Classification 방법을 이용해서 다음 생성된 리뷰 데이터에 기반한 감정 분석을 해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this great product! It exceeded my expe...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Worst purchase I have ever made. Completel...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is an average product, nothing special but ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Great service and who can help but love this d...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Terrible experience, I will never buy from thi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  I love this great product! It exceeded my expe...  positive\n",
       "1  The Worst purchase I have ever made. Completel...  negative\n",
       "2  It is an average product, nothing special but ...   neutral\n",
       "3  Great service and who can help but love this d...  positive\n",
       "4  Terrible experience, I will never buy from thi...  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리뷰 데이터 생성\n",
    "data = {\n",
    "    'review': [\n",
    "        'I love this great product! It exceeded my expectations.',\n",
    "        'The Worst purchase I have ever made. Completely useless.',\n",
    "        'It is an average product, nothing special but not terrible either.',\n",
    "        'Great service and who can help but love this design? Highly recommend!',\n",
    "        'Terrible experience, I will never buy from this poor brand again.',\n",
    "        'It’s acceptable, but I expected better service, not just an acceptable one.',\n",
    "        'Absolutely wonderful! I am very satisfied with this great service.',\n",
    "        'The quality is poor and it broke after one use. Terrible enough!',\n",
    "        'Acceptable product for the price, but there are better options out there.',\n",
    "        'Great quality and fast shipping with wonderful service! I love it'\n",
    "    ],\n",
    "    'sentiment': [\n",
    "        'positive', 'negative', 'neutral', 'positive', 'negative',\n",
    "        'neutral', 'positive', 'negative', 'neutral', 'positive',\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 리스트 정의\n",
    "stopwords = ['i', 'my', 'am', 'this', 'it', 'its', 'an', 'a', 'the', 'is', 'are', 'and', 'product', 'service']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 전처리 함수 정의\n",
    "def preprocess_text(text):\n",
    "    # 소문자로 변환\n",
    "    text = text.lower()\n",
    "    # 특수 기호 제거\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # 불용어 제거\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stopwords]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# 모든 리뷰에 대해 전처리 수행\n",
    "df['review'] = df['review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적인 데이터 전처리가 완료되었습니다!\n",
    "이제부터 직접 나이브 베이지안 분류를 수행해 봅시다.  \n",
    "우리가 분류하고자 하는 문장은 총 두가지 입니다.  \n",
    "전처리가 완료되었다고 치고,   \n",
    "첫번째 문장은 **'love, great, awesome'**,  \n",
    "두번째 문장은 **'terrible, not, never'** 입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전 확률 $P(positive), P(negative), P(neutral)$을 구합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사전 확률:\n",
      " sentiment\n",
      "positive    0.4\n",
      "negative    0.3\n",
      "neutral     0.3\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 사전 확률 구하는 코드를 작성해주세요.\n",
    "prior_probabilities = df['sentiment'].value_counts(normalize=True)\n",
    "print(\"사전 확률:\\n\", prior_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가능도를 구하기 위한 확률들을 계산합니다.  \n",
    "예: 첫번째 문장 분류를 위해서는, $P(love|positive), P(great|positive), P(awesome|positive)\\\\\n",
    "P(love|negative), P(great|negative), P(awesome|negative)\\\\\n",
    "P(love|neutral), P(great|neutral), P(great|neutral)$를 구합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 때 CountVectorizer를 사용하여 도출한 단어 벡터를 활용하면 확률들을 간편하게 구할 수 있습니다.  \n",
    "참고: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "review_array = vectorizer.fit_transform(df['review']).toarray()\n",
    "review_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['absolutely', 'acceptable', 'after', 'again', 'average', 'better',\n",
       "       'brand', 'broke', 'but', 'buy', 'can', 'completely', 'design',\n",
       "       'either', 'enough', 'ever', 'exceeded', 'expectations', 'expected',\n",
       "       'experience', 'fast', 'for', 'from', 'great', 'have', 'help',\n",
       "       'highly', 'just', 'love', 'made', 'never', 'not', 'nothing', 'one',\n",
       "       'options', 'out', 'poor', 'price', 'purchase', 'quality',\n",
       "       'recommend', 'satisfied', 'shipping', 'special', 'terrible',\n",
       "       'there', 'use', 'useless', 'very', 'who', 'will', 'with',\n",
       "       'wonderful', 'worst'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 28,\n",
       " 'great': 23,\n",
       " 'exceeded': 16,\n",
       " 'expectations': 17,\n",
       " 'worst': 53,\n",
       " 'purchase': 38,\n",
       " 'have': 24,\n",
       " 'ever': 15,\n",
       " 'made': 29,\n",
       " 'completely': 11,\n",
       " 'useless': 47,\n",
       " 'average': 4,\n",
       " 'nothing': 32,\n",
       " 'special': 43,\n",
       " 'but': 8,\n",
       " 'not': 31,\n",
       " 'terrible': 44,\n",
       " 'either': 13,\n",
       " 'who': 49,\n",
       " 'can': 10,\n",
       " 'help': 25,\n",
       " 'design': 12,\n",
       " 'highly': 26,\n",
       " 'recommend': 40,\n",
       " 'experience': 19,\n",
       " 'will': 50,\n",
       " 'never': 30,\n",
       " 'buy': 9,\n",
       " 'from': 22,\n",
       " 'poor': 36,\n",
       " 'brand': 6,\n",
       " 'again': 3,\n",
       " 'acceptable': 1,\n",
       " 'expected': 18,\n",
       " 'better': 5,\n",
       " 'just': 27,\n",
       " 'one': 33,\n",
       " 'absolutely': 0,\n",
       " 'wonderful': 52,\n",
       " 'very': 48,\n",
       " 'satisfied': 41,\n",
       " 'with': 51,\n",
       " 'quality': 39,\n",
       " 'broke': 7,\n",
       " 'after': 2,\n",
       " 'use': 46,\n",
       " 'enough': 14,\n",
       " 'for': 21,\n",
       " 'price': 37,\n",
       " 'there': 45,\n",
       " 'options': 34,\n",
       " 'out': 35,\n",
       " 'fast': 20,\n",
       " 'shipping': 42}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>after</th>\n",
       "      <th>again</th>\n",
       "      <th>average</th>\n",
       "      <th>better</th>\n",
       "      <th>brand</th>\n",
       "      <th>broke</th>\n",
       "      <th>but</th>\n",
       "      <th>...</th>\n",
       "      <th>terrible</th>\n",
       "      <th>there</th>\n",
       "      <th>use</th>\n",
       "      <th>useless</th>\n",
       "      <th>very</th>\n",
       "      <th>who</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>wonderful</th>\n",
       "      <th>worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  absolutely  acceptable  after  again  average  better  brand  \\\n",
       "0  positive           0           0      0      0        0       0      0   \n",
       "1  negative           0           0      0      0        0       0      0   \n",
       "2   neutral           0           0      0      0        1       0      0   \n",
       "3  positive           0           0      0      0        0       0      0   \n",
       "4  negative           0           0      0      1        0       0      1   \n",
       "5   neutral           0           2      0      0        0       1      0   \n",
       "6  positive           1           0      0      0        0       0      0   \n",
       "7  negative           0           0      1      0        0       0      0   \n",
       "8   neutral           0           1      0      0        0       1      0   \n",
       "9  positive           0           0      0      0        0       0      0   \n",
       "\n",
       "   broke  but  ...  terrible  there  use  useless  very  who  will  with  \\\n",
       "0      0    0  ...         0      0    0        0     0    0     0     0   \n",
       "1      0    0  ...         0      0    0        1     0    0     0     0   \n",
       "2      0    1  ...         1      0    0        0     0    0     0     0   \n",
       "3      0    1  ...         0      0    0        0     0    1     0     0   \n",
       "4      0    0  ...         1      0    0        0     0    0     1     0   \n",
       "5      0    1  ...         0      0    0        0     0    0     0     0   \n",
       "6      0    0  ...         0      0    0        0     1    0     0     1   \n",
       "7      1    0  ...         1      0    1        0     0    0     0     0   \n",
       "8      0    1  ...         0      2    0        0     0    0     0     0   \n",
       "9      0    0  ...         0      0    0        0     0    0     0     1   \n",
       "\n",
       "   wonderful  worst  \n",
       "0          0      0  \n",
       "1          0      1  \n",
       "2          0      0  \n",
       "3          0      0  \n",
       "4          0      0  \n",
       "5          0      0  \n",
       "6          1      0  \n",
       "7          0      0  \n",
       "8          0      0  \n",
       "9          1      0  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_matrix = pd.DataFrame(review_array, columns = vectorizer.get_feature_names_out())\n",
    "frequency_matrix = pd.concat([df['sentiment'], frequency_matrix], axis=1)\n",
    "frequency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "조건부 확률:\n",
      " {'positive': {'very': 0.044444444444444446, 'fast': 0.044444444444444446, 'who': 0.044444444444444446, 'expectations': 0.044444444444444446, 'recommend': 0.044444444444444446, 'exceeded': 0.044444444444444446, 'highly': 0.044444444444444446, 'wonderful': 0.06666666666666667, 'absolutely': 0.044444444444444446, 'with': 0.06666666666666667, 'shipping': 0.044444444444444446, 'can': 0.044444444444444446, 'design': 0.044444444444444446, 'help': 0.044444444444444446, 'satisfied': 0.044444444444444446, 'love': 0.08888888888888889, 'but': 0.044444444444444446, 'quality': 0.044444444444444446, 'great': 0.1111111111111111}, 'negative': {'one': 0.043478260869565216, 'made': 0.043478260869565216, 'brand': 0.043478260869565216, 'purchase': 0.043478260869565216, 'after': 0.043478260869565216, 'have': 0.043478260869565216, 'experience': 0.043478260869565216, 'broke': 0.043478260869565216, 'useless': 0.043478260869565216, 'never': 0.043478260869565216, 'enough': 0.043478260869565216, 'buy': 0.043478260869565216, 'from': 0.043478260869565216, 'again': 0.043478260869565216, 'ever': 0.043478260869565216, 'terrible': 0.06521739130434782, 'worst': 0.043478260869565216, 'poor': 0.06521739130434782, 'use': 0.043478260869565216, 'quality': 0.043478260869565216, 'will': 0.043478260869565216, 'completely': 0.043478260869565216}, 'neutral': {'one': 0.04878048780487805, 'there': 0.07317073170731707, 'special': 0.04878048780487805, 'nothing': 0.04878048780487805, 'not': 0.07317073170731707, 'acceptable': 0.0975609756097561, 'terrible': 0.04878048780487805, 'out': 0.04878048780487805, 'options': 0.04878048780487805, 'but': 0.0975609756097561, 'average': 0.04878048780487805, 'expected': 0.04878048780487805, 'just': 0.04878048780487805, 'for': 0.04878048780487805, 'better': 0.07317073170731707, 'price': 0.04878048780487805, 'either': 0.04878048780487805}}\n"
     ]
    }
   ],
   "source": [
    "# 위와 같이 조건부 확률을 구하는 코드를 작성해주세요\n",
    "\n",
    "def tokenize(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    return text.split()\n",
    "\n",
    "df['tokens'] = df['review'].apply(tokenize)\n",
    "\n",
    "token_by_sentiment = {\n",
    "    sentiment: sum(df[df['sentiment'] == sentiment]['tokens'], [])\n",
    "    for sentiment in df['sentiment'].unique()\n",
    "}\n",
    "\n",
    "conditional_probabilities = {\n",
    "    sentiment: {token: (tokens.count(token) + 1) / (len(tokens) + len(set(token_by_sentiment[sentiment])))\n",
    "                for token in set(tokens)}\n",
    "    for sentiment, tokens in token_by_sentiment.items()\n",
    "}\n",
    "\n",
    "print(\"조건부 확률:\\n\", conditional_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "독립성 가정을 이용하여 가능도(likelihood)를 구합니다.  \n",
    "첫번째 문장 예시: $P(love, great, awesome|positive), P(love, great, awesome|negative), P(love, great, awesome|neutral)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihoods for target_review1:\n",
      "Likelihoods for 'positive': [0.08888888888888889, 0.1111111111111111, 0.034482758620689655]\n",
      "Likelihoods for 'negative': [0.037037037037037035, 0.037037037037037035, 0.037037037037037035]\n",
      "Likelihoods for 'neutral': [0.037037037037037035, 0.037037037037037035, 0.037037037037037035]\n",
      "\n",
      "Likelihoods for target_review2:\n",
      "Likelihoods for 'positive': [0.034482758620689655, 0.034482758620689655, 0.034482758620689655]\n",
      "Likelihoods for 'negative': [0.06521739130434782, 0.043478260869565216, 0.037037037037037035]\n",
      "Likelihoods for 'neutral': [0.04878048780487805, 0.037037037037037035, 0.037037037037037035]\n"
     ]
    }
   ],
   "source": [
    "target_review1 = \"love great awesome\"\n",
    "target_review2 = \"terrible experience bad\"\n",
    "\n",
    "def calculate_likelihood(review, sentiment):\n",
    "    tokens = tokenize(review)\n",
    "    likelihood = [conditional_probabilities[sentiment].get(token, 1 / (len(token_by_sentiment[sentiment]) + len(set(tokens))))\n",
    "                  for token in tokens]\n",
    "    return likelihood\n",
    "\n",
    "print(\"Likelihoods for target_review1:\")\n",
    "for sentiment in df['sentiment'].unique():\n",
    "    print(f\"Likelihoods for '{sentiment}':\", calculate_likelihood(target_review1, sentiment))\n",
    "\n",
    "print(\"\\nLikelihoods for target_review2:\")\n",
    "for sentiment in df['sentiment'].unique():\n",
    "    print(f\"Likelihoods for '{sentiment}':\", calculate_likelihood(target_review2, sentiment))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 구한 사전 확률과 가능도를 이용하여 타겟 문장이 positive, negative, neutral일 확률을 구하고 최종적으로 어떤 감성일지 분석해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(positive|target_review1): 0.8171500630517023\n",
      "P(negative|target_review1): 0.0914249684741488\n",
      "P(neutral|target_review1): 0.0914249684741488\n",
      "P(positive|target_review2): 0.24125583538195833\n",
      "P(negative|target_review2): 0.4634521557286217\n",
      "P(neutral|target_review2): 0.29529200888942\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_posterior(review, sentiment):\n",
    "    prior = prior_probabilities[sentiment]\n",
    "    likelihood = np.prod(calculate_likelihood(review, sentiment))\n",
    "    evidence = sum([np.prod(calculate_likelihood(review, s)) * prior_probabilities[s] for s in df['sentiment'].unique()])\n",
    "    return (likelihood * prior) / evidence if evidence != 0 else 0\n",
    "\n",
    "# 첫번째 문장\n",
    "print(\"P(positive|target_review1):\", calculate_posterior(target_review1, 'positive'))\n",
    "print(\"P(negative|target_review1):\", calculate_posterior(target_review1, 'negative'))\n",
    "print(\"P(neutral|target_review1):\", calculate_posterior(target_review1, 'neutral'))\n",
    "\n",
    "# 두번째 문장\n",
    "print(\"P(positive|target_review2):\", calculate_posterior(target_review2, 'positive'))\n",
    "print(\"P(negative|target_review2):\", calculate_posterior(target_review2, 'negative'))\n",
    "print(\"P(neutral|target_review2):\", calculate_posterior(target_review2, 'neutral'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2-1.   \n",
    "Target review1의 분류 결과: positive   \n",
    "Target review2의 분류 결과: negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2-2. 나이브 베이지안 기반 확률을 구하는 과정에서 어떤 문제점을 발견할 수 있었나요? 그리고 그 문제를 해결하기 위한 방법에 대해 간략하게 조사 및 서술해 주세요. (힌트: Laplace smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2-2. 특정 단어가 훈련 데이터의 어떤 클래스에서도 등장하지 않으면 그 단어에 대한 조건부 확률이 0이 되는 문제가 발생함. 이로 인해 해당 클래스에 대한 전체 확률 계산이 왜곡될 수 있음. 이를 해결하기 위해 Laplace smoothing을 적용하면 모든 단어에 작은 확률을 부여하여 해당 문제를 방지할 수 있음."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
