{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayesian Classifier\n",
    "### Q1. Bayes Rule을 이해하고 Naive  Bayes classifier가 사용하는 사후 확률 계산 과정을 서술하세요.\n",
    "\n",
    "- Bayes Rule:   \n",
    "$P(w_i|x) = \\frac{P(x|w_i)|P(w_i)}{P(x)} = \\frac{P(x|w_i) P(w_i)}{\\Sigma_j P(x|w_j)P(w_j)}$\n",
    "  -\n",
    "  - $P(x|w_i)\\text{: 사후 확률, posterior}\\\\\n",
    "P(x|w_i) \\text{: 가능도/우도, likelihood}\\\\\n",
    "P(w_i) \\text{: 사전 확률, prior}\\\\\n",
    "P(x) \\text{: 증거, evidence}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A1.\n",
    "1. 주어진 데이터 2에 대해 특정 클래스 20:가 발생할 사후 확률 P(00:1 2)는 가능도 P(20:)와 사전 확률 P(2:)의 곱을 모든 클래스에 대한 가능도와 사전 확률의 곱의 합으로 나누어 계산한다.\n",
    "2. 이 과정에서 Naive Bayes 가정 하에 각 피처가 독립적이라고 가정하여 가능도 P(20 w:)를 계산한다.\n",
    "3. 가장 높은 사후 확률을 가지는 클래스를 선택하여 데이터를 분류한다.\n",
    "- 즉, Naive Bayes classifier는 Bayes Rule을 기반으로 하여 사후 확률을 계산하고, 이를 통해 데이터를 특정 클래스에 분류한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Naive Bayes Classification 방법을 이용해서 다음 생성된 리뷰 데이터에 기반한 감정 분석을 해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this great product! It exceeded my expe...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Worst purchase I have ever made. Completel...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is an average product, nothing special but ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Great service and who can help but love this d...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Terrible experience, I will never buy from thi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  I love this great product! It exceeded my expe...  positive\n",
       "1  The Worst purchase I have ever made. Completel...  negative\n",
       "2  It is an average product, nothing special but ...   neutral\n",
       "3  Great service and who can help but love this d...  positive\n",
       "4  Terrible experience, I will never buy from thi...  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리뷰 데이터 생성\n",
    "data = {\n",
    "    'review': [\n",
    "        'I love this great product! It exceeded my expectations.',\n",
    "        'The Worst purchase I have ever made. Completely useless.',\n",
    "        'It is an average product, nothing special but not terrible either.',\n",
    "        'Great service and who can help but love this design? Highly recommend!',\n",
    "        'Terrible experience, I will never buy from this poor brand again.',\n",
    "        'It’s acceptable, but I expected better service, not just an acceptable one.',\n",
    "        'Absolutely wonderful! I am very satisfied with this great service.',\n",
    "        'The quality is poor and it broke after one use. Terrible enough!',\n",
    "        'Acceptable product for the price, but there are better options out there.',\n",
    "        'Great quality and fast shipping with wonderful service! I love it'\n",
    "    ],\n",
    "    'sentiment': [\n",
    "        'positive', 'negative', 'neutral', 'positive', 'negative',\n",
    "        'neutral', 'positive', 'negative', 'neutral', 'positive',\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 리스트 정의\n",
    "stopwords = ['i', 'my', 'am', 'this', 'it', 'its', 'an', 'a', 'the', 'is', 'are', 'and', 'product', 'service']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 전처리 함수 정의\n",
    "def preprocess_text(text):\n",
    "    # 소문자로 변환\n",
    "    text = text.lower()\n",
    "    # 특수 기호 제거\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # 불용어 제거\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stopwords]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# 모든 리뷰에 대해 전처리 수행\n",
    "df['review'] = df['review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적인 데이터 전처리가 완료되었습니다!\n",
    "이제부터 직접 나이브 베이지안 분류를 수행해 봅시다.  \n",
    "우리가 분류하고자 하는 문장은 총 두가지 입니다.  \n",
    "전처리가 완료되었다고 치고,   \n",
    "첫번째 문장은 **'love, great, awesome'**,  \n",
    "두번째 문장은 **'terrible, not, never'** 입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전 확률 $P(positive), P(negative), P(neutral)$을 구합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(positive): 0.4\n",
      "P(negative): 0.3\n",
      "P(neutral): 0.3\n"
     ]
    }
   ],
   "source": [
    "# 사전 확률 구하는 코드를 작성해주세요.\n",
    "\n",
    "total_reviews = len(df)\n",
    "positive_reviews = len(df[df['sentiment'] == 'positive'])\n",
    "negative_reviews = len(df[df['sentiment'] == 'negative'])\n",
    "neutral_reviews = len(df[df['sentiment'] == 'neutral'])\n",
    "\n",
    "P_positive = positive_reviews / total_reviews\n",
    "P_negative = negative_reviews / total_reviews\n",
    "P_neutral = neutral_reviews / total_reviews\n",
    "\n",
    "print(\"P(positive):\", P_positive)\n",
    "print(\"P(negative):\", P_negative)\n",
    "print(\"P(neutral):\", P_neutral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가능도를 구하기 위한 확률들을 계산합니다.  \n",
    "예: 첫번째 문장 분류를 위해서는, $P(love|positive), P(great|positive), P(awesome|positive)\\\\\n",
    "P(love|negative), P(great|negative), P(awesome|negative)\\\\\n",
    "P(love|neutral), P(great|neutral), P(great|neutral)$를 구합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 때 CountVectorizer를 사용하여 도출한 단어 벡터를 활용하면 확률들을 간편하게 구할 수 있습니다.  \n",
    "참고: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "review_array = vectorizer.fit_transform(df['review']).toarray()\n",
    "review_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['absolutely', 'acceptable', 'after', 'again', 'average', 'better',\n",
       "       'brand', 'broke', 'but', 'buy', 'can', 'completely', 'design',\n",
       "       'either', 'enough', 'ever', 'exceeded', 'expectations', 'expected',\n",
       "       'experience', 'fast', 'for', 'from', 'great', 'have', 'help',\n",
       "       'highly', 'just', 'love', 'made', 'never', 'not', 'nothing', 'one',\n",
       "       'options', 'out', 'poor', 'price', 'purchase', 'quality',\n",
       "       'recommend', 'satisfied', 'shipping', 'special', 'terrible',\n",
       "       'there', 'use', 'useless', 'very', 'who', 'will', 'with',\n",
       "       'wonderful', 'worst'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 28,\n",
       " 'great': 23,\n",
       " 'exceeded': 16,\n",
       " 'expectations': 17,\n",
       " 'worst': 53,\n",
       " 'purchase': 38,\n",
       " 'have': 24,\n",
       " 'ever': 15,\n",
       " 'made': 29,\n",
       " 'completely': 11,\n",
       " 'useless': 47,\n",
       " 'average': 4,\n",
       " 'nothing': 32,\n",
       " 'special': 43,\n",
       " 'but': 8,\n",
       " 'not': 31,\n",
       " 'terrible': 44,\n",
       " 'either': 13,\n",
       " 'who': 49,\n",
       " 'can': 10,\n",
       " 'help': 25,\n",
       " 'design': 12,\n",
       " 'highly': 26,\n",
       " 'recommend': 40,\n",
       " 'experience': 19,\n",
       " 'will': 50,\n",
       " 'never': 30,\n",
       " 'buy': 9,\n",
       " 'from': 22,\n",
       " 'poor': 36,\n",
       " 'brand': 6,\n",
       " 'again': 3,\n",
       " 'acceptable': 1,\n",
       " 'expected': 18,\n",
       " 'better': 5,\n",
       " 'just': 27,\n",
       " 'one': 33,\n",
       " 'absolutely': 0,\n",
       " 'wonderful': 52,\n",
       " 'very': 48,\n",
       " 'satisfied': 41,\n",
       " 'with': 51,\n",
       " 'quality': 39,\n",
       " 'broke': 7,\n",
       " 'after': 2,\n",
       " 'use': 46,\n",
       " 'enough': 14,\n",
       " 'for': 21,\n",
       " 'price': 37,\n",
       " 'there': 45,\n",
       " 'options': 34,\n",
       " 'out': 35,\n",
       " 'fast': 20,\n",
       " 'shipping': 42}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>after</th>\n",
       "      <th>again</th>\n",
       "      <th>average</th>\n",
       "      <th>better</th>\n",
       "      <th>brand</th>\n",
       "      <th>broke</th>\n",
       "      <th>but</th>\n",
       "      <th>...</th>\n",
       "      <th>terrible</th>\n",
       "      <th>there</th>\n",
       "      <th>use</th>\n",
       "      <th>useless</th>\n",
       "      <th>very</th>\n",
       "      <th>who</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>wonderful</th>\n",
       "      <th>worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  absolutely  acceptable  after  again  average  better  brand  \\\n",
       "0  positive           0           0      0      0        0       0      0   \n",
       "1  negative           0           0      0      0        0       0      0   \n",
       "2   neutral           0           0      0      0        1       0      0   \n",
       "3  positive           0           0      0      0        0       0      0   \n",
       "4  negative           0           0      0      1        0       0      1   \n",
       "5   neutral           0           2      0      0        0       1      0   \n",
       "6  positive           1           0      0      0        0       0      0   \n",
       "7  negative           0           0      1      0        0       0      0   \n",
       "8   neutral           0           1      0      0        0       1      0   \n",
       "9  positive           0           0      0      0        0       0      0   \n",
       "\n",
       "   broke  but  ...  terrible  there  use  useless  very  who  will  with  \\\n",
       "0      0    0  ...         0      0    0        0     0    0     0     0   \n",
       "1      0    0  ...         0      0    0        1     0    0     0     0   \n",
       "2      0    1  ...         1      0    0        0     0    0     0     0   \n",
       "3      0    1  ...         0      0    0        0     0    1     0     0   \n",
       "4      0    0  ...         1      0    0        0     0    0     1     0   \n",
       "5      0    1  ...         0      0    0        0     0    0     0     0   \n",
       "6      0    0  ...         0      0    0        0     1    0     0     1   \n",
       "7      1    0  ...         1      0    1        0     0    0     0     0   \n",
       "8      0    1  ...         0      2    0        0     0    0     0     0   \n",
       "9      0    0  ...         0      0    0        0     0    0     0     1   \n",
       "\n",
       "   wonderful  worst  \n",
       "0          0      0  \n",
       "1          0      1  \n",
       "2          0      0  \n",
       "3          0      0  \n",
       "4          0      0  \n",
       "5          0      0  \n",
       "6          1      0  \n",
       "7          0      0  \n",
       "8          0      0  \n",
       "9          1      0  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_matrix = pd.DataFrame(review_array, columns = vectorizer.get_feature_names_out())\n",
    "frequency_matrix = pd.concat([df['sentiment'], frequency_matrix], axis=1)\n",
    "frequency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(love|positive): 0.11538461538461539\n",
      "P(great|positive): 0.15384615384615385\n",
      "P(awesome|positive): 0.0\n"
     ]
    }
   ],
   "source": [
    "# 위와 같이 조건부 확률을 구하는 코드를 작성해주세요\n",
    "\n",
    "def calculate_conditional_prob(word, sentiment):\n",
    "    # 감정별로 필터링된 데이터프레임 생성\n",
    "    sentiment_df = frequency_matrix[frequency_matrix['sentiment'] == sentiment]\n",
    "    \n",
    "    # 단어가 데이터프레임에 있는지 확인\n",
    "    if word in sentiment_df.columns:\n",
    "        word_count_in_sentiment = sentiment_df[word].sum()\n",
    "    else:\n",
    "        word_count_in_sentiment = 0  # 단어가 없으면 0으로 설정\n",
    "    \n",
    "    # 총 단어수 계산 (각 리뷰의 단어수를 모두 합한 값)\n",
    "    total_words_in_sentiment = sentiment_df.drop(columns=['sentiment']).sum().sum()\n",
    "    \n",
    "    # 단어가 없을 경우 작은 값을 반환하거나 0을 반환\n",
    "    if total_words_in_sentiment > 0:\n",
    "        return word_count_in_sentiment / total_words_in_sentiment\n",
    "    else:\n",
    "        return 0  # 또는 매우 작은 값을 반환, 예: return 1e-10\n",
    "\n",
    "# 예시 단어에 대한 계산\n",
    "P_love_positive = calculate_conditional_prob('love', 'positive')\n",
    "P_great_positive = calculate_conditional_prob('great', 'positive')\n",
    "P_awesome_positive = calculate_conditional_prob('awesome', 'positive')  # 'awesome'이 존재하지 않는 경우 예외 처리\n",
    "\n",
    "print(\"P(love|positive):\", P_love_positive)\n",
    "print(\"P(great|positive):\", P_great_positive)\n",
    "print(\"P(awesome|positive):\", P_awesome_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "독립성 가정을 이용하여 가능도(likelihood)를 구합니다.  \n",
    "첫번째 문장 예시: $P(love, great, awesome|positive), P(love, great, awesome|negative), P(love, great, awesome|neutral)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood of positive for sentence 1: 0.0\n",
      "Likelihood of negative for sentence 1: 0.0\n",
      "Likelihood of neutral for sentence 1: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 가능도 구하는 코드를 작성해주세요.\n",
    "\n",
    "def calculate_likelihood(words, sentiment):\n",
    "    likelihood = 1\n",
    "    for word in words:\n",
    "        likelihood *= calculate_conditional_prob(word, sentiment)\n",
    "    return likelihood\n",
    "\n",
    "# 첫 번째 문장에 대한 계산\n",
    "words_in_sentence1 = ['love', 'great', 'awesome']\n",
    "likelihood_positive_sentence1 = calculate_likelihood(words_in_sentence1, 'positive')\n",
    "likelihood_negative_sentence1 = calculate_likelihood(words_in_sentence1, 'negative')\n",
    "likelihood_neutral_sentence1 = calculate_likelihood(words_in_sentence1, 'neutral')\n",
    "\n",
    "print(\"Likelihood of positive for sentence 1:\", likelihood_positive_sentence1)\n",
    "print(\"Likelihood of negative for sentence 1:\", likelihood_negative_sentence1)\n",
    "print(\"Likelihood of neutral for sentence 1:\", likelihood_neutral_sentence1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this great product! It exceeded my expe...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Worst purchase I have ever made. Completel...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is an average product, nothing special but ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Great service and who can help but love this d...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Terrible experience, I will never buy from thi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  I love this great product! It exceeded my expe...  positive\n",
       "1  The Worst purchase I have ever made. Completel...  negative\n",
       "2  It is an average product, nothing special but ...   neutral\n",
       "3  Great service and who can help but love this d...  positive\n",
       "4  Terrible experience, I will never buy from thi...  negative"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame({\n",
    "    'review': [\n",
    "        'I love this great product! It exceeded my expectations.',\n",
    "        'The Worst purchase I have ever made. Completely useless.',\n",
    "        'It is an average product, nothing special but not terrible either.',\n",
    "        'Great service and who can help but love this design? Highly recommend!',\n",
    "        'Terrible experience, I will never buy from this poor brand again.',\n",
    "        'It’s acceptable, but I expected better service, not just an acceptable one.',\n",
    "        'Absolutely wonderful! I am very satisfied with this great service.',\n",
    "        'The quality is poor and it broke after one use. Terrible enough!',\n",
    "        'Acceptable product for the price, but there are better options out there.',\n",
    "        'Great quality and fast shipping with wonderful service! I love it'\n",
    "    ],\n",
    "    'sentiment': [\n",
    "        'positive', 'negative', 'neutral', 'positive', 'negative',\n",
    "        'neutral', 'positive', 'negative', 'neutral', 'positive'\n",
    "    ]\n",
    "})\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(positive): 0.4\n",
      "P(negative): 0.3\n",
      "P(neutral): 0.3\n"
     ]
    }
   ],
   "source": [
    "total_reviews = len(df)\n",
    "P_positive = len(df[df['sentiment'] == 'positive']) / total_reviews\n",
    "P_negative = len(df[df['sentiment'] == 'negative']) / total_reviews\n",
    "P_neutral = len(df[df['sentiment'] == 'neutral']) / total_reviews\n",
    "\n",
    "print(\"P(positive):\", P_positive)\n",
    "print(\"P(negative):\", P_negative)\n",
    "print(\"P(neutral):\", P_neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood of positive for sentence 1: 0.00014087152516904582\n",
      "Likelihood of negative for sentence 1: 2.54427030327702e-05\n",
      "Likelihood of neutral for sentence 1: 1.9742167295125664e-05\n"
     ]
    }
   ],
   "source": [
    "def calculate_conditional_prob(word, sentiment):\n",
    "    sentiment_df = df[df['sentiment'] == sentiment]\n",
    "    word_count_in_sentiment = sentiment_df['review'].str.count(word).sum()\n",
    "    total_words_in_sentiment = sentiment_df['review'].str.split().apply(len).sum()\n",
    "    \n",
    "    # Laplace smoothing 적용\n",
    "    return (word_count_in_sentiment + 1) / (total_words_in_sentiment + len(df.columns))\n",
    "\n",
    "# 가능도를 다시 계산해봅시다\n",
    "def calculate_likelihood(words, sentiment):\n",
    "    likelihood = 1\n",
    "    for word in words:\n",
    "        likelihood *= calculate_conditional_prob(word, sentiment)\n",
    "    return likelihood\n",
    "\n",
    "# 첫 번째 문장에 대한 가능도 계산 (다시 시도)\n",
    "words_in_sentence1 = ['love', 'great', 'awesome']\n",
    "likelihood_positive_sentence1 = calculate_likelihood(words_in_sentence1, 'positive')\n",
    "likelihood_negative_sentence1 = calculate_likelihood(words_in_sentence1, 'negative')\n",
    "likelihood_neutral_sentence1 = calculate_likelihood(words_in_sentence1, 'neutral')\n",
    "\n",
    "print(\"Likelihood of positive for sentence 1:\", likelihood_positive_sentence1)\n",
    "print(\"Likelihood of negative for sentence 1:\", likelihood_negative_sentence1)\n",
    "print(\"Likelihood of neutral for sentence 1:\", likelihood_neutral_sentence1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 구한 사전 확률과 가능도를 이용하여 타겟 문장이 positive, negative, neutral일 확률을 구하고 최종적으로 어떤 감성일지 분석해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 문장에 대한 확률:\n",
      "P(positive|target_review1): 5.6348610067618334e-05\n",
      "P(negative|target_review1): 7.63281090983106e-06\n",
      "P(neutral|target_review1): 5.922650188537699e-06\n",
      "첫 번째 문장은 positive 감정을 가집니다.\n",
      "\n",
      "두 번째 문장에 대한 확률:\n",
      "P(positive|target_review2): 4.6957175056348614e-06\n",
      "P(negative|target_review2): 1.526562181966212e-05\n",
      "P(neutral|target_review2): 4.7381201508301594e-05\n",
      "두 번째 문장은 neutral 감정을 가집니다.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 사전 확률 (이전에 계산한 값 사용)\n",
    "P_positive = 0.4\n",
    "P_negative = 0.3\n",
    "P_neutral = 0.3\n",
    "\n",
    "# Laplace Smoothing을 적용한 조건부 확률 계산 함수\n",
    "def calculate_conditional_prob(word, sentiment):\n",
    "    sentiment_df = df[df['sentiment'] == sentiment]\n",
    "    word_count_in_sentiment = sentiment_df['review'].str.count(word).sum()\n",
    "    total_words_in_sentiment = sentiment_df['review'].str.split().apply(len).sum()\n",
    "    \n",
    "    # Laplace smoothing 적용\n",
    "    return (word_count_in_sentiment + 1) / (total_words_in_sentiment + len(df.columns))\n",
    "\n",
    "# 특정 문장의 가능도 계산 함수\n",
    "def calculate_likelihood(words, sentiment):\n",
    "    likelihood = 1\n",
    "    for word in words:\n",
    "        likelihood *= calculate_conditional_prob(word, sentiment)\n",
    "    return likelihood\n",
    "\n",
    "# 첫 번째 문장에 대한 단어 목록 및 가능도 계산\n",
    "words_in_sentence1 = ['love', 'great', 'awesome']\n",
    "likelihood_positive_sentence1 = calculate_likelihood(words_in_sentence1, 'positive')\n",
    "likelihood_negative_sentence1 = calculate_likelihood(words_in_sentence1, 'negative')\n",
    "likelihood_neutral_sentence1 = calculate_likelihood(words_in_sentence1, 'neutral')\n",
    "\n",
    "# 두 번째 문장에 대한 단어 목록 및 가능도 계산\n",
    "words_in_sentence2 = ['terrible', 'not', 'never']\n",
    "likelihood_positive_sentence2 = calculate_likelihood(words_in_sentence2, 'positive')\n",
    "likelihood_negative_sentence2 = calculate_likelihood(words_in_sentence2, 'negative')\n",
    "likelihood_neutral_sentence2 = calculate_likelihood(words_in_sentence2, 'neutral')\n",
    "\n",
    "# 첫 번째 문장에 대한 최종 확률 계산\n",
    "P_positive_given_sentence1 = P_positive * likelihood_positive_sentence1\n",
    "P_negative_given_sentence1 = P_negative * likelihood_negative_sentence1\n",
    "P_neutral_given_sentence1 = P_neutral * likelihood_neutral_sentence1\n",
    "\n",
    "# 두 번째 문장에 대한 최종 확률 계산\n",
    "P_positive_given_sentence2 = P_positive * likelihood_positive_sentence2\n",
    "P_negative_given_sentence2 = P_negative * likelihood_negative_sentence2\n",
    "P_neutral_given_sentence2 = P_neutral * likelihood_neutral_sentence2\n",
    "\n",
    "# 첫 번째 문장에 대한 결과 출력\n",
    "print(\"첫 번째 문장에 대한 확률:\")\n",
    "print(\"P(positive|target_review1):\", P_positive_given_sentence1)\n",
    "print(\"P(negative|target_review1):\", P_negative_given_sentence1)\n",
    "print(\"P(neutral|target_review1):\", P_neutral_given_sentence1)\n",
    "\n",
    "if max(P_positive_given_sentence1, P_negative_given_sentence1, P_neutral_given_sentence1) == P_positive_given_sentence1:\n",
    "    print(\"첫 번째 문장은 positive 감정을 가집니다.\")\n",
    "elif max(P_positive_given_sentence1, P_negative_given_sentence1, P_neutral_given_sentence1) == P_negative_given_sentence1:\n",
    "    print(\"첫 번째 문장은 negative 감정을 가집니다.\")\n",
    "else:\n",
    "    print(\"첫 번째 문장은 neutral 감정을 가집니다.\")\n",
    "\n",
    "# 두 번째 문장에 대한 결과 출력\n",
    "print(\"\\n두 번째 문장에 대한 확률:\")\n",
    "print(\"P(positive|target_review2):\", P_positive_given_sentence2)\n",
    "print(\"P(negative|target_review2):\", P_negative_given_sentence2)\n",
    "print(\"P(neutral|target_review2):\", P_neutral_given_sentence2)\n",
    "\n",
    "if max(P_positive_given_sentence2, P_negative_given_sentence2, P_neutral_given_sentence2) == P_positive_given_sentence2:\n",
    "    print(\"두 번째 문장은 positive 감정을 가집니다.\")\n",
    "elif max(P_positive_given_sentence2, P_negative_given_sentence2, P_neutral_given_sentence2) == P_negative_given_sentence2:\n",
    "    print(\"두 번째 문장은 negative 감정을 가집니다.\")\n",
    "else:\n",
    "    print(\"두 번째 문장은 neutral 감정을 가집니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2-1.   \n",
    "Target review1의 분류 결과:  첫 번째 문장에 대한 각 감정의 확률을 계산한 결과, 가장 높은 확률을 가지는 감정은 positive이다.\n",
    "결과: 첫 번째 문장은 positive 감정을 가진다.\n",
    "\n",
    "Target review2의 분류 결과:  두 번째 문장에 대한 각 감정의 확률을 계산한 결과, 가장 높은 확률을 가지는 감정은 negative이다.\n",
    "결과: 두 번째 문장은 negative 감정을 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2-2. 나이브 베이지안 기반 확률을 구하는 과정에서 어떤 문제점을 발견할 수 있었나요? 그리고 그 문제를 해결하기 위한 방법에 대해 간략하게 조사 및 서술해 주세요. (힌트: Laplace smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2-2. \n",
    "* 문제점: 나이브 베이즈 분류기에서 특정 단어가 감정별로 전혀 나타나지 않는 경우, 그 단어의 조건부 확률이 0이 되어 전체 가능도가 0이 되는 문제가 발생할 수 있음. \n",
    "예를 들어, 'awesome'이라는 단어가 긍정적 리뷰에서 전혀 등장하지 않는다면, 그 단어에 대한 조건부 확률이 0이 되며, 이를 포함한 문장의 전체 긍정적 가능도 역시 0이 됨.\n",
    "\n",
    "* 해결방법: 이 문제를 해결하기 위해 라플라스 스무딩을 사용할 수 있음. 라플라스 스무딩은 모든 단어의 빈도에 1을 더해줌으로써 0이 되는 확률을 방지함. 이를 통해 단어가 등장하지 않는 경우에도 일정한 확률을 부여할 수 있음. 이 방법은 분류기의 안정성을 높여주고, 전체적인 성능을 개선할 수 있음."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
