{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayesian Classifier\n",
    "### Q1. Bayes Ruleì„ ì´í•´í•˜ê³  Naive  Bayes classifierê°€ ì‚¬ìš©í•˜ëŠ” ì‚¬í›„ í™•ë¥  ê³„ì‚° ê³¼ì •ì„ ì„œìˆ í•˜ì„¸ìš”.\n",
    "\n",
    "- Bayes Rule:   \n",
    "$P(w_i|x) = \\frac{P(x|w_i)|P(w_i)}{P(x)} = \\frac{P(x|w_i) P(w_i)}{\\Sigma_j P(x|w_j)P(w_j)}$\n",
    "  -\n",
    "  - $P(x|w_i)\\text{: ì‚¬í›„ í™•ë¥ , posterior}\\\\\n",
    "P(x|w_i) \\text{: ê°€ëŠ¥ë„/ìš°ë„, likelihood}\\\\\n",
    "P(w_i) \\text{: ì‚¬ì „ í™•ë¥ , prior}\\\\\n",
    "P(x) \\text{: ì¦ê±°, evidence}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A1. ì‚¬ì „ í™•ë¥ (Prior Probability) ì„ êµ¬í•˜ê³  ìš°ë„ë¥¼ êµ¬í•˜ê³  ì´ë¥¼ ì´ìš©í•´ ê³„ì‚°í•©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Naive Bayes Classification ë°©ë²•ì„ ì´ìš©í•´ì„œ ë‹¤ìŒ ìƒì„±ëœ ë¦¬ë·° ë°ì´í„°ì— ê¸°ë°˜í•œ ê°ì • ë¶„ì„ì„ í•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this great product! It exceeded my expe...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Worst purchase I have ever made. Completel...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is an average product, nothing special but ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Great service and who can help but love this d...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Terrible experience, I will never buy from thi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  I love this great product! It exceeded my expe...  positive\n",
       "1  The Worst purchase I have ever made. Completel...  negative\n",
       "2  It is an average product, nothing special but ...   neutral\n",
       "3  Great service and who can help but love this d...  positive\n",
       "4  Terrible experience, I will never buy from thi...  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë¦¬ë·° ë°ì´í„° ìƒì„±\n",
    "data = {\n",
    "    'review': [\n",
    "        'I love this great product! It exceeded my expectations.',\n",
    "        'The Worst purchase I have ever made. Completely useless.',\n",
    "        'It is an average product, nothing special but not terrible either.',\n",
    "        'Great service and who can help but love this design? Highly recommend!',\n",
    "        'Terrible experience, I will never buy from this poor brand again.',\n",
    "        'Itâ€™s acceptable, but I expected better service, not just an acceptable one.',\n",
    "        'Absolutely wonderful! I am very satisfied with this great service.',\n",
    "        'The quality is poor and it broke after one use. Terrible enough!',\n",
    "        'Acceptable product for the price, but there are better options out there.',\n",
    "        'Great quality and fast shipping with wonderful service! I love it'\n",
    "    ],\n",
    "    'sentiment': [\n",
    "        'positive', 'negative', 'neutral', 'positive', 'negative',\n",
    "        'neutral', 'positive', 'negative', 'neutral', 'positive',\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ ì •ì˜\n",
    "stopwords = ['i', 'my', 'am', 'this', 'it', 'its', 'an', 'a', 'the', 'is', 'are', 'and', 'product', 'service']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜\n",
    "def preprocess_text(text):\n",
    "    # ì†Œë¬¸ìë¡œ ë³€í™˜\n",
    "    text = text.lower()\n",
    "    # íŠ¹ìˆ˜ ê¸°í˜¸ ì œê±°\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # ë¶ˆìš©ì–´ ì œê±°\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stopwords]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# ëª¨ë“  ë¦¬ë·°ì— ëŒ€í•´ ì „ì²˜ë¦¬ ìˆ˜í–‰\n",
    "df['review'] = df['review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê¸°ë³¸ì ì¸ ë°ì´í„° ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n",
    "ì´ì œë¶€í„° ì§ì ‘ ë‚˜ì´ë¸Œ ë² ì´ì§€ì•ˆ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•´ ë´…ì‹œë‹¤.  \n",
    "ìš°ë¦¬ê°€ ë¶„ë¥˜í•˜ê³ ì í•˜ëŠ” ë¬¸ì¥ì€ ì´ ë‘ê°€ì§€ ì…ë‹ˆë‹¤.  \n",
    "ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆë‹¤ê³  ì¹˜ê³ ,   \n",
    "ì²«ë²ˆì§¸ ë¬¸ì¥ì€ **'love, great, awesome'**,  \n",
    "ë‘ë²ˆì§¸ ë¬¸ì¥ì€ **'terrible, not, never'** ì…ë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì‚¬ì „ í™•ë¥  $P(positive), P(negative), P(neutral)$ì„ êµ¬í•©ë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love great exceeded expectations</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worst purchase have ever made completely useless</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>average nothing special but not terrible either</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great who can help but love design highly reco...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>terrible experience will never buy from poor b...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acceptable but expected better not just accept...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>absolutely wonderful very satisfied with great</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>quality poor broke after one use terrible enough</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>acceptable for price but there better options ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>great quality fast shipping with wonderful love</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0                   love great exceeded expectations  positive\n",
       "1   worst purchase have ever made completely useless  negative\n",
       "2    average nothing special but not terrible either   neutral\n",
       "3  great who can help but love design highly reco...  positive\n",
       "4  terrible experience will never buy from poor b...  negative\n",
       "5  acceptable but expected better not just accept...   neutral\n",
       "6     absolutely wonderful very satisfied with great  positive\n",
       "7   quality poor broke after one use terrible enough  negative\n",
       "8  acceptable for price but there better options ...   neutral\n",
       "9    great quality fast shipping with wonderful love  positive"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(positive): 0.4\n",
      "P(negative): 0.3\n",
      "P(neutral): 0.3\n"
     ]
    }
   ],
   "source": [
    "P_positive = len(df[df['sentiment'] == 'positive']) / len(df)\n",
    "P_negative = len(df[df['sentiment'] == 'negative']) / len(df)\n",
    "P_neutral = len(df[df['sentiment'] == 'neutral']) / len(df)\n",
    "\n",
    "print(\"P(positive):\", P_positive)\n",
    "print(\"P(negative):\", P_negative)\n",
    "print(\"P(neutral):\", P_neutral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê°€ëŠ¥ë„ë¥¼ êµ¬í•˜ê¸° ìœ„í•œ í™•ë¥ ë“¤ì„ ê³„ì‚°í•©ë‹ˆë‹¤.  \n",
    "ì˜ˆ: ì²«ë²ˆì§¸ ë¬¸ì¥ ë¶„ë¥˜ë¥¼ ìœ„í•´ì„œëŠ”, $P(love|positive), P(great|positive), P(awesome|positive)\\\\\n",
    "P(love|negative), P(great|negative), P(awesome|negative)\\\\\n",
    "P(love|neutral), P(great|neutral), P(great|neutral)$ë¥¼ êµ¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ ë•Œ CountVectorizerë¥¼ ì‚¬ìš©í•˜ì—¬ ë„ì¶œí•œ ë‹¨ì–´ ë²¡í„°ë¥¼ í™œìš©í•˜ë©´ í™•ë¥ ë“¤ì„ ê°„í¸í•˜ê²Œ êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
    "ì°¸ê³ : https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "review_array = vectorizer.fit_transform(df['review']).toarray()\n",
    "review_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['absolutely', 'acceptable', 'after', 'again', 'average', 'better',\n",
       "       'brand', 'broke', 'but', 'buy', 'can', 'completely', 'design',\n",
       "       'either', 'enough', 'ever', 'exceeded', 'expectations', 'expected',\n",
       "       'experience', 'fast', 'for', 'from', 'great', 'have', 'help',\n",
       "       'highly', 'just', 'love', 'made', 'never', 'not', 'nothing', 'one',\n",
       "       'options', 'out', 'poor', 'price', 'purchase', 'quality',\n",
       "       'recommend', 'satisfied', 'shipping', 'special', 'terrible',\n",
       "       'there', 'use', 'useless', 'very', 'who', 'will', 'with',\n",
       "       'wonderful', 'worst'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 28,\n",
       " 'great': 23,\n",
       " 'exceeded': 16,\n",
       " 'expectations': 17,\n",
       " 'worst': 53,\n",
       " 'purchase': 38,\n",
       " 'have': 24,\n",
       " 'ever': 15,\n",
       " 'made': 29,\n",
       " 'completely': 11,\n",
       " 'useless': 47,\n",
       " 'average': 4,\n",
       " 'nothing': 32,\n",
       " 'special': 43,\n",
       " 'but': 8,\n",
       " 'not': 31,\n",
       " 'terrible': 44,\n",
       " 'either': 13,\n",
       " 'who': 49,\n",
       " 'can': 10,\n",
       " 'help': 25,\n",
       " 'design': 12,\n",
       " 'highly': 26,\n",
       " 'recommend': 40,\n",
       " 'experience': 19,\n",
       " 'will': 50,\n",
       " 'never': 30,\n",
       " 'buy': 9,\n",
       " 'from': 22,\n",
       " 'poor': 36,\n",
       " 'brand': 6,\n",
       " 'again': 3,\n",
       " 'acceptable': 1,\n",
       " 'expected': 18,\n",
       " 'better': 5,\n",
       " 'just': 27,\n",
       " 'one': 33,\n",
       " 'absolutely': 0,\n",
       " 'wonderful': 52,\n",
       " 'very': 48,\n",
       " 'satisfied': 41,\n",
       " 'with': 51,\n",
       " 'quality': 39,\n",
       " 'broke': 7,\n",
       " 'after': 2,\n",
       " 'use': 46,\n",
       " 'enough': 14,\n",
       " 'for': 21,\n",
       " 'price': 37,\n",
       " 'there': 45,\n",
       " 'options': 34,\n",
       " 'out': 35,\n",
       " 'fast': 20,\n",
       " 'shipping': 42}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>after</th>\n",
       "      <th>again</th>\n",
       "      <th>average</th>\n",
       "      <th>better</th>\n",
       "      <th>brand</th>\n",
       "      <th>broke</th>\n",
       "      <th>but</th>\n",
       "      <th>...</th>\n",
       "      <th>terrible</th>\n",
       "      <th>there</th>\n",
       "      <th>use</th>\n",
       "      <th>useless</th>\n",
       "      <th>very</th>\n",
       "      <th>who</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>wonderful</th>\n",
       "      <th>worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  absolutely  acceptable  after  again  average  better  brand  \\\n",
       "0  positive           0           0      0      0        0       0      0   \n",
       "1  negative           0           0      0      0        0       0      0   \n",
       "2   neutral           0           0      0      0        1       0      0   \n",
       "3  positive           0           0      0      0        0       0      0   \n",
       "4  negative           0           0      0      1        0       0      1   \n",
       "5   neutral           0           2      0      0        0       1      0   \n",
       "6  positive           1           0      0      0        0       0      0   \n",
       "7  negative           0           0      1      0        0       0      0   \n",
       "8   neutral           0           1      0      0        0       1      0   \n",
       "9  positive           0           0      0      0        0       0      0   \n",
       "\n",
       "   broke  but  ...  terrible  there  use  useless  very  who  will  with  \\\n",
       "0      0    0  ...         0      0    0        0     0    0     0     0   \n",
       "1      0    0  ...         0      0    0        1     0    0     0     0   \n",
       "2      0    1  ...         1      0    0        0     0    0     0     0   \n",
       "3      0    1  ...         0      0    0        0     0    1     0     0   \n",
       "4      0    0  ...         1      0    0        0     0    0     1     0   \n",
       "5      0    1  ...         0      0    0        0     0    0     0     0   \n",
       "6      0    0  ...         0      0    0        0     1    0     0     1   \n",
       "7      1    0  ...         1      0    1        0     0    0     0     0   \n",
       "8      0    1  ...         0      2    0        0     0    0     0     0   \n",
       "9      0    0  ...         0      0    0        0     0    0     0     1   \n",
       "\n",
       "   wonderful  worst  \n",
       "0          0      0  \n",
       "1          0      1  \n",
       "2          0      0  \n",
       "3          0      0  \n",
       "4          0      0  \n",
       "5          0      0  \n",
       "6          1      0  \n",
       "7          0      0  \n",
       "8          0      0  \n",
       "9          1      0  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_matrix = pd.DataFrame(review_array, columns = vectorizer.get_feature_names_out())\n",
    "frequency_matrix = pd.concat([df['sentiment'], frequency_matrix], axis=1)\n",
    "frequency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(love/positive) 0.75\n",
      "P(love/negative) 0.0\n",
      "P(love/neutral) 0.0\n",
      "P(great/positive) 1.0\n",
      "P(great/negative) 0.0\n",
      "P(great/neutral) 0.0\n",
      "P(awesome/positive): 0\n",
      "P(awesome/negative): 0\n",
      "P(awesome/neutral): 0\n",
      "\n",
      "\n",
      "P(terrible/positive) 0.0\n",
      "P(terrible/negative) 0.6666666666666666\n",
      "P(terrible/neutral) 0.3333333333333333\n",
      "P(not/positive) 0.0\n",
      "P(not/negative) 0.0\n",
      "P(not/neutral) 0.6666666666666666\n",
      "P(never/positive) 0.0\n",
      "P(never/negative) 0.3333333333333333\n",
      "P(never/neutral) 0.0\n"
     ]
    }
   ],
   "source": [
    "# ìœ„ì™€ ê°™ì´ ì¡°ê±´ë¶€ í™•ë¥ ì„ êµ¬í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”\n",
    "\n",
    "# ğ‘ƒ(ğ‘™ğ‘œğ‘£ğ‘’|ğ‘ğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’),ğ‘ƒ(ğ‘”ğ‘Ÿğ‘’ğ‘ğ‘¡|ğ‘ğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’),ğ‘ƒ(ğ‘ğ‘¤ğ‘’ğ‘ ğ‘œğ‘šğ‘’|ğ‘ğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’)\n",
    "# ğ‘ƒ(ğ‘™ğ‘œğ‘£ğ‘’|ğ‘›ğ‘’ğ‘”ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’),ğ‘ƒ(ğ‘”ğ‘Ÿğ‘’ğ‘ğ‘¡|ğ‘›ğ‘’ğ‘”ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’),ğ‘ƒ(ğ‘ğ‘¤ğ‘’ğ‘ ğ‘œğ‘šğ‘’|ğ‘›ğ‘’ğ‘”ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’)\n",
    "# ğ‘ƒ(ğ‘™ğ‘œğ‘£ğ‘’|ğ‘›ğ‘’ğ‘¢ğ‘¡ğ‘Ÿğ‘ğ‘™),ğ‘ƒ(ğ‘”ğ‘Ÿğ‘’ğ‘ğ‘¡|ğ‘›ğ‘’ğ‘¢ğ‘¡ğ‘Ÿğ‘ğ‘™),ğ‘ƒ(ğ‘”ğ‘Ÿğ‘’ğ‘ğ‘¡|ğ‘›ğ‘’ğ‘¢ğ‘¡ğ‘Ÿğ‘ğ‘™)\n",
    "cnt_pos = len(frequency_matrix[frequency_matrix['sentiment'] == 'positive'])\n",
    "cnt_nega = len(frequency_matrix[frequency_matrix['sentiment'] == 'negative'])\n",
    "cnt_neu = len(frequency_matrix[frequency_matrix['sentiment'] == 'neutral'])\n",
    "\n",
    "sentiment = ['positive', 'negative', 'neutral']\n",
    "review1=['love', 'great', 'awesome']\n",
    "review2 = ['terrible', 'not', 'never']\n",
    "\n",
    "post1 = []\n",
    "post2 = []\n",
    "for i in review1:    \n",
    "    p = []\n",
    "    for j in sentiment:\n",
    "        if i not in frequency_matrix.columns:\n",
    "            print(\"P(\"+i+\"/\"+j+\"): 0\")\n",
    "            p.append(0)\n",
    "        else: \n",
    "            a= len(frequency_matrix[(frequency_matrix['sentiment'] == j) & (frequency_matrix[i]!=0)])\n",
    "            b= len(frequency_matrix[(frequency_matrix['sentiment'] == j)])\n",
    "            print(\"P(\"+i+\"/\"+j+\")\", a/b )    \n",
    "            p.append(a/b)\n",
    "    post1.append(p)\n",
    "                  \n",
    "                \n",
    "print(\"\\n\")\n",
    "\n",
    "for i in review2:\n",
    "    p = []\n",
    "    for j in sentiment:\n",
    "        if i not in frequency_matrix.columns:\n",
    "            print(\"P(\"+i+\"/\"+j+\"): 0\")\n",
    "            p.append(0)\n",
    "        else: \n",
    "            a= len(frequency_matrix[(frequency_matrix['sentiment'] == j) & (frequency_matrix[i]!=0)])\n",
    "            b= len(frequency_matrix[(frequency_matrix['sentiment'] == j)])\n",
    "            print(\"P(\"+i+\"/\"+j+\")\", a/b )    \n",
    "            p.append(a/b)\n",
    "    post2.append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë…ë¦½ì„± ê°€ì •ì„ ì´ìš©í•˜ì—¬ ê°€ëŠ¥ë„(likelihood)ë¥¼ êµ¬í•©ë‹ˆë‹¤.  \n",
    "ì²«ë²ˆì§¸ ë¬¸ì¥ ì˜ˆì‹œ: $P(love, great, awesome|positive), P(love, great, awesome|negative), P(love, great, awesome|neutral)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive_df = frequency_matrix[frequency_matrix['sentiment'] == 'negative']\n",
    "\n",
    "# # ê° ì—´ì—ì„œ ê°’ì´ 0ì´ ì•„ë‹Œ ì—´ì˜ ê°œìˆ˜ ê³„ì‚°\n",
    "# non_zero_counts = (positive_df.iloc[:, 1:] != 0).sum()\n",
    "\n",
    "# # ê°’ì´ 0ì´ ì•„ë‹Œ ì—´ì˜ ê°œìˆ˜\n",
    "# non_zero_columns_count = (non_zero_counts > 0).sum()\n",
    "\n",
    "# print(\"Sentimentê°€ 'positive'ì´ê³  ê°’ì´ 0ì´ ì•„ë‹Œ ì—´ì˜ ê°œìˆ˜:\", non_zero_columns_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "awesome_pos= 1/(19+ len(vectorizer.vocabulary_))\n",
    "post1[2][0] = awesome_pos* 1*0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğ‘ƒ(ğ‘™ğ‘œğ‘£ğ‘’,ğ‘”ğ‘Ÿğ‘’ğ‘ğ‘¡,ğ‘ğ‘¤ğ‘’ğ‘ ğ‘œğ‘šğ‘’|ğ‘ğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’) 0.007705479452054794\n",
      "ğ‘ƒ(ğ‘™ğ‘œğ‘£ğ‘’,ğ‘”ğ‘Ÿğ‘’ğ‘ğ‘¡,ğ‘ğ‘¤ğ‘’ğ‘ ğ‘œğ‘šğ‘’|ğ‘›ğ‘’ğ‘”ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’) 0.0\n",
      "ğ‘ƒ(ğ‘™ğ‘œğ‘£ğ‘’,ğ‘”ğ‘Ÿğ‘’ğ‘ğ‘¡,ğ‘ğ‘¤ğ‘’ğ‘ ğ‘œğ‘šğ‘’|ğ‘›ğ‘’ğ‘¢ğ‘¡ğ‘Ÿğ‘ğ‘™) 0.0\n",
      "ğ‘ƒ(terrible, not, never|ğ‘ğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’) 0.0\n",
      "ğ‘ƒ(terrible, not, never|ğ‘›ğ‘’ğ‘”ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’) 0.0\n",
      "ğ‘ƒ(terrible, not, never|ğ‘›ğ‘’ğ‘¢ğ‘¡ğ‘Ÿğ‘ğ‘™) 0.0\n"
     ]
    }
   ],
   "source": [
    "# ê°€ëŠ¥ë„ êµ¬í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "result1 = []\n",
    "result2 = []\n",
    "# ë°°ì—´ì˜ ê¸¸ì´ë§Œí¼ ë°˜ë³µí•˜ë©° ì¸ë±ìŠ¤ë¼ë¦¬ ê³±ì…ˆ ìˆ˜í–‰\n",
    "for i in range(len(post1[0])):\n",
    "    product = 1\n",
    "    for row in post1:\n",
    "        product *= row[i]\n",
    "    result1.append(product)\n",
    "\n",
    "for i in range(len(post2[0])):\n",
    "    product = 1\n",
    "    for row in post2:\n",
    "        product *= row[i]\n",
    "    result2.append(product)\n",
    "\n",
    "print(\"ğ‘ƒ(ğ‘™ğ‘œğ‘£ğ‘’,ğ‘”ğ‘Ÿğ‘’ğ‘ğ‘¡,ğ‘ğ‘¤ğ‘’ğ‘ ğ‘œğ‘šğ‘’|ğ‘ğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’)\", result1[0])\n",
    "print(\"ğ‘ƒ(ğ‘™ğ‘œğ‘£ğ‘’,ğ‘”ğ‘Ÿğ‘’ğ‘ğ‘¡,ğ‘ğ‘¤ğ‘’ğ‘ ğ‘œğ‘šğ‘’|ğ‘›ğ‘’ğ‘”ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’)\", result1[1])\n",
    "print(\"ğ‘ƒ(ğ‘™ğ‘œğ‘£ğ‘’,ğ‘”ğ‘Ÿğ‘’ğ‘ğ‘¡,ğ‘ğ‘¤ğ‘’ğ‘ ğ‘œğ‘šğ‘’|ğ‘›ğ‘’ğ‘¢ğ‘¡ğ‘Ÿğ‘ğ‘™)\", result1[2])\n",
    "\n",
    "\n",
    "print(\"ğ‘ƒ(terrible, not, never|ğ‘ğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’)\", result2[0])\n",
    "print(\"ğ‘ƒ(terrible, not, never|ğ‘›ğ‘’ğ‘”ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’)\", result2[1])\n",
    "print(\"ğ‘ƒ(terrible, not, never|ğ‘›ğ‘’ğ‘¢ğ‘¡ğ‘Ÿğ‘ğ‘™)\", result2[2])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ìœ„ì—ì„œ êµ¬í•œ ì‚¬ì „ í™•ë¥ ê³¼ ê°€ëŠ¥ë„ë¥¼ ì´ìš©í•˜ì—¬ íƒ€ê²Ÿ ë¬¸ì¥ì´ positive, negative, neutralì¼ í™•ë¥ ì„ êµ¬í•˜ê³  ìµœì¢…ì ìœ¼ë¡œ ì–´ë–¤ ê°ì„±ì¼ì§€ ë¶„ì„í•´ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frequency_matrix[(frequency_matrix['love']!=0) |(frequency_matrix['great']!=0) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(positive|target_review1):  0.007705479452054794\n",
      "P(negative|target_review1):  0.0\n",
      "P(neutral|target_review1):  0.0\n",
      "P(positive|target_review1):  0.0\n",
      "P(negative|target_review1):  0.0\n",
      "P(neutral|target_review1):  0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# ìµœì¢… í™•ë¥  êµ¬í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
    "# ì²«ë²ˆì§¸ ë¬¸ì¥\n",
    "\n",
    "print(\"P(positive|target_review1): \",P_positive* result1[0]/(len(frequency_matrix[(frequency_matrix['love']!=0) |(frequency_matrix['great']!=0) ])/10))\n",
    "\n",
    "# P(negative|target_review1)\n",
    "\n",
    "print(\"P(negative|target_review1): \",P_negative* result1[1]/(len(frequency_matrix[(frequency_matrix['love']!=0) |(frequency_matrix['great']!=0) ])/10))\n",
    "# P(neutral|target_review1)\n",
    "print(\"P(neutral|target_review1): \",P_neutral* result1[2]/(len(frequency_matrix[(frequency_matrix['love']!=0) |(frequency_matrix['great']!=0) ])/10))\n",
    "\n",
    "\n",
    "# ë‘ë²ˆì§¸ ë¬¸ì¥\n",
    "# P(positive|target_review2)\n",
    "print(\"P(positive|target_review1): \",P_positive* result2[0]/(len(frequency_matrix[(frequency_matrix['never']!=0)| (frequency_matrix['terrible']!=0) |(frequency_matrix['not']!=0) ])/10))\n",
    "\n",
    "\n",
    "# P(negative|target_review2)\n",
    "print(\"P(negative|target_review1): \",P_negative* result2[1]/(len(frequency_matrix[(frequency_matrix['never']!=0)| (frequency_matrix['terrible']!=0) |(frequency_matrix['not']!=0) ])/10))\n",
    "\n",
    "\n",
    "# P(neutral|target_review2)\n",
    "print(\"P(neutral|target_review1): \",P_neutral* result2[2]/(len(frequency_matrix[(frequency_matrix['never']!=0)| (frequency_matrix['terrible']!=0) |(frequency_matrix['not']!=0) ])/10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2-1.   \n",
    "Target review1ì˜ ë¶„ë¥˜ ê²°ê³¼:   \n",
    "Target review2ì˜ ë¶„ë¥˜ ê²°ê³¼: ë¶€ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2-2. ë‚˜ì´ë¸Œ ë² ì´ì§€ì•ˆ ê¸°ë°˜ í™•ë¥ ì„ êµ¬í•˜ëŠ” ê³¼ì •ì—ì„œ ì–´ë–¤ ë¬¸ì œì ì„ ë°œê²¬í•  ìˆ˜ ìˆì—ˆë‚˜ìš”? ê·¸ë¦¬ê³  ê·¸ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ë°©ë²•ì— ëŒ€í•´ ê°„ëµí•˜ê²Œ ì¡°ì‚¬ ë° ì„œìˆ í•´ ì£¼ì„¸ìš”. (íŒíŠ¸: Laplace smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2-2. awesome ê°™ì€ ì—†ëŠ” ë‹¨ì–´ê°€ ìˆìœ¼ë©´ 0ì´ ë˜ì–´ë²„ë¦¼. ì´ë¥¼ ë°©ì§€í•˜ê¸°ìœ„í•´ Naive Bayes ë¶„ë¥˜ê¸°ì—ì„œ ë²”ì£¼í˜• ë°ì´í„°ì˜ í™•ë¥ ì„ ê³„ì‚°í•  ë•Œ, ë¹ˆë„ ê¸°ë°˜ í™•ë¥ ì´ 0ì´ ë˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ë¼í”Œë¼ìŠ¤ ìŠ¤ë¬´ë”© ì‚¬ìš©"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
